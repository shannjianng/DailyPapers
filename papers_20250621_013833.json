[
  {
    "title": "Simulation and one-ring prototyping of 1 mm-rod-resolution hemispherical brain PET with TOF-DOI detectors.",
    "authors": [
      "Kurumi Narita",
      "Go Akamatsu",
      "Eiji Yoshida",
      "Hideaki Tashima",
      "Yuma Iwao",
      "Miwako Takahashi",
      "Taiga Yamaya"
    ],
    "abstract": "Objective.Brain positron emission tomography (PET) imaging plays crucial roles in research and diagnosis of various brain diseases. To achieve high spatial resolution and high sensitivity, we proposed a hemispherical geometry which offers higher sensitivity with fewer detectors than a conventional cylindrical geometry. Our developed hemispherical brain PET system, Vrain, has indeed achieved a rod resolution of 2.2 mm with a 229 ps time-of-flight (TOF) resolution. To further improve the spatial resolution, we will use TOF and depth-of-interaction (DOI) detectors with our original crosshair light-sharing (CLS) configuration. This study aimed at estimating the performance of the hemispherical brain PET with TOF-DOI detectors and at developing a one-ring PET prototype with 1.6 mm scintillator pitch CLS-based TOF-DOI detectors.Approach.The sensitivity, rod resolution, and image quality of the TOF-DOI hemispherical brain PET (TDHBP-sim) and Vrain (Vrain-sim) were estimated using Geant4 simulation. A one-ring prototype with a 30 cm diameter was developed using the CLS-based TOF-DOI detectors. The energy resolution, TOF timing resolution, rod resolution, and the Hoffman brain phantom image quality of the prototype were evaluated.Main results.In the simulation study, TDHBP-sim achieved 1.4 times better sensitivity than Vrain-sim. TDHBP-sim visualized 1.0 mm rods and gyri and sulci structures in the brain phantom. In the one-ring experiment, the energy resolution was 11.6% at 511 keV, the TOF timing resolution was 294.6 ps, and 1.0 mm rods were resolved at the central 10 cm-diameter field-of-view. The 0.8 mm-thick radioactivity distribution could be identified in the Hoffman phantom.Significance.The study findings suggested that a hemispherical brain PET with 1.6 mm scintillator pitch TOF-DOI detectors should offer excellent performance including 1 mm rod resolution.",
    "abstract_zh": "**翻译：**<br><br>目标。脑部正电子发射断层扫描(PET)成像在各种脑疾病的研究和诊断中发挥着至关重要的作用。为了实现高空间分辨率和高灵敏度，我们提出了一种半球形几何结构，与传统的圆柱形几何结构相比，它可以用更少的探测器提供更高的灵敏度。我们开发的半球形脑部PET系统Vrain确实实现了2.2毫米的杆分辨率和229皮秒的飞行时间(TOF)分辨率。为了进一步提高空间分辨率，我们将结合TOF和深度相互作用(DOI)探测器，采用我们原创的十字光共享(CLS)配置。本研究旨在评估配备TOF-DOI探测器的半球形脑部PET的性能，并开发一个单环PET原型，该原型采用基于CLS、闪烁体间距为1.6毫米的TOF-DOI探测器。<br><br>方法。使用Geant4模拟估计了TOF-DOI半球形脑部PET（TDHBP-sim）和Vrain（Vrain-sim）的灵敏度、杆分辨率和图像质量。使用基于CLS的TOF-DOI探测器开发了一个直径为30厘米的单环原型。评估了该原型的能量分辨率、TOF时间分辨率、杆分辨率以及霍夫曼脑部模型图像质量。<br><br>主要结果。在模拟研究中，TDHBP-sim的灵敏度比Vrain-sim提高了1.4倍。 TDHBP-sim可以可视化脑部模型中1.0毫米的杆以及脑回和脑沟结构。在单环实验中，511 keV处的能量分辨率为11.6％，TOF时间分辨率为294.6 ps，并且在直径为10厘米的中心视野中可以分辨出1.0毫米的杆。可以在霍夫曼模型中识别出0.8毫米厚的放射性分布。<br><br>意义。研究结果表明，配备1.6毫米闪烁体间距TOF-DOI探测器的半球形脑部PET应该提供出色的性能，包括1毫米杆分辨率。",
    "summary_zh": "本研究旨在提升脑部PET成像的空间分辨率和灵敏度。研究者提出并模拟了一种半球形PET系统（TDHBP-sim），并与现有Vrain系统进行了比较。模拟结果表明，TDHBP-sim在灵敏度和分辨率上均优于Vrain。同时，研究者还开发了一个基于十字光共享(CLS)的单环TOF-DOI探测器原型，实验结果验证了该原型在分辨率方面的潜力。研究结果表明，采用1.6mm闪烁体间距TOF-DOI探测器的半球形PET系统有望达到1mm的杆分辨率，从而显著提升脑部PET成像的性能。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/ade2b4",
    "link": "https://doi.org/10.1088/1361-6560/ade2b4"
  },
  {
    "title": "Enhancing image quality in fast neutron-based range verification of proton therapy using a deep learning-based prior in LM-MAP-EM reconstruction.",
    "authors": [
      "Lena M Setterdahl",
      "Kyrre Skjerdal",
      "Hunter N Ratliff",
      "Kristian Smeland Ytre-Hauge",
      "William R B Lionheart",
      "Sean Holman",
      "Helge E S Pettersen",
      "Francesco Blangiardi",
      "Danny Lathouwers",
      "Ilker Meric"
    ],
    "abstract": "Objective.This study investigates the use of list-mode (LM) maximuma posteriori(MAP) expectation maximization (EM) incorporating prior information predicted by a convolutional neural network for image reconstruction in fast neutron (FN)-based proton therapy range verification.Approach. A conditional generative adversarial network (pix2pix) was trained on progressively noisier data, where detector resolution effects were introduced gradually to simulate realistic conditions. FN data were generated using Monte Carlo simulations of an 85 MeV proton pencil beam in a computed tomography-based lung cancer patient model, with range shifts emulating weight gain and loss. The network was trained to estimate the expected two-dimensional ground truth FN production distribution from simple back-projection images. Performance was evaluated using mean squared error, structural similarity index (SSIM), and the correlation between shifts in predicted distributions and true range shifts.Main results. Our results show that pix2pix performs well on noise-free data but suffers from significant degradation when detector resolution effects are introduced. Among the LM-MAP-EM approaches tested, incorporating a mean prior estimate into the reconstruction process improved performance, with LM-MAP-EM using a mean prior estimate outperforming naïve LM maximum likelihood EM (LM-MLEM) and conventional LM-MAP-EM with a smoothing quadratic energy function in terms of SSIM.Significance. Findings suggest that deep learning techniques can enhance iterative reconstruction for range verification in proton therapy. However, the effectiveness of the model is highly dependent on data quality, limiting its robustness in high-noise scenarios.",
    "abstract_zh": "**翻译：**<br><br>**目的。** 本研究旨在探讨在基于快中子（FN）的质子治疗射程验证中，利用列表模式（LM）最大后验（MAP）期望最大化（EM）算法进行图像重建的方法，该方法结合了卷积神经网络预测的先验信息。<br><br>**方法。** 一个条件生成对抗网络（pix2pix）在逐渐增加噪声的数据上进行训练，其中探测器分辨率效应被逐步引入以模拟真实条件。快中子数据通过蒙特卡罗模拟在一个基于CT的肺癌患者模型中模拟一个85 MeV的质子笔形束产生，并模拟了因体重增加和减少而导致的射程偏移。该网络被训练成从简单的反投影图像中估计预期的二维真实快中子产生分布。使用均方误差、结构相似性指数（SSIM）以及预测分布偏移和真实射程偏移之间的相关性来评估性能。<br><br>**主要结果。** 结果表明，pix2pix在无噪声数据上表现良好，但在引入探测器分辨率效应后性能显著下降。在测试的LM-MAP-EM方法中，将平均先验估计纳入重建过程可以提高性能，其中使用平均先验估计的LM-MAP-EM在SSIM方面优于简单的LM最大似然EM（LM-MLEM）以及具有平滑二次能量函数的传统LM-MAP-EM。<br><br>**意义。** 研究结果表明，深度学习技术可以增强质子治疗射程验证的迭代重建效果。然而，模型的有效性高度依赖于数据质量，限制了其在高噪声场景中的鲁棒性。",
    "summary_zh": "本研究探索了使用深度学习增强快中子质子治疗射程验证中图像重建的方法。研究使用条件生成对抗网络（pix2pix）预测快中子产生分布的先验信息，并将其整合到列表模式最大后验期望最大化（LM-MAP-EM）算法中进行图像重建。结果表明，深度学习方法在无噪声数据上有效，但受探测器分辨率和噪声的影响较大，将平均先验估计纳入重建过程能够提高性能。研究强调了数据质量对深度学习模型在实际应用中鲁棒性的重要影响。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/ade198",
    "link": "https://doi.org/10.1088/1361-6560/ade198"
  },
  {
    "title": "Development of an ultrasensitive small animal PET with 4-layer DOI detectors for sub-second dynamic rodent imaging.",
    "authors": [
      "Han Gyu Kang",
      "Hideaki Tashima",
      "Hidekatsu Wakizaka",
      "Go Akamatsu",
      "Yuma Iwao",
      "Chie Toramatsu",
      "Taiga Yamaya"
    ],
    "abstract": "Objective.Dynamic positron emission tomography (PET) imaging is important for preclinical research since it can visualize the functional information of rodent models as a function of time. However, the temporal resolution of small animal PET imaging has been limited to a scale of seconds due to low sensitivity, and it is not sufficient to capture cardiac or brain function accurately. Here, we present an ultrasensitive small-animal PET scanner with total-body coverage for sub-second dynamic imaging of a rat.Methods.The ultrasensitive small animal PET scanner has a 155 mm inner diameter and 325.6 mm axial coverage. The PET scanner has six rings, each of which has 10 depth-of-interaction (DOI) detectors. Each DOI detector consists of a four-layer Zr-doped gadolinium oxyorthosilicate crystal array (2.85 mm pitch, 30 mm total thickness) and 8 × 8 multi-anode photomultiplier tubes. The physical PET performance was evaluated based on the National Electrical Manufacturers Association NU4 protocol. Sub-second dynamic rat imaging was performed with18F-FDG tracer.Main results.The peak absolute sensitivity was 20.2% and spatial resolution was 2.6 mm at the center of the field of view with an energy window of 400-600 keV. Total-body images of a rat were obtained with a single bed position. The cardiac function of a rat was visualized with 0.25 s temporal resolution, which was hardly possible with conventional small animal PET scanners.Significance. The developed ultrasensitive animal PET enabled sub-second dynamic PET imaging in rodent models with total-body coverage. In conclusion, the ultrasensitive small animal PET scanner can serve as a useful molecular imaging tool for preclinical research with its long axial coverage sub-second temporal resolution.",
    "abstract_zh": "**翻译：**<br><br>**目的。** 动态正电子发射断层扫描（PET）成像对于临床前研究至关重要，因为它能够以时间为函数可视化啮齿动物模型的功能信息。然而，由于灵敏度低，小动物PET成像的时间分辨率一直被限制在秒级，不足以准确捕捉心脏或大脑功能。在此，我们展示了一种超灵敏小动物PET扫描仪，该扫描仪具有全身覆盖范围，可对大鼠进行亚秒级动态成像。<br><br>**方法。** 该超灵敏小动物PET扫描仪的内径为155毫米，轴向覆盖范围为325.6毫米。该PET扫描仪有六个环，每个环都具有10个深度方向（DOI）探测器。每个DOI探测器由一个四层掺锆硅酸钆晶体阵列（2.85毫米间距，30毫米总厚度）和8 × 8 多阳极光电倍增管组成。根据美国国家电气制造商协会NU4协议评估了PET的物理性能。使用18F-FDG示踪剂进行亚秒级动态大鼠成像。<br><br>**主要结果。** 在400-600 keV的能量窗口下，峰值绝对灵敏度为20.2%，视场中心的空间分辨率为2.6毫米。通过单次床位扫描获得了大鼠的全身图像。以0.25秒的时间分辨率可视化了大鼠的心脏功能，这在传统的小动物PET扫描仪上几乎是不可能的。<br><br>**意义。** 所开发的超灵敏动物PET能够对啮齿动物模型进行具有全身覆盖范围的亚秒级动态PET成像。总之，超灵敏小动物PET扫描仪具有较长的轴向覆盖范围和亚秒级的时间分辨率，可以作为临床前研究中一种有用的分子成像工具。<br><br>**",
    "summary_zh": "**\n\n本研究开发了一种新型超灵敏小动物PET扫描仪，具有全身覆盖和大鼠亚秒级动态成像能力。该扫描仪的峰值灵敏度为20.2%，空间分辨率为2.6mm。使用该扫描仪成功实现了对大鼠心脏功能的0.25秒时间分辨率成像。该设备有望成为临床前研究中进行分子成像的有力工具。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/ade112",
    "link": "https://doi.org/10.1088/1361-6560/ade112"
  },
  {
    "title": "Physical phantom validation of clustering-initiated factorization in dynamic PET.",
    "authors": [
      "Valerie Kobzarenko",
      "Suzanne L Baker",
      "Mustafa Janabi",
      "Woon-Seng Choong",
      "Grant T Gullberg",
      "Youngho Seo",
      "Rostyslav Boutchko",
      "Debasis Mitra"
    ],
    "abstract": "BACKGROUND: Dynamic positron emission tomography (PET) enables the quantification of physiological parameters of radiotracers employed in the investigation of neuropsychiatric disorders. We previously introduced a factor analysis-based algorithm, Cluster-Initialized Factor Analysis (CIFA), designed to overcome the problem of specifying reference regions. CIFA is capable of automatically extracting distinct radiotracer binding distributions across many modalities based on the differences in tracer dynamics, and thus can distinguish regions of specific- and non-specific binding without requiring prior segmentation.\nPURPOSE: Our goal is to quantitatively validate the ability of CIFA to resolve different dynamic biological processes by comparing the output of the algorithm to an independent benchmark. As an intermediate goal, we aim to create a physical phantom capable of modeling unique aspects of dynamic imaging and to use this phantom as the benchmark in evaluating CIFA.\nMETHODS: CIFA was used to reconstruct 18F-flortaucipir dynamic brain PET datasets acquired at Lawrence Berkeley National Lab. The resulting factor curves served as the foundation for creating dynamic input time-activity curve (TAC) combinations in a physical brain phantom specifically constructed for this purpose. The phantom represented three components: two overlapping tissue types and free radiotracer, constructed with a combination of small hydraulic elements. The physical components were scanned separately to generate a library of images, allowing us to reproduce scans of any duration with prescribed dynamics and realistic partial volume effects. The phantom was designed to produce noisy instances with compartment mixing of dynamic scans with desired activity TACs for free, non-specifically bound, and specifically bound radiotracers. Ten distinct dynamic simulations with varying levels of TAC similarity were estimated with CIFA.\nRESULTS: We directly evaluated CIFA's performance in analyzing each of the 10 dynamic datasets by computing the Pearson correlation coefficient between the estimated outputs and the ground truth tissue TACs and corresponding tissue distributions. For seven out of 10 modeled dynamics, which captured the full spectrum of realistically expected tissue TAC shapes, the curve correlation of the specific binding tissue was above 95%.\nCONCLUSIONS: This work formulated an innovative process by combining a physical phantom design with PET images for evaluating the application of CIFA in the extraction of dynamic TACs from dynamic PET image data. In most cases the CIFA algorithm accurately reproduced the dynamics of the phantom simulated data.",
    "abstract_zh": "翻译：<br><br>背景：动态正电子发射断层扫描（PET）能够量化放射性示踪剂的生理参数，这些示踪剂被用于神经精神疾病的研究。我们之前引入了一种基于因子分析的算法，即聚类初始化因子分析（CIFA），旨在克服指定参考区域的问题。CIFA能够基于示踪剂动力学的差异，自动提取跨多种模式的不同放射性示踪剂结合分布，从而区分特异性结合区域和非特异性结合区域，而无需预先分割。<br><br>目的：我们的目标是通过将算法的输出与独立的基准进行比较，定量验证CIFA解析不同动态生物过程的能力。作为一个中间目标，我们旨在创建一个能够模拟动态成像独特方面的物理模型，并使用该模型作为评估CIFA的基准。<br><br>方法：我们使用CIFA重建了在劳伦斯伯克利国家实验室获取的18F-flortaucipir动态脑部PET数据集。生成的因子曲线构成了物理脑部模型中创建动态输入时间-活动曲线（TAC）组合的基础，该模型是专门为此目的构建的。该模型代表三个组成部分：两种重叠的组织类型和游离放射性示踪剂，由小型液压元件组合构建而成。各个物理组件被单独扫描以生成图像库，使我们能够重现具有预定动力学和真实部分容积效应的任何持续时间的扫描。该模型旨在产生具有动态扫描的隔室混合的噪声实例，这些扫描具有针对游离、非特异性结合和特异性结合放射性示踪剂的所需活动TAC。使用CIFA估计了十种具有不同TAC相似度水平的不同动态模拟。<br><br>结果：我们通过计算估计输出与真实组织TAC以及相应组织分布之间的皮尔逊相关系数，直接评估了CIFA在分析10个动态数据集中的表现。对于10个建模动态中的7个，它们捕获了现实预期的组织TAC形状的完整范围，特异性结合组织的曲线相关性高于95％。<br><br>结论：这项工作通过将物理模型设计与PET图像相结合，制定了一个创新的过程，用于评估CIFA在从动态PET图像数据中提取动态TAC的应用。在大多数情况下，CIFA算法准确地再现了模型模拟数据的动态特性。",
    "summary_zh": "本研究旨在验证一种名为CIFA的PET图像分析算法在区分不同动态生物过程的能力。研究者构建了一个物理脑模型，该模型可以模拟放射性示踪剂在不同组织中的动态变化。通过比较CIFA算法的输出与模型的真实动态数据，研究发现CIFA能够准确地再现大多数情况下模拟数据的动态特性，从而验证了该算法的有效性。该研究为CIFA在神经精神疾病研究中的应用提供了依据。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17902",
    "link": "https://doi.org/10.1002/mp.17902"
  },
  {
    "title": "Modeling prompt gamma (PG) emission, detection and imaging in real patient anatomy using a novel Compton camera for dose verification in proton therapy.",
    "authors": [
      "V R Sharma",
      "Z Jiang",
      "S Mossahebi",
      "E Shakeri",
      "A Chalise",
      "M K Gobbert",
      "S W Peterson",
      "J C Polf",
      "L Ren"
    ],
    "abstract": "Objective. Prompt gamma (PG) imaging is a promising modality for proton dose verification. Currently, there is a lack of effective tools to investigate the entire PG imaging process in patient anatomy, from PG emission to camera detection and image reconstruction, to evaluate and optimize its efficacy for dose verification in proton therapy.Approach. To address this gap, we developed a Monte-Carlo package, POLARIS J Monte Carlo (PJ-MC), that simulates the entire PG emission and imaging workflow in patient anatomy. We utilized Geant4 classes and G4-ancillary tools, employing the DCMTK external tool with G4PhantomParameterisation to convert patient CT data into voxelized geometries. Proton beams were modeled based on medical physics commissioning data. A novel two-stage POLARIS-J3 Compton-Camera was simulated under the patient couch for recording total, double, and triple scattered PG signals. Proton maximum range calculations from the PJ-MC are compared with dose calculations from a clinical treatment planning system. The detected PG signals data in the simulation were used to reconstruct PG images using Kernel- Weighted-Back-Projection algorithm.Main results. Analysis of gamma energy distribution showed a decay pattern with clear emission lines from nuclear reactions involving oxygen, carbon, nitrogen, and calcium. Neutron-induced reactions contribute significantly less-by an order of magnitude-compared to proton-induced reactions in various tissues. Mean absolute percentage error analysis showed that PG range verification was more stable when considering the range at 80%or 50%ofDmax, as opposed to the range at theDmax, where energy gating slightly improves accuracy but may reduce localization due to photon loss. Results showed that patient anatomy can impact the location of hot spot in the PG images, affecting its accuracy for localizing Bragg peak.Significance. In summary, our simulation package provides additional insights into PG emission and imaging in patient anatomy and serves as a robust tool for evaluating and optimizing PG imaging, enhancing its precision for dose verification in proton therapy.",
    "abstract_zh": "**翻译：**<br><br>**目的：** 即发伽马（PG）成像是一种有前景的质子剂量验证方法。目前，缺乏有效的工具来研究患者解剖结构中的整个PG成像过程，从PG发射到相机探测和图像重建，以评估和优化其在质子治疗中剂量验证的有效性。<br><br>**方法：** 为了弥补这一空白，我们开发了一个蒙特卡洛软件包，POLARIS J Monte Carlo (PJ-MC)，它可以模拟患者解剖结构中的整个PG发射和成像流程。我们利用Geant4类和G4辅助工具，并使用带有G4PhantomParameterisation的DCMTK外部工具将患者CT数据转换为体素化几何模型。质子束基于医学物理调试数据进行建模。在患者治疗床下方模拟了一个新型的两级POLARIS-J3康普顿相机，用于记录总散射、双散射和三散射PG信号。将PJ-MC计算的质子最大射程与临床治疗计划系统计算的剂量进行比较。模拟中检测到的PG信号数据被用于使用核权重反投影算法重建PG图像。<br><br>**主要结果：** 伽马能量分布分析显示出衰减模式，并显示了来自涉及氧、碳、氮和钙的核反应的清晰发射线。中子诱导的反应与质子诱导的反应相比，在各种组织中的贡献明显较小（一个数量级）。平均绝对百分比误差分析表明，在考虑80%或50%Dmax处的射程时，PG射程验证更加稳定，而不是在Dmax处的射程。在Dmax处，能量窗控略微提高了精度，但可能因光子损失而降低定位精度。结果表明，患者解剖结构会影响PG图像中热点的位置，从而影响其定位布拉格峰的准确性。<br><br>**意义：** 总之，我们的模拟软件包提供了关于患者解剖结构中PG发射和成像的额外见解，并为评估和优化PG成像提供了一个强大的工具，从而提高其在质子治疗中剂量验证的精确度。",
    "summary_zh": "该研究开发了一个蒙特卡洛模拟软件包PJ-MC，用于模拟患者体内质子治疗中的即发伽马(PG)发射和成像过程，以评估和优化PG成像在剂量验证方面的效果。该软件包能够模拟从CT数据转换、质子束建模、PG信号产生与探测到图像重建的整个流程。研究发现，在80%或50%Dmax处的射程验证更稳定，患者解剖结构会影响PG图像热点位置，从而影响布拉格峰的定位精度。该模拟工具为深入理解PG成像过程和提高其在质子治疗剂量验证中的精度提供了重要帮助。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/addf0d",
    "link": "https://doi.org/10.1088/1361-6560/addf0d"
  },
  {
    "title": "Machine learning positioning algorithms for long semi-monolithic scintillator PET detectors.",
    "authors": [
      "Samuel Mungai Kinyanjui",
      "Zhonghua Kuang",
      "Zheng Liu",
      "Ning Ren",
      "Yongfeng Yang"
    ],
    "abstract": "Objective.In this work, machine learning positioning algorithms are developed to improve the spatial resolutions of the semi-monolithic scintillator detectors in both monolithic (y) and depth of interaction (z) directions.Approach.Two long semi-monolithic scintillator detectors consisting of 12 lutetium yttrium oxyorthosilicate (LYSO) slabs of 0.96 × 56 × 10 mm3and 14 LYSO slabs of 0.81 × 56 × 10 mm3were manufactured. The scintillator arrays were read out by a 4 × 16 silicon photomultiplier array. 27 × 5 (y, z) positions of each detector were irradiated via a collimated22Na pencil beam. Extreme gradient boosting (XGBoost) machine learning model was used to predict the interaction positions foryandz. The genetic algorithm (GA) or particle swarm optimization (PSO) algorithm was used to optimize hyperparameters for the XGBoost model. The results of the machine learning positioning algorithms were compared to analytical positioning methods.Main results.The GA and PSO algorithms provided similar results. Compared to the analytical methods, the machine learning positioning methods improved bothyandzspatial resolutions especially at both ends of the detectors. The averageyspatial resolutions using the machine learning positioning methods were 0.92 ± 0.41 mm and 0.94 ± 0.44 mm as compared to those obtained with the squared center of gravity method of 1.38 ± 0.23 mm and 1.39 ± 0.25 mm for the two detectors, respectively. The averagezspatial resolutions obtained with the machine learning positioning methods were 1.67 ± 0.41 mm and 1.68 ± 0.45 mm as compared to those obtained with inverse standard deviation method of 2.09 ± 0.82 mm and 2.14 ± 0.81 mm for the two detectors, respectively.Significance.With the machine learning positioning algorithms, the semi-monolithic scintillator detectors with submillimeter slab thickness evaluated in this work provide less than 1 mmyspatial resolution and less than 2 mmzspatial resolution.",
    "abstract_zh": "**翻译：**<br><br>**目标：** 本文旨在开发机器学习定位算法，以提高半单片闪烁体探测器在单片方向 (y) 和深度方向 (z) 上的空间分辨率。<br><br>**方法：** 制造了两个长条半单片闪烁体探测器，分别由 12 个尺寸为 0.96 × 56 × 10 mm³ 和 14 个尺寸为 0.81 × 56 × 10 mm³ 的钇铝石榴石钇 (LYSO) 板组成。闪烁体阵列由一个 4 × 16 硅光电倍增管阵列读出。 使用准直的 <sup>22</sup>Na 笔形束照射每个探测器的 27 × 5 (y, z) 个位置。 采用极限梯度提升 (XGBoost) 机器学习模型来预测 y 和 z 方向上的相互作用位置。 遗传算法 (GA) 或粒子群优化 (PSO) 算法用于优化 XGBoost 模型的超参数。 将机器学习定位算法的结果与解析定位方法进行了比较。<br><br>**主要结果：** 遗传算法和粒子群优化算法提供了相似的结果。 与解析方法相比，机器学习定位方法提高了 y 和 z 方向的空间分辨率，尤其是在探测器的两端。 使用机器学习定位方法获得的平均 y 方向空间分辨率分别为 0.92 ± 0.41 mm 和 0.94 ± 0.44 mm，而使用平方重心法获得的平均 y 方向空间分辨率分别为 1.38 ± 0.23 mm 和 1.39 ± 0.25 mm。 使用机器学习定位方法获得的平均 z 方向空间分辨率分别为 1.67 ± 0.41 mm 和 1.68 ± 0.45 mm，而使用反标准差法获得的平均 z 方向空间分辨率分别为 2.09 ± 0.82 mm 和 2.14 ± 0.81 mm。<br><br>**意义：** 借助机器学习定位算法，本文评估的具有亚毫米级板厚度的半单片闪烁体探测器可提供小于 1 mm 的 y 方向空间分辨率和小于 2 mm 的 z 方向空间分辨率。",
    "summary_zh": "本研究开发了基于XGBoost的机器学习定位算法，并结合遗传算法(GA)或粒子群优化(PSO)算法优化超参数，用于提高半单片LYSO闪烁体探测器的空间分辨率。实验结果表明，相比于传统的解析定位方法，该机器学习方法显著提升了y和z方向的空间分辨率，使得探测器能够实现亚毫米级的y方向分辨率和小于2mm的z方向分辨率。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/addbbe",
    "link": "https://doi.org/10.1088/1361-6560/addbbe"
  },
  {
    "title": "Uncertainty quantification for deep learning-based metastatic lesion segmentation on whole body PET/CT.",
    "authors": [
      "Brayden Schott",
      "Victor Santoro-Fernandes",
      "Žan Klaneček",
      "Scott Perlman",
      "Robert Jeraj"
    ],
    "abstract": "Objective.Deep learning models are increasingly being implemented for automated medical image analysis to inform patient care. Most models, however, lack uncertainty information, without which the reliability of model outputs cannot be ensured. Several uncertainty quantification (UQ) methods exist to capture model uncertainty. Yet, it is not clear which method is optimal for a given task. The purpose of this work was to investigate several commonly used UQ methods for the critical yet understudied task of metastatic lesion segmentation on whole body PET/CT.Approach.59 whole body68Ga-DOTATATE PET/CT images of patients undergoing theranostic treatment of metastatic neuroendocrine tumors were used in this work. A 3D U-Net was trained for lesion segmentation following five-fold cross validation. Uncertainty measures derived from four UQ methods-probability entropy, Monte Carlo dropout, deep ensembles, and test time augmentation-were investigated. Each uncertainty measure was assessed across four quantitative evaluations: (1) its ability to detect artificially degraded image data at low, medium, and high degradation magnitudes; (2) to detect false-positive (FP) predicted regions; (3) to recover false-negative (FN) predicted regions; and (4) to establish correlations with model biomarker extraction and segmentation performance metrics.Mainresults.Test time augmentation and probability entropy respectively achieved the highest and lowest degraded image detection at low (AUC = 0.54 vs. 0.68), medium (AUC = 0.70 vs. 0.82), and high (AUC = 0.83 vs. 0.90) degradation magnitudes. For detecting FPs, all UQ methods achieve strong performance, with AUC values ranging narrowly between 0.77 and 0.81. FN region recovery performance was strongest for test time augmentation and weakest for probability entropy. Performance for the correlation analysis was mixed, where the strongest performance was achieved by test time augmentation for SUVtotalcapture (ρ= 0.57) and segmentation Dice coefficient (ρ= 0.72), by Monte Carlo dropout for SUVmeancapture (ρ= 0.35), and by probability entropy for segmentation cross entropy (ρ= 0.96).Significance.Overall, test time augmentation demonstrated superior UQ performance and is recommended for use in metastatic lesion segmentation task. It also offers the advantage of being post hoc and computationally efficient. In contrast, probability entropy performed the worst, highlighting the need for advanced UQ approaches for this task.",
    "abstract_zh": "**翻译：**<br><br>**目的。** 深度学习模型越来越多地被应用于医学图像的自动分析，以辅助患者的诊疗。然而，大多数模型缺乏不确定性信息，这导致模型输出的可靠性无法得到保证。目前存在多种不确定性量化（UQ）方法来捕获模型的不确定性。但是，尚不清楚哪种方法对于特定任务是最优的。本研究的目的是针对全身PET/CT上转移性病灶分割这一关键但研究不足的任务，调查几种常用的UQ方法。<br><br>**方法。** 本研究使用了59例接受转移性神经内分泌肿瘤放射性核素治疗的患者的全身68Ga-DOTATATE PET/CT图像。 训练了一个3D U-Net用于病灶分割，并进行了五折交叉验证。研究了四种UQ方法（概率熵、蒙特卡洛dropout、深度集成和测试时增强）导出的不确定性度量。通过四项定量评估对每种不确定性度量进行了评估：(1) 其在低、中、高退化幅度下检测人为退化图像数据的能力；(2) 检测假阳性（FP）预测区域的能力；(3) 恢复假阴性（FN）预测区域的能力；(4) 建立与模型生物标志物提取和分割性能指标之间的相关性。<br><br>**主要结果。** 测试时增强和概率熵分别在低（AUC = 0.68 vs. 0.54）、中（AUC = 0.82 vs. 0.70）和高（AUC = 0.90 vs. 0.83）退化幅度下实现了最高和最低的退化图像检测能力。在检测FP方面，所有UQ方法都表现出强大的性能，AUC值范围狭窄，介于0.77和0.81之间。对于FN区域恢复性能，测试时增强最强，而概率熵最弱。相关性分析的性能喜忧参半，其中测试时增强在SUVtotalcapture（ρ= 0.57）和分割Dice系数（ρ= 0.72）上表现最强，蒙特卡洛dropout在SUVmeancapture（ρ= 0.35）上表现最强，而概率熵在分割交叉熵（ρ= 0.96）上表现最强。<br><br>**重要性。** 总体而言，测试时增强表现出卓越的UQ性能，建议用于转移性病灶分割任务。它还具有后验和计算高效的优点。相比之下，概率熵表现最差，突出了针对此任务采用高级UQ方法的需求。",
    "summary_zh": "本研究评估了四种不确定性量化(UQ)方法在全身PET/CT转移性病灶分割任务中的性能。结果表明，测试时增强方法在检测退化图像、恢复假阴性区域以及与生物标志物和分割性能指标相关性方面表现优异，并且计算高效，推荐用于该任务。而概率熵方法表现最差，提示需要更先进的UQ方法。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/add9df",
    "link": "https://doi.org/10.1088/1361-6560/add9df"
  },
  {
    "title": "Predicting and monitoring response to head and neck cancer radiotherapy using multimodality imaging and radiobiological digital twin simulations.",
    "authors": [
      "Eric Aliotta",
      "Jeho Jeong",
      "Ramesh Paudyal",
      "Milan Grkovski",
      "Bill Diplas",
      "James Han",
      "Vaios Hatzoglou",
      "Michalis Aristophanous",
      "Nadeem Riaz",
      "Heiko Schöder",
      "Nancy Y Lee",
      "Amita Shukla-Dave",
      "Joseph O Deasy"
    ],
    "abstract": "Objective.To predict radiotherapy treatment response for head and neck cancer (HNC) using multimodality imaging and personalized radiobiological modeling.Approach.A mechanistic radiobiological model was combined with multi-modality imaging data from diffusion weighted-magnetic resonance imaging and positron emission tomography scans with [18F]Fluorodeoxyglucose (FDG) and [18F]Fluoromisonidazole (FMISO) tracers to develop personalized treatment response models for human papilloma virus associated HNC patients undergoing chemo-radiotherapy. Models were initialized to incorporate patient-specific imaging and updated to reflect longitudinal measurements of nodal gross tumor volume throughout treatment. Prediction accuracy was assessed based on mean absolute error (MAE) of weekly volume predictions and in predicting locoregional recurrence (LRR) following treatment.Main results.Personalized modeling based on pretreatment imaging significantly improved longitudinal volume prediction accuracy and correlation with measurement compared with a generic population model (MAE = 23.4 ± 10.0% vs 24.9 ± 9.0%,p= 0.002 on pairedt-test,R= 0.82 vs 0.72). Adding volume measurements from weeks 1 and 2 further improved prediction accuracy for subsequent weeks (MAE = 12.5 ± 8.1%, 10.7 ± 9.9%). When incorporating feedback with longitudinal measurements, penalizing large deviations from pretreatment model parameters using a variational regularization method was necessary to maintain model stability. Model-predicted volumes based on baseline + week-1 information significantly improved LRR prediction compared with week-1 volume data alone (area under the curve, AUC = 0.83 vs 0.77,p= 0.03) and was similar to prediction using week-3 volume data (AUC = 0.83 vs 0.85,p= non-significant).Significance.The proposed approach, which integrates clinical imaging and radiobiological principles, could be a basis to guide pretreatment prescription personalization as well as on-treatment adaptations.",
    "abstract_zh": "**翻译：**<br><br>**目的：** 旨在利用多模态影像和个体化放射生物学建模预测头颈癌（HNC）的放射治疗响应。<br><br>**方法：** 将一个机制性的放射生物学模型与来自弥散加权磁共振成像（diffusion weighted-magnetic resonance imaging）和正电子发射断层扫描（positron emission tomography scans）的多模态影像数据相结合，其中正电子发射断层扫描使用了[18F]氟代脱氧葡萄糖（FDG）和[18F]氟米索硝唑（FMISO）示踪剂，从而为接受同步放化疗的人乳头瘤病毒相关头颈癌患者开发个体化的治疗响应模型。模型的初始化结合了患者特异性的影像信息，并根据治疗过程中淋巴结肿瘤总体积的纵向测量数据进行更新。基于每周体积预测的平均绝对误差（MAE）以及治疗后局部区域复发（LRR）的预测来评估预测准确性。<br><br>**主要结果：** 与通用人群模型相比，基于治疗前影像的个体化建模显著提高了纵向体积预测的准确性和与测量的相关性（配对t检验，MAE = 23.4 ± 10.0% vs 24.9 ± 9.0%，p= 0.002，R= 0.82 vs 0.72）。添加来自第1周和第2周的体积测量数据进一步提高了后续几周的预测准确性（MAE = 12.5 ± 8.1%, 10.7 ± 9.9%）。当结合纵向测量数据进行反馈时，必须采用变分正则化方法来惩罚与治疗前模型参数的较大偏差，以维持模型的稳定性。与仅使用第1周体积数据相比，基于基线+第1周信息的模型预测体积显著提高了LRR预测（曲线下面积，AUC = 0.83 vs 0.77，p= 0.03），并且与使用第3周体积数据进行预测的结果相似（AUC = 0.83 vs 0.85，p= 无显著性）。<br><br>**意义：** 提出的方法整合了临床影像和放射生物学原理，可以为指导治疗前处方个体化以及治疗中适应性调整提供基础。",
    "summary_zh": "本研究结合多模态影像（MRI和PET）与个体化放射生物学模型，预测人乳头瘤病毒相关头颈癌患者放化疗的治疗响应。结果表明，与通用模型相比，基于治疗前影像的个体化模型能更准确地预测肿瘤体积变化，且早期（第1、2周）的体积测量数据能进一步提升预测准确性。该模型还能有效预测局部区域复发风险。该方法有望指导个体化治疗方案的设计与调整。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/add9de",
    "link": "https://doi.org/10.1088/1361-6560/add9de"
  },
  {
    "title": "Whole-body CT-to-PET synthesis using a customized transformer-enhanced GAN.",
    "authors": [
      "Bangyan Xu",
      "Ziwei Nie",
      "Jian He",
      "Aimei Li",
      "Ting Wu"
    ],
    "abstract": "Background. Positron emission tomography with 2-deoxy-2-[fluorine-18]fluoro-D-glucose integrated with computed tomography (18F-FDG PET-CT) is a multi-modality medical imaging technique widely used for screening and diagnosis of lesions and tumors, in which, CT can provide detailed anatomical structures, while PET can show metabolic activities. Nevertheless, it has disadvantages such as long scanning time, high cost, and relatively high radiation doses.Purpose. We propose a deep learning model for the whole-body CT-to-PET synthesis task, generating high-quality synthetic PET images that are comparable to real ones in both clinical relevance and diagnostic value.Material. We collect 102 pairs of 3D CT and PET scans, which are sliced into 27 240 pairs of 2D CT and PET images (training: 21,855 pairs, validation: 2810 pairs, testing: 2575 pairs).Methods. We propose a transformer-enhanced generative adversarial network (GAN) for whole-body CT-to-PET synthesis task. The CPGAN model uses residual blocks and fully connected transformer residual blocks to capture both local features and global contextual information. A customized loss function incorporating structural consistency is designed to improve the quality of synthesized PET images.Results. Both quantitative and qualitative evaluation results demonstrate effectiveness of the CPGAN model. The mean and standard variance of NRMSE, PSNR and SSIM values on test set are(16.90±12.27)×10-4,28.71±2.67and0.926±0.033, respectively, outperforming other seven state-of-the-art models. Three radiologists independently and blindly evaluated and gave subjective scores to 100 randomly chosen PET images (50 real and 50 synthetic). By Wilcoxon signed rank test, there are no statistical differences between the synthetic PET images and the real ones.Conclusions. Despite the inherent limitations of CT images to directly reflect biological information of metabolic tissues, CPGAN model effectively synthesizes satisfying PET images from CT scans, which has potential in reducing the reliance on actual PET-CT scans.",
    "abstract_zh": "**翻译：**<br><br>背景：正电子发射断层扫描结合计算机断层扫描（18F-FDG PET-CT）是一种多模态医学成像技术，广泛应用于病灶和肿瘤的筛查和诊断。其中，CT能够提供详细的解剖结构，而PET能够显示代谢活动。然而，它也存在一些缺点，例如扫描时间长、成本高以及相对较高的辐射剂量。<br><br>目的：我们提出了一种深度学习模型，用于全身CT到PET的合成任务，旨在生成高质量的合成PET图像，使其在临床相关性和诊断价值方面与真实图像相当。<br><br>材料：我们收集了102对3D CT和PET扫描图像，并将其切片为27240对2D CT和PET图像（训练集：21855对，验证集：2810对，测试集：2575对）。<br><br>方法：我们提出了一种transformer增强的生成对抗网络（GAN），用于全身CT到PET的合成任务。该CPGAN模型使用残差块和全连接transformer残差块来捕获局部特征和全局上下文信息。我们设计了一个定制的损失函数，其中包含结构一致性，以提高合成PET图像的质量。<br><br>结果：定量和定性评估结果均表明CPGAN模型的有效性。在测试集上，NRMSE、PSNR和SSIM值的均值和标准差分别为(16.90±12.27)×10-4、28.71±2.67和0.926±0.033，优于其他七个最先进的模型。三位放射科医师独立且盲法地评估了随机选择的100张PET图像（50张真实图像和50张合成图像），并给出了主观评分。通过Wilcoxon符号秩检验，合成PET图像和真实图像之间没有统计学差异。<br><br>结论：尽管CT图像在直接反映代谢组织的生物学信息方面存在固有局限性，但CPGAN模型能够有效地从CT扫描合成令人满意的PET图像，这具有降低对实际PET-CT扫描依赖性的潜力。",
    "summary_zh": "该研究提出了一种名为CPGAN的深度学习模型，利用Transformer增强的生成对抗网络，从CT图像合成高质量的PET图像。实验结果表明，合成的PET图像在质量和诊断价值上与真实PET图像相当，并且经过放射科医师的评估，二者之间没有显著的统计学差异。该模型有潜力减少对实际PET-CT扫描的依赖性，从而降低成本、缩短扫描时间和减少辐射剂量。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/add8dd",
    "link": "https://doi.org/10.1088/1361-6560/add8dd"
  },
  {
    "title": "Generation of synthetic CT from MRI for MRI-based attenuation correction of brain PET images using radiomics and machine learning.",
    "authors": [
      "Amin Hoseinipourasl",
      "Gholam-Ali Hossein-Zadeh",
      "Peyman Sheikhzadeh",
      "Hossein Arabalibeik",
      "Shaghayegh Karimi Alavijeh",
      "Habib Zaidi",
      "Mohammad Reza Ay"
    ],
    "abstract": "BACKGROUND: Accurate quantitative PET imaging in neurological studies requires proper attenuation correction. MRI-guided attenuation correction in PET/MRI remains challenging owing to the lack of direct relationship between MRI intensities and linear attenuation coefficients.\nPURPOSE: This study aims at generating accurate patient-specific synthetic CT volumes, attenuation maps, and attenuation correction factor (ACF) sinograms with continuous values utilizing a combination of machine learning algorithms, image processing techniques, and voxel-based radiomics feature extraction approaches.\nMETHODS: Brain MR images of ten healthy volunteers were acquired using IR-pointwise encoding time reduction with radial acquisition (IR-PETRA) and VIBE-Dixon techniques. synthetic CT (SCT) images, attenuation maps, and attenuation correction factors (ACFs) were generated using the LightGBM, a fast and accurate machine learning algorithm, from the radiomics-based and image processing-based feature maps of MR images. Additionally, ultra-low-dose CT images of the same volunteers were acquired and served as the standard of reference for evaluation. The SCT images, attenuation maps, and ACF sinograms were assessed using qualitative and quantitative evaluation metrics and compared against their corresponding reference images, attenuation maps, and ACF sinograms.\nRESULTS: The voxel-wise and volume-wise comparison between synthetic and reference CT images yielded an average mean absolute error of 60.75 ± 8.8 HUs, an average structural similarity index of 0.88 ± 0.02, and an average peak signal-to-noise ratio of 32.83 ± 2.74 dB. Additionally, we compared MRI-based attenuation maps and ACF sinograms with their CT-based counterparts, revealing average normalized mean absolute errors of 1.48% and 1.33%, respectively.\nCONCLUSION: Quantitative assessments indicated higher correlations and similarities between LightGBM-synthesized CT and Reference CT images. Moreover, the cross-validation results showed the possibility of producing accurate SCT images, MRI-based attenuation maps, and ACF sinograms. This might spur the implementation of MRI-based attenuation correction on PET/MRI and dedicated brain PET scanners with lower computational time using CPU-based processors.",
    "abstract_zh": "**翻译：**<br><br>**背景：** 在神经系统研究中，准确的定量PET成像需要适当的衰减校正。PET/MRI中基于MRI引导的衰减校正仍然具有挑战性，因为MRI强度与线性衰减系数之间缺乏直接关系。<br><br>**目的：** 本研究旨在结合机器学习算法、图像处理技术和基于体素的放射组学特征提取方法，生成准确的、个体化的、连续值的合成CT (SCT) 体数据、衰减图和衰减校正因子 (ACF) 正弦图。<br><br>**方法：** 使用IR-PETRA (IR-pointwise encoding time reduction with radial acquisition) 和VIBE-Dixon技术获取了10名健康志愿者的脑部MR图像。利用快速且准确的机器学习算法LightGBM，从MR图像的基于放射组学和图像处理的特征图中生成合成CT (SCT) 图像、衰减图和衰减校正因子 (ACFs)。此外，还获取了相同志愿者的超低剂量CT图像，作为评估的标准参考。使用定性和定量评估指标对SCT图像、衰减图和ACF正弦图进行评估，并将其与相应的参考图像、衰减图和ACF正弦图进行比较。<br><br>**结果：** 合成CT图像和参考CT图像之间的逐体素和逐体积比较显示，平均绝对误差为60.75 ± 8.8 HUs，平均结构相似性指数为0.88 ± 0.02，平均峰值信噪比为32.83 ± 2.74 dB。此外，我们将基于MRI的衰减图和ACF正弦图与基于CT的对应图进行比较，显示平均归一化平均绝对误差分别为1.48%和1.33%。<br><br>**结论：** 定量评估表明，LightGBM合成的CT图像与参考CT图像之间具有较高的相关性和相似性。此外，交叉验证结果表明，可以生成准确的SCT图像、基于MRI的衰减图和ACF正弦图。这可能会推动在PET/MRI和专用脑PET扫描仪上实施基于MRI的衰减校正，并使用基于CPU的处理器降低计算时间。",
    "summary_zh": "本研究利用LightGBM机器学习算法，结合放射组学和图像处理技术，从MRI图像中生成高质量的合成CT图像、衰减图和衰减校正因子正弦图。实验结果表明，生成的合成CT图像与参考CT图像高度相似，衰减图和衰减校正因子正弦图的误差很小，为PET/MRI和脑PET扫描仪中实现基于MRI的衰减校正提供了一种有效方法，并有望降低计算成本。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17867",
    "link": "https://doi.org/10.1002/mp.17867"
  },
  {
    "title": "Impact of tracer uptake rate on quantification accuracy of myocardial blood flow in PET: A simulation study.",
    "authors": [
      "Xiaotong Hong",
      "Amirhossein Sanaat",
      "Yazdan Salimi",
      "René Nkoulou",
      "Hossein Arabi",
      "Lijun Lu",
      "Habib Zaidi"
    ],
    "abstract": "BACKGROUND: Cardiac perfusion PET is commonly used to assess ischemia and cardiovascular risk, which enables quantitative measurements of myocardial blood flow (MBF) through kinetic modeling. However, the estimation of kinetic parameters is challenging due to the noisy nature of short dynamic frames and limited sample data points.\nPURPOSE: This work aimed to investigate the errors in MBF estimation in PET through a simulation study and to evaluate different parameter estimation approaches, including a deep learning (DL) method.\nMATERIALS AND METHODS: Simulated studies were generated using digital phantoms based on cardiac segmentations from 55 clinical CT images. We employed the irreversible 2-tissue compartmental model and simulated dynamic 13N-ammonia PET scans under both rest and stress conditions (220 cases each). The simulations covered a rest K1 range of 0.6 to 1.2 and a stress K1 range of 1.2 to 3.6 (unit: mL/min/g) in the myocardium. A transformer-based DL model was trained on the simulated dataset to predict parametric images (PIMs) from noisy PET image frames and was validated using 5-fold cross-validation. We compared the DL method with the voxel-wise nonlinear least squares (NLS) fitting applied to the dynamic images, using either Gaussian filter (GF) smoothing (GF-NLS) or a dynamic nonlocal means (DNLM) algorithm for denoising (DNLM-NLS). Two patients with coronary CT angiography (CTA) and fractional flow reserve (FFR) were enrolled to test the feasibility of applying DL models on clinical PET data.\nRESULTS: The DL method showed clearer image structures with reduced noise compared to the traditional NLS-based methods. In terms of mean absolute relative error (MARE), as the rest K1 values increased from 0.6 to 1.2 mL/min/g, the overall bias in myocardium K1 estimates decreased from approximately 58% to 45% for the NLS-based methods while the DL method showed a reduction in MARE from 42% to 18%. For stress data, as the stress K1 decreased from 3.6 to 1.2 mL/min/g, the MARE increased from 30% to 70% for the GF-NLS method. In contrast, both the DNLM-NLS (average: 42%) and the DL methods (average: 20%) demonstrated significantly smaller MARE changes as stress K1 varied. Regarding the regional mean bias (±standard deviation), the GF-NLS method had a bias of 6.30% (±8.35%) of rest K1, compared to 1.10% (±8.21%) for DNLM-NLS and 6.28% (±14.05%) for the DL method. For the stress K1, the GF-NLS showed a mean bias of 10.72% (±9.34%) compared to 1.69% (±8.82%) for DNLM-NLS and -10.55% (±9.81%) for the DL method.\nSIGNIFICANCE: This study showed that an increase in the tracer uptake rate (K1) corresponded to improved accuracy and precision in MBF quantification, whereas lower tracer uptake resulted in higher noise in dynamic PET and poorer parameter estimates. Utilizing denoising techniques or DL approaches can mitigate noise-induced bias in PET parametric imaging.",
    "abstract_zh": "**背景：** 心肌灌注PET常用于评估缺血和心血管风险，它可以通过动力学建模对心肌血流量（MBF）进行定量测量。然而，由于短时程动态帧的噪声性质以及有限的样本数据点，动力学参数的估计具有挑战性。<br><br>**目的：** 本研究旨在通过模拟研究来调查PET中MBF估计的误差，并评估不同的参数估计方法，包括一种深度学习（DL）方法。<br><br>**材料与方法：** 基于55例临床CT图像的心脏分割，使用数字体模生成模拟研究数据。我们采用了不可逆的二室模型，并模拟了静息和负荷两种状态下的动态13N-氨PET扫描（每种状态各220例）。模拟涵盖了心肌中静息K1范围为0.6至1.2，负荷K1范围为1.2至3.6（单位：mL/min/g）。在模拟数据集上训练了一个基于Transformer的DL模型，以从噪声PET图像帧预测参数图像（PIMs），并使用5倍交叉验证进行验证。我们将DL方法与应用于动态图像的逐体素非线性最小二乘（NLS）拟合进行比较，NLS拟合使用高斯滤波（GF）平滑（GF-NLS）或动态非局部均值（DNLM）算法进行去噪（DNLM-NLS）。纳入了两名接受了冠状动脉CT血管造影（CTA）和血流储备分数（FFR）检查的患者，以测试将DL模型应用于临床PET数据的可行性。<br><br>**结果：** 与传统的基于NLS的方法相比，DL方法显示出更清晰的图像结构，并降低了噪声。在平均绝对相对误差（MARE）方面，随着静息K1值从0.6增加到1.2 mL/min/g，基于NLS的方法心肌K1估计的总体偏差从大约58%降低到45%，而DL方法的MARE则从42%降低到18%。对于负荷数据，随着负荷K1从3.6降低到1.2 mL/min/g，GF-NLS方法的MARE从30%增加到70%。相比之下，DNLM-NLS（平均：42%）和DL方法（平均：20%）在负荷K1变化时表现出明显更小的MARE变化。关于区域平均偏差（±标准差），GF-NLS方法的静息K1偏差为6.30%（±8.35%），而DNLM-NLS为1.10%（±8.21%），DL方法为6.28%（±14.05%）。对于负荷K1，GF-NLS显示的平均偏差为10.72%（±9.34%），DNLM-NLS为1.69%（±8.82%），DL方法为-10.55%（±9.81%）。<br><br>**意义：** 这项研究表明，示踪剂摄取率（K1）的增加对应于MBF量化准确性和精度的提高，而较低的示踪剂摄取导致动态PET中更高的噪声和较差的参数估计。利用去噪技术或DL方法可以减轻PET参数成像中噪声引起的偏差。",
    "summary_zh": "该研究利用模拟数据评估了深度学习(DL)在心肌灌注PET血流参数估计中的性能，并与传统非线性最小二乘法(NLS)结合不同去噪方法进行了比较。结果表明，DL方法在降低噪声、提高K1估计准确性方面优于传统方法，尤其是在低示踪剂摄取情况下。该研究强调了去噪技术和DL在改善PET定量成像中的重要性。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17871",
    "link": "https://doi.org/10.1002/mp.17871"
  },
  {
    "title": "Exploiting network optimization stability for enhanced PET image denoising using deep image prior.",
    "authors": [
      "Fumio Hashimoto",
      "Kibo Ote",
      "Yuya Onishi",
      "Hideaki Tashima",
      "Go Akamatsu",
      "Yuma Iwao",
      "Miwako Takahashi",
      "Taiga Yamaya"
    ],
    "abstract": "Objective. Positron emission tomography (PET) is affected by statistical noise due to constraints on tracer dose and scan duration, impacting both diagnostic performance and quantitative accuracy. While deep learning-based PET denoising methods have been used to improve image quality, they may introduce over-smoothing, which can obscure critical structural details and compromise quantitative accuracy. We propose a method for making a deep learning solution more reliable and apply it to the conditional deep image prior (DIP).Approach. We introduce the idea ofstability informationin the optimization process of conditional DIP, enabling the identification of unstable regions within the network's optimization trajectory. Our method incorporates a stability map, which is derived from multiple intermediate outputs of a moderate neural network at different optimization steps. The final denoised PET image is then obtained by computing a linear combination of the DIP output and the original reconstructed PET image, weighted by the stability map.Main results. We employed eight high-resolution brain PET datasets for comparison. Our method effectively reduces background noise while preserving small structure details in brain [18F]FDG PET images. Comparative analysis demonstrated that our approach outperformed existing methods in terms of peak-to-valley ratio and background noise suppression across various low-dose levels. Additionally, region-of-interest analysis confirmed that the proposed method maintains quantitative accuracy without introducing under- or over-estimation. Furthermore, we applied our method to full-dose PET data to assess its impact on image quality. The results revealed that the proposed method significantly reduced background noise while preserving the peak-to-valley ratio at a level comparable to that of unfiltered full-dose PET images.Significance. The proposed method introduces a robust approach to deep learning-based PET denoising, enhancing its reliability and preserving quantitative accuracy. Furthermore, this strategy can potentially advance performance in high-sensitivity PET scanners and surpass the limit of image quality inherent to PET scanners.",
    "abstract_zh": "**翻译：**<br><br>**目的。** 正电子发射断层扫描（PET）受到统计噪声的影响，这是由于示踪剂剂量和扫描时间的限制所致，从而影响诊断性能和定量准确性。虽然基于深度学习的PET去噪方法已被用于提高图像质量，但它们可能引入过度平滑，这会掩盖关键的结构细节并损害定量准确性。我们提出了一种使深度学习解决方案更可靠的方法，并将其应用于条件深度图像先验（DIP）。<br><br>**方法。** 我们在条件DIP的优化过程中引入了*稳定性信息*的概念，从而能够识别网络优化轨迹中的不稳定区域。我们的方法包含一个稳定性图，该图由中等神经网络在不同优化步骤中的多个中间输出导出。然后，通过计算DIP输出和原始重建PET图像的线性组合来获得最终的去噪PET图像，该线性组合由稳定性图加权。<br><br>**主要结果。** 我们采用了八个高分辨率脑PET数据集进行比较。我们的方法有效地降低了背景噪声，同时保留了脑[18F]FDG PET图像中的小结构细节。对比分析表明，我们的方法在各种低剂量水平下，在峰谷比和背景噪声抑制方面均优于现有方法。此外，感兴趣区域分析证实，所提出的方法保持了定量准确性，而没有引入低估或高估。此外，我们将我们的方法应用于全剂量PET数据，以评估其对图像质量的影响。结果表明，所提出的方法显著降低了背景噪声，同时将峰谷比保持在与未滤波的全剂量PET图像相当的水平。<br><br>**意义。** 所提出的方法为基于深度学习的PET去噪引入了一种稳健的方法，增强了其可靠性并保持了定量准确性。此外，这种策略有可能提高高灵敏度PET扫描仪的性能，并超越PET扫描仪固有的图像质量限制。<br><br>【**总结**】<br><br>本研究提出了一种基于条件深度图像先验(DIP)的PET图像去噪方法，通过引入“稳定性信息”来识别和处理深度学习优化过程中的不稳定区域，从而提高去噪的可靠性和定量准确性。该方法生成一个稳定性图，并据此对DIP输出和原始PET图像进行加权线性组合，得到最终的去噪图像。实验结果表明，该方法在降低背景噪声、保留结构细节和保持定量准确性方面优于现有方法，并且在高灵敏度PET扫描仪的应用中具有潜力。",
    "summary_zh": "",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/add63f",
    "link": "https://doi.org/10.1088/1361-6560/add63f"
  },
  {
    "title": "Patient CT-based simulation study of secondary-electron-bremsstrahlung imaging for range verification in proton therapy: comparison with prompt gamma and PET imaging for simplified proton pencil beam and SOBP irradiation scenarios.",
    "authors": [
      "Takuya Yabe",
      "Munetaka Nitta",
      "Mitsutaka Yamaguchi",
      "Marco Pinto",
      "Naoki Kawachi",
      "Katia Parodi"
    ],
    "abstract": "Objective.Secondary electron bremsstrahlung (SEB) imaging, along with prompt gamma (PG) and positron emission tomography (PET) imaging, has been proposed as anin vivorange verification tool for proton therapy. This study presents the first simulation based on patient computed tomography (CT) data to investigate the feasibility of SEB imaging for range verification in proton therapy, while comparing the characteristics of SEB imaging with those of PG and PET imaging.Approach.A Monte Carlo simulation was performed using patient CT data for the irradiation of monoenergetic pencil beams and spread-out Bragg peak proton beams. The physical characteristics of SEB imaging were analyzed at three different anatomical sites and compared with those of PG and PET imaging.Main results. In all the treatment cases, SEB imaging exhibited higher production rates than PG and PET imaging, particularly in the regions with high CT values along the beam path. Although the SEB signal was more affected by scattering and absorption than the PET or PG signals, sufficient statistical counts for range verification (∼3 × 10-3SEBs/proton) could potentially be detected outside the patient geometry. For pencil beam cases, the SEB and PET fall-offs were located 4-5 mm proximal to the dose fall-off, while the PG fall-off was located 0-1 mm distal to it.Significance.Results suggest that SEB imaging has the potential to offer a real-time range verification tool (by comparing measured and expected images), particularly for treating shallow-seated tumors using proton pencil-beam scanning delivery. Thus, this study represents a significant step towards the clinical application of range verification based on SEB imaging and promotes future efforts in this direction.",
    "abstract_zh": "**翻译：**<br><br>**目的。** 次级电子轫致辐射（SEB）成像，连同瞬发伽马（PG）和正电子发射断层扫描（PET）成像，已被提议作为质子治疗中一种体内射程验证工具。本研究首次基于患者计算机断层扫描（CT）数据进行模拟，以探讨SEB成像用于质子治疗射程验证的可行性，同时比较SEB成像与PG和PET成像的特性。<br><br>**方法。** 使用患者CT数据进行蒙特卡罗模拟，模拟单能笔形束和扩展布拉格峰质子束的照射。在三个不同的解剖部位分析了SEB成像的物理特性，并将其与PG和PET成像的物理特性进行了比较。<br><br>**主要结果。** 在所有治疗案例中，SEB成像的产生率均高于PG和PET成像，尤其是在沿射束路径CT值较高的区域。尽管SEB信号比PET或PG信号更容易受到散射和吸收的影响，但在患者几何体外，仍有可能检测到足够的统计计数用于射程验证（约3 × 10-3 SEBs/质子）。对于笔形束案例，SEB和PET的信号衰减位于剂量衰减近端4-5毫米处，而PG的信号衰减位于剂量衰减远端0-1毫米处。<br><br>**意义。** 结果表明，SEB成像具有提供实时射程验证工具的潜力（通过比较测量图像和预期图像），尤其适用于使用质子笔形束扫描递送治疗浅表肿瘤。因此，本研究代表了基于SEB成像的射程验证临床应用的重要一步，并促进了未来在这方面的努力。",
    "summary_zh": "本研究通过蒙特卡罗模拟，评估了次级电子轫致辐射（SEB）成像在质子治疗射程验证中的可行性，并将其与瞬发伽马（PG）和正电子发射断层扫描（PET）成像进行了比较。结果表明，SEB成像具有更高的信号产生率，尽管散射和吸收影响较大，但仍可检测到足够的统计计数用于射程验证。SEB成像的信号衰减位置与剂量衰减位置存在一定偏差。研究表明SEB成像有望成为一种实时射程验证工具，尤其适用于笔形束扫描治疗浅表肿瘤，并为该方向的进一步研究提供了依据。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/add4b7",
    "link": "https://doi.org/10.1088/1361-6560/add4b7"
  },
  {
    "title": "Instantaneous in vivo distal edge verification in intensity-modulated proton therapy by means of PET imaging.",
    "authors": [
      "Brian Zapien-Campos",
      "Zahra Ahmadi Ganjeh",
      "Giuliano Perotti-Bernardini",
      "Jeffrey Free",
      "Stefan Both",
      "Peter Dendooven"
    ],
    "abstract": "BACKGROUND: Intensity-modulated proton therapy (IMPT) holds promise for improving outcomes in head-and-neck cancer (HNC) patients by enhancing organ-at-risk (OAR) sparing. A key challenge in IMPT is ensuring an accurate dose delivery at the distal edge of the tumor, where the steep dose gradients make treatment precision highly sensitive to uncertainties in both proton range and patient setup. Thus, IMPT conformality is increased by incorporating robust margins in the treatment optimization. However, an increment in the plan robustness could lead to an OAR overdosing. Therefore, an accurate distal edge verification during dose delivery is crucial to increase IMPT conformality by reducing optimization settings in treatment planning.\nPURPOSE: This work aims to evaluate, in a quasi-clinical setting, a novel approach for accurate instantaneous proton beam distal edge verification in IMPT by means of spot-by-spot positron emission tomography (PET) imaging.\nMETHODS: An anthropomorphic head and neck phantom CIRS-731 HN was irradiated at the head and neck region. The targets were defined as 4 cm diameter spheres. A 60-ms delay was introduced between the proton beam spots in order to enable the spot-by-spot coincidence detection of the 511-keV photons resulting from positron annihilation following the positron emission from very short-lived positron-emitting, mainly 12N (T1/2  = 11.0 ms). Additionally, modified irradiations were carried out using solid water slabs of 2 and 5 mm thickness in the beam path to assess the precision of the approach for detecting range deviations. The positron activity range (PAR) was determined from the 50% distal fall-off position of the 1D longitudinal positron activity profile derived from the 2D image reconstructions. Furthermore, Monte Carlo (MC) simulations were performed using an in-house RayStation/GATE MC framework to predict the positron activity images and verify the PAR measurements.\nRESULTS: PAR measurements achieved a precision between 1.5 and 3.6 mm (at 1.5σ clinical level) at the beam spot level within sub-second time scales. Measured PAR shifts of 1.6-2.1  and 4.2--.7 mm were observed with the 2- and 5-mm thickness range shifters, respectively, aligning with the corresponding proton dose range (PDR) shifts of 1.3-1.8 and 3.9-4.3 mm. The simulated PAR agrees with the measured PARs, showing an average range difference of ∼0.4 mm.\nCONCLUSION: This study demonstrated the feasibility of instantaneous distal edge verification using PET imaging by introducing beam spot delays during dose delivery. The findings represent a first step toward the clinical implementation of instantaneous in vivo distal edge verification. The approach contributes to the development of real-time range verification aimed at improving IMPT treatments by mitigating range and setup uncertainties, thereby reducing dose to organs-at-risk and ultimately enhancing patient outcomes.",
    "abstract_zh": "**翻译：**<br><br>背景：调强质子治疗（IMPT）有望通过提高危及器官（OAR）的保护能力，改善头颈部肿瘤（HNC）患者的治疗效果。IMPT的一个关键挑战是确保在肿瘤远端边缘进行精确的剂量递送，因为在肿瘤远端边缘，陡峭的剂量梯度使得治疗精度对质子射程和患者摆位的不确定性高度敏感。因此，IMPT适形性通过在治疗优化中纳入稳健性容差来提高。然而，计划稳健性的增加可能导致危及器官的过量照射。因此，在剂量递送过程中进行精确的远端边缘验证对于通过减少治疗计划中的优化设置来提高IMPT适形性至关重要。<br><br>目的：本研究旨在在准临床环境中，评估一种用于IMPT中精确的瞬时质子束远端边缘验证的新方法，该方法采用逐点正电子发射断层扫描（PET）成像。<br><br>方法：在头颈部区域对一个人体头颈部模型CIRS-731 HN进行了照射。靶区定义为直径4厘米的球体。在质子束点之间引入60毫秒的延迟，以便能够逐点符合检测由于极短寿命的正电子发射体（主要是12N，半衰期=11.0毫秒）发射正电子后发生正电子湮灭而产生的511 keV光子。此外，使用2毫米和5毫米厚度的固体水板在光束路径中进行了修改后的照射，以评估该方法检测射程偏差的精度。正电子活动范围（PAR）由二维图像重建得到的纵向正电子活动曲线50%远端下降位置确定。此外，使用内部RayStation/GATE MC框架进行了蒙特卡罗（MC）模拟，以预测正电子活动图像并验证PAR测量结果。<br><br>结果：PAR测量在亚秒级时间尺度内，在光束点水平上实现了1.5至3.6毫米的精度（在1.5σ临床水平下）。分别使用2毫米和5毫米厚度的射程调节器观察到1.6-2.1毫米和4.2-4.7毫米的PAR偏移，与相应的1.3-1.8毫米和3.9-4.3毫米的质子剂量范围（PDR）偏移一致。模拟的PAR与测量的PAR一致，显示平均范围差异约为0.4毫米。<br><br>结论：本研究证明了通过在剂量递送过程中引入光束点延迟，使用PET成像进行瞬时远端边缘验证的可行性。这些发现代表了瞬时体内远端边缘验证临床实施的第一步。该方法有助于开发旨在通过减轻射程和摆位不确定性来改善IMPT治疗的实时射程验证，从而减少危及器官的剂量，最终改善患者的治疗效果。",
    "summary_zh": "本研究旨在评估一种利用逐点PET成像进行IMPT中瞬时质子束远端边缘验证的新方法。通过对头颈部模型进行照射实验，并辅以蒙特卡罗模拟，结果表明该方法能够以较高的精度（1.5-3.6mm，1.5σ临床水平）在亚秒级时间尺度上验证质子射程，并能有效检测射程偏差。该研究证明了瞬时远端边缘验证的可行性，为实时射程验证的临床应用奠定了基础，有望减少危及器官的剂量，改善患者的治疗效果。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17850",
    "link": "https://doi.org/10.1002/mp.17850"
  },
  {
    "title": "Modeling inter-reader variability in clinical target volume delineation for soft tissue sarcomas using diffusion model.",
    "authors": [
      "Yafei Dong",
      "Thibault Marin",
      "Yue Zhuo",
      "Elie Najem",
      "Arnaud Beddok",
      "Laura Rozenblum",
      "Maryam Moteabbed",
      "Kira Grogg",
      "Fangxu Xing",
      "Jonghye Woo",
      "Yen-Lin E Chen",
      "Ruth Lim",
      "Xiaofeng Liu",
      "Chao Ma",
      "Georges El Fakhri"
    ],
    "abstract": "BACKGROUND: Accurate delineation of the clinical target volume (CTV) is essential in the radiotherapy treatment of soft tissue sarcomas. However, this process is subject to inter-reader variability due to the need for clinical assessment of risk and extent of potential microscopic spread. This can lead to inconsistencies in treatment planning, potentially impacting treatment outcomes. Most existing automatic CTV delineation methods do not account for this variability and can only generate a single CTV for each case.\nPURPOSE: This study aims to develop a deep learning-based technique to generate multiple CTV contours for each case, simulating the inter-reader variability in the clinical practice.\nMETHODS: We employed a publicly available dataset consisting of fluorodeoxyglucose positron emission tomography (FDG-PET), x-ray computed tomography (CT), and pre-contrast T1-weighted magnetic resonance imaging (MRI) scans from 51 patients with soft tissue sarcoma, along with an independent validation set containing five additional patients. An experienced reader drew a contour of the gross tumor volume (GTV) for each patient based on multi-modality images. Subsequently, two additional readers, together with the first one, were responsible for contouring three CTVs in total based on the GTV. We developed a diffusion model-based deep learning method that is capable of generating arbitrary number of different and plausible CTVs to mimic the inter-reader variability in CTV delineation. The proposed model incorporates a separate encoder to extract features from the GTV masks, leveraging the critical role of GTV information in accurate CTV delineation.\nRESULTS: The proposed diffusion model demonstrated superior performance with the highest Dice Index (0.902 compared to values below 0.881 for state-of-the-art models) and the best generalized energy distance (GED) (0.209 compared to values exceeding 0.221 for state-of-the-art models). It also achieved the second-highest recall and precision metrics among the compared ambiguous image segmentation models. Results from both datasets exhibited consistent trends, reinforcing the reliability of our findings. Additionally, ablation studies exploring different model structures and input configurations highlighted the significance of incorporating prior GTV information for accurate CTV delineation.\nCONCLUSIONS: The proposed diffusion model successfully generates multiple plausible CTV contours for soft tissue sarcomas, effectively capturing inter-reader variability in CTV delineation.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17865",
    "link": "https://doi.org/10.1002/mp.17865"
  },
  {
    "title": "Thorax-encompassing multi-modality PET/CT deep learning model for resected lung cancer prognostication: A retrospective, multicenter study.",
    "authors": [
      "Jaryd R Christie",
      "Perrin Romine",
      "Karen Eddy",
      "Delphine L Chen",
      "Omar Daher",
      "Mohamed Abdelrazek",
      "Richard A Malthaner",
      "Mehdi Qiabi",
      "Rahul Nayak",
      "Paul Kinahan",
      "Viswam S Nair",
      "Sarah A Mattonen"
    ],
    "abstract": "BACKGROUND: Patients with early-stage non-small cell lung cancer (NSCLC) typically receive surgery as their primary form of treatment. However, studies have shown that a high proportion of these patients will experience a recurrence after their resection, leading to an increased risk of death. Cancer staging is currently the gold standard for establishing a patient's prognosis and can help clinicians determine patients who may benefit from additional therapy. However, medical images which are used to help determine the cancer stage, have been shown to hold unutilized prognostic information that can augment clinical data and better identify high-risk NSCLC patients. There remains an unmet need for models to incorporate clinical, pathological, surgical, and imaging information, and extend beyond the current staging system to assist clinicians in identifying patients who could benefit from additional therapy immediately after surgery.\nPURPOSE: We aimed to determine whether a deep learning model (DLM) integrating FDG PET and CT imaging from the thoracic cavity along with clinical, surgical, and pathological information can predict NSCLC recurrence-free survival (RFS) and stratify patients into risk groups better than conventional staging.\nMATERIALS AND METHODS: Surgically resected NSCLC patients enrolled between 2009 and 2018 were retrospectively analyzed from two academic institutions (local institution: 305 patients; external validation: 195 patients). The thoracic cavity (including the lungs, mediastinum, pleural interfaces, and thoracic vertebrae) was delineated on the preoperative FDG PET and CT images and combined with each patient's clinical, surgical, and pathological information. Using the local cohort of patients, a multi-modal DLM using these features was built in a training cohort (n = 225), tuned on a validation cohort (n = 45), and evaluated on testing (n = 35) and external validation (n = 195) cohorts to predict RFS and stratify patients into risk groups. The area under the curve (AUC), Kaplan-Meier curves, and log-rank test were used to assess the prognostic value of the model. The DLM's stratification performance was compared to the conventional staging stratification.\nRESULTS: The multi-modal DLM incorporating imaging, pathological, surgical, and clinical data predicted RFS in the testing cohort (AUC = 0.78 [95% CI:0.63-0.94]) and external validation cohort (AUC = 0.66 [95% CI:0.58-0.73]). The DLM significantly stratified patients into high, medium, and low-risk groups of RFS in both the testing and external validation cohorts (multivariable log-rank p < 0.001) and outperformed conventional staging. Conventional staging was unable to stratify patients into three distinct risk groups of RFS (testing: p = 0.94; external validation: p = 0.38). Lastly, the DLM displayed the ability to further stratify patients significantly into sub-risk groups within each stage in the testing (stage I: p = 0.02, stage II: p = 0.03) and external validation (stage I: p = 0.05, stage II: p = 0.03) cohorts.\nCONCLUSION: This is the first study to use multi-modality imaging along with clinical, surgical, and pathological data to predict RFS of NSCLC patients after surgery. The multi-modal DLM better stratified patients into risk groups of poor outcomes when compared to conventional staging and further stratified patients within each staging classification. This model has the potential to assist clinicians in better identifying patients that may benefit from additional therapy.",
    "abstract_zh": "**翻译：**<br><br>背景：早期非小细胞肺癌（NSCLC）患者通常接受手术作为主要治疗方式。然而，研究表明，相当比例的患者在切除术后会复发，从而增加死亡风险。癌症分期是目前确定患者预后的金标准，可以帮助临床医生确定哪些患者可能从额外治疗中获益。然而，用于确定癌症分期的医学图像已被证明含有未被充分利用的预后信息，这些信息可以增强临床数据，从而更好地识别高危NSCLC患者。目前仍迫切需要能够整合临床、病理、手术和影像信息的模型，并超越现有的分期系统，以帮助临床医生识别术后立即可能从额外治疗中获益的患者。<br><br>目的：我们旨在确定一种深度学习模型（DLM），该模型整合了胸腔的FDG PET和CT影像，以及临床、手术和病理信息，是否能比传统分期更好地预测NSCLC的无复发生存期（RFS）并将患者分层为不同的风险组。<br><br>材料与方法：回顾性分析了2009年至2018年间在两家学术机构（本地机构：305例患者；外部验证：195例患者）入组的接受手术切除的NSCLC患者。在术前FDG PET和CT图像上勾画出胸腔（包括肺、纵隔、胸膜界面和胸椎），并结合每位患者的临床、手术和病理信息。使用本地患者队列，在训练队列（n = 225）中构建了一个使用这些特征的多模态DLM，在验证队列（n = 45）中进行调整，并在测试（n = 35）和外部验证（n = 195）队列中进行评估，以预测RFS并将患者分层为风险组。使用曲线下面积（AUC）、Kaplan-Meier曲线和log-rank检验来评估模型的预后价值。将DLM的分层性能与传统分期分层进行比较。<br><br>结果：多模态DLM整合了影像、病理、手术和临床数据，在测试队列（AUC = 0.78 [95% CI: 0.63-0.94]）和外部验证队列（AUC = 0.66 [95% CI: 0.58-0.73]）中预测了RFS。在测试和外部验证队列中，DLM均显著地将患者分层为RFS的高、中、低风险组（多变量log-rank p < 0.001），并且优于传统分期。传统分期无法将患者分层为RFS的三个不同的风险组（测试：p = 0.94；外部验证：p = 0.38）。最后，DLM显示出在测试（I期：p = 0.02，II期：p = 0.03）和外部验证（I期：p = 0.05，II期：p = 0.03）队列中，能够在每个分期内进一步显著地将患者分层为亚风险组的能力。<br><br>结论：这是首个使用多模态影像以及临床、手术和病理数据来预测NSCLC患者术后RFS的研究。与传统分期相比，多模态DLM能更好地将患者分层为预后不良的风险组，并在每个分期分类中进一步对患者进行分层。该模型具有帮助临床医生更好地识别可能从额外治疗中获益的患者的潜力。",
    "summary_zh": "本研究旨在开发一种基于深度学习的多模态模型，该模型整合FDG PET/CT影像、临床、手术和病理数据，以更准确地预测早期NSCLC患者术后的无复发生存期（RFS）并进行风险分层。结果表明，该模型在预测RFS和风险分层方面优于传统分期，能够在不同分期内进一步细化风险分组，有助于识别可能从术后辅助治疗中获益的患者。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17862",
    "link": "https://doi.org/10.1002/mp.17862"
  },
  {
    "title": "Evaluation of a motion correction algorithm in lung cancer PET/CT: Phantom validation and patient studies.",
    "authors": [
      "Ziyang Wang",
      "Jianjing Liu",
      "Di Lu",
      "Guoqing Sui",
      "Yaya Wang",
      "Lina Tong",
      "Xueyao Liu",
      "Yan Zhang",
      "Jie Fu",
      "Wengui Xu",
      "Dong Dai"
    ],
    "abstract": "BACKGROUND: Data-driven gating (DDG) is an emerging technology that can reduce the respiratory motion artifacts in positron emission tomography (PET) images.\nPURPOSE: The aim of this study is to use phantom and patient data to validate the performance of DDG with a motion correction algorithm based on the reconstruct, register, and average (RRA) method.\nMETHODS: A customized motion platform drove the phantom (five spheres with diameters of 10-28 mm) using a periodic motion that had a duration of 3-5 s and amplitudes of 2-4 cm. Normalized ratio of ungated and RRA PET relative to the ground-truth static PET was calculated for RSUVmax, RSUVmean, RSUVpeak, RVolume, and relative contrast-to-noise ratio (RCNR). Additionally, 30 lung cancer patients with 76 lung lesions less than 3 cm in diameter were prospectively studied. The overall image quality of patient examination was scored using a 5-point scale by two radiologists. SUVmax, SUVmean, SUVpeak, volume, and CNR of lesions measured in ungated and RRA PET were compared, and subgroup analysis was conducted.\nRESULTS: In RRA PET images, motion artifacts of the spheres in the phantom were effectively mitigated, regardless of changes in movement amplitudes or duration. For all spheres with different ranges of motion and cycles, RSUVmax, RSUVmean, RSUVpeak, and RCNR increased significantly (p ≤ 0.001) and RVolume decreased significantly (p < 0.001) in RRA PET images. The average radiologist scores of image quality were 3.90 ± 0.86 with RRA PET, and 3.03 ± 1.19 with ungated PET. In RRA PET images, the SUVmax (p < 0.001), SUVmean (p < 0.001), SUVpeak (p < 0.001), and CNR (p < 0.001) of the lesions increased, while the volume (p < 0.001) of the lesions decreased. Δ%SUVmax, Δ%SUVmean, Δ%SUVpeak, and Δ%CNR of the lesions increased by 3.9%, 6.5%, 5.6%, and 4.3%, respectively, while Δ%Volume of the lesions decreased by 18.4%. Subgroup analysis showed that in lesions in the upper and middle lobes, only SUVpeak (p < 0.001) significantly increased by 5.6% in RRA PET, while their volume (p < 0.001) notably decreased by 12.4% (p < 0.001).\nCONCLUSION: DDG integrated with RRA motion correction algorithm can effectively mitigate motion artifacts, thus enhancing the quantification accuracy and visual quality of images in lung cancer PET/CT.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17846",
    "link": "https://doi.org/10.1002/mp.17846"
  },
  {
    "title": "Hepatocellular carcinoma 18F-FDG PET/CT kinetic parameter estimation based on the advantage actor-critic algorithm.",
    "authors": [
      "Jianfeng He",
      "Siming Li",
      "Yiwei Xiong",
      "Yu Yao",
      "Siyu Wang",
      "Sidan Wang",
      "Shaobo Wang"
    ],
    "abstract": "BACKGROUND: Kinetic parameters estimated with dynamic 18F-fluorodeoxyglucose (18F-FDG) positron emission tomography (PET)/computed tomography (CT) help characterize hepatocellular carcinoma (HCC), and deep reinforcement learning (DRL) can improve kinetic parameter estimation.\nPURPOSE: The advantage actor-critic (A2C) algorithm is a DRL algorithm with neural networks that seek the optimal parameters. The aim of this study was to preliminarily assess the role of the A2C algorithm in estimating the kinetic parameters of 18F-FDG PET/CT in patients with HCC.\nMATERIALS AND METHODS: 18F-FDG PET data from 14 liver tissues and 17 HCC tumors obtained via a previously developed, abbreviated acquisition protocol (5-min dynamic PET/CT imaging supplemented with 1-min static imaging at 60 min) were prospectively collected. The A2C algorithm was used to estimate kinetic parameters with a reversible double-input, three-compartment model, and the results were compared with those of the conventional nonlinear least squares (NLLS) algorithm. Fitting errors were compared via the root-mean-square errors (RMSEs) of the time activity curves (TACs).\nRESULTS: Significant differences in K1, k2, k3, k4, fa, and vb according to the A2C algorithm and k3, fa, and vb according to the NLLS algorithm were detected between HCC and normal liver tissues (all p < 0.05). Furthermore, A2C demonstrated superior diagnostic performance over NLLS in terms of k3 and vb (both p < 0.05 in the Delong test). Notably, A2C yielded a smaller fitting error for normal liver tissue (0.62 ± 0.24 vs. 1.04 ± 1.00) and HCC tissue (1.40 ± 0.42 vs. 1.51 ± 0.97) than did NLLS.\nCONCLUSIONS: Compared with the conventional postreconstruction NLLS method, the A2C algorithm can more precisely estimate 18F-FDG kinetic parameters with a reversible double-input, three-compartment model for HCC tumors, attaining better TAC fitting with a lower RMSE.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17851",
    "link": "https://doi.org/10.1002/mp.17851"
  },
  {
    "title": "Predicting [177Lu]Lu-DOTA-TATE dosimetry by using pre-therapy [68Ga]Ga-DOTA-TATE PET/CT and biomarkers in patient with neuroendocrine tumors.",
    "authors": [
      "Hongxing Yang",
      "Ming Qi",
      "Zhihao Chen",
      "Fei Liu",
      "Junyan Xu",
      "Xiaoping Xu",
      "Qing Kong",
      "Jianping Zhang",
      "Shaoli Song"
    ],
    "abstract": "BACKGROUND: Lutetium-177 DOTA-TATE peptide receptor radionuclide therapy (PRRT) is an established and effective treatment modality for patients with metastatic neuroendocrine tumors (NETs).\nPURPOSE: This study aims to predict patient-absorbed doses from [177Lu]Lu-DOTA-TATE PRRT in the liver, kidney and lesion by utilizing patient-specific absorbed doses from pre-therapeutic [68Ga]Ga-DOTA-TATE PET/CT.\nMETHODS: Before the treatment of cycle 1, 11 patients with NETs underwent PET/CT scans at 0.5, 1.0, 2.0 and 4.0 h after the injection of [68Ga]Ga-DOTA-TATE. Patients then received [177Lu]Lu-DOTA-TATE PRRT and underwent SPECT/CT scans at 4, 24, 96, and 168 h post-administration. The segmentations and dosimetry were performed by using a professional software. The linear regression model used the absorbed doses from [68Ga]Ga-DOTA-TATE alone as the predictor variable. The multiple linear regression model used the absorbed doses from [68Ga]Ga-DOTA-TATE and the relevant clinical biomarkers as the predictor variables.\nRESULTS: The mean absorbed doses from [177Lu]Lu-DOTA-TATE PRRT in kidney and liver were 4.1 and 2.1 Gy, respectively. In comparison, the mean absorbed doses from [68Ga]Ga-DOTA-TATE were significantly lower: 18.0 mGy and 11.0 mGy, respectively. For lesions, the maximum absorbed dose from [68Ga]Ga-DOTA-TATE ranged from 24.1 to 170.4 mGy, while the maximum absorbed dose from [177Lu]Lu-DOTA-TATE PRRT was significantly higher, ranging from 9.6 to 77.9 Gy. The linear regression model yielded moderate R-squared values of 0.50, 0.59, and 0.36 for kidney, liver and lesion, respectively. The performance of multiple linear regression model was better, with R-squared values increasing to 0.81, 0.77, and 0.84.\nCONCLUSION: Absorbed doses from [177Lu]Lu-DOTA-TATE PRRT can be accurately predicted. Moreover, our models are formalized into simple equations.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17852",
    "link": "https://doi.org/10.1002/mp.17852"
  },
  {
    "title": "Depth-of-interaction encoding techniques for pixelated PET detectors enabled by machine learning methods and fast waveform digitization.",
    "authors": [
      "Bing Dai",
      "Srilalan Krishnamoorthy",
      "Emmanuel Morales",
      "Suleman Surti",
      "Joel S Karp"
    ],
    "abstract": "Objective. Pixelated detectors with single-ended readout are routinely used by commercial positron emission tomography scanners owing to their good energy and timing resolution and optimized manufacturing, but they typically do not provide depth-of-interaction (DOI) information, which can help improve the performance of systems with higher resolution and smaller ring diameter. This work aims to develop a technique for multi-level DOI classification that does not require modifications to the detector designs.Approach. We leveraged high-speed (5 Gs s-1) waveform sampling electronics with the Domino Ring Sampler (DRS4) and machine learning (ML) methods to extract DOI information from the entire scintillation waveforms of pixelated crystals. We evaluated different grouping schemes for multi-level DOI classification by analyzing the DOI positioning profile and DOI positioning error. We examined trade-offs among crystal configurations, detector timing performance, and DOI classification accuracy. We also investigated the impact of different ML algorithms and input features-extracted from scintillation waveforms-on model accuracy.Main results. The DOI positioning profile and positioning error suggest that 2- or 3-level binning was effective for 20 mm long crystals. 2-level discrete DOI models achieved 95% class-wise accuracy and 83% overall accuracy in positioning events into the correct DOI level and 3-level up to 90% class-wise accuracy for long and narrow crystals (2 × 2 × 20 mm3). Long short-term memory networks trained with time-frequency moments were twice as efficient in training time while maintaining equal or better accuracy compared to those trained with waveforms. Classical ML algorithms exhibit comparable accuracy while consuming one order less training time than deep learning models.Significance. This work demonstrates a proof-of-concept approach for obtaining DOI information from commercially available pixelated detectors without altering the detector design thereby avoiding potential degradation in detector timing performance. It provides an alternative solution for multi-level DOI classification, potentially inspiring future scanner designs.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/adc96d",
    "link": "https://doi.org/10.1088/1361-6560/adc96d"
  }
]