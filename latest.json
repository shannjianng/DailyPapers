[
  {
    "title": "A hybrid predictor-corrector network and spatiotemporal classifier method for noisy plant PET image classification.",
    "authors": [
      "Weike Chang",
      "Nicola D'Ascenzo",
      "Emanuele Antonecchia",
      "Daniele Passaretti",
      "Giancarlo Pagnani",
      "Michele Pisante",
      "Qingguo Xie"
    ],
    "abstract": "Plant Positron Emission Tomography (PET) is a new and efficient imaging technique which aims at providing a quantitative analysis of plant stress, enabling personalized crop management and maximizing productivity. However, a highly performant classification system for noisy dynamic plant PET images faces the challenge of retrieving noise-free datasets and encoding both spatial and temporal representations within a unified model.&#xD;Approach. To overcome these limitations, we introduce an innovative hybrid model that combines denoising and classification for dynamic plant PET images. Initially, we compute a precise solution for the denoising problem of noisy dynamic plant PET images using a modified optimization method coupled with deep convolutional neural networks. Subsequently, this solution is unfolded into a deep network known as the Predictor-Corrector Network (PCNet). To optimize the PCNet without requiring a noise-free dynamic training set, we propose a novel unsupervised learning method. Finally, the sequence of noise-reduced dynamic plant PET images is further fed into a unique classification system, encoding spatial representations of images and temporal representations of multivariate time series into a unified spatiotemporal representation and generating a prediction.&#xD;{\\it Main results}. The experimental results underscore the necessity of the denoising procedure and highlight the superiority of the proposed PCNet over existing competing denoising methods, demonstrating the effectiveness of the proposed classification system. Notably, the classification performance between the two classes achieves an averaged accuracy of 0.852, an averaged precision of 0.838, an averaged recall of 0.959, and an averaged F1-score of 0.880.&#xD;Significance. The ability of the proposed method to reduce noise intensity and effectively encode spatiotemporal representations overcomes the limitations of existing methods. This advancement may have substantial implications for other noisy dynamic image classification.",
    "abstract_zh": "植物正电子发射断层扫描（PET）是一种新型高效的成像技术，旨在对植物胁迫进行定量分析，从而实现个性化的作物管理并最大化生产力。然而，针对带噪声的动态植物PET图像，构建一个高性能的分类系统面临着获取无噪声数据集以及在一个统一模型中编码空间和时间表示的挑战。<br><br>**方法：** 为了克服这些局限性，我们引入了一种创新的混合模型，该模型结合了动态植物PET图像的去噪和分类。首先，我们使用改进的优化方法与深度卷积神经网络相结合，为带噪声的动态植物PET图像的去噪问题计算出一个精确的解决方案。随后，这个解决方案被展开成一个深度网络，称为预测器-校正器网络（PCNet）。为了在不需要无噪声动态训练集的情况下优化PCNet，我们提出了一种新的无监督学习方法。最后，将降噪后的动态植物PET图像序列进一步输入到一个独特的分类系统中，该系统将图像的空间表示和多元时间序列的时间表示编码成一个统一的时空表示，并生成预测。<br><br>**主要结果：** 实验结果强调了去噪过程的必要性，并突出了所提出的PCNet相对于现有竞争性去噪方法的优越性，证明了所提出的分类系统的有效性。值得注意的是，两类之间的分类性能达到了平均准确率0.852，平均精确率0.838，平均召回率0.959和平均F1分数0.880。<br><br>**意义：** 所提出的方法具有降低噪声强度和有效编码时空表示的能力，克服了现有方法的局限性。这一进步可能对其他带噪声的动态图像分类产生重大影响。",
    "summary_zh": "该论文提出了一种用于处理带噪声动态植物PET图像的创新混合模型。该模型首先使用改进的优化方法和深度卷积神经网络进行去噪，然后构建预测器-校正器网络（PCNet）并采用无监督学习进行优化。最后，通过一个独特的分类系统，将图像的空间和时间信息整合为时空表示，从而进行分类。实验结果表明该方法在去噪和分类方面均优于现有方法，并在两类分类中取得了显著的性能提升。该方法为其他带噪声的动态图像分类提供了潜在的借鉴意义。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/ade8cd",
    "link": "https://doi.org/10.1088/1361-6560/ade8cd"
  },
  {
    "title": "NEMA NU 4-2008 performance and MRI-compatibility study of the edgeless preclinical PET insert: ScintoTube.",
    "authors": [
      "Andrea González Montoro",
      "Marta Freire",
      "Fernando López-Berenguer",
      "Jorge Alamo",
      "Carlos de Alfonso",
      "Julio Barberá",
      "Stuart S Berr",
      "Carlos Correcher",
      "Laura Moliner Martinez",
      "Joseph Vincent Rispoli",
      "Jennifer L Sachs",
      "Luis F Vidal",
      "Mark B Williams",
      "José Maria Benlloch",
      "Antonio J González Martínez"
    ],
    "abstract": "The goal of this work is to evaluate the performance of a preclinical Positron Emission Tomography (PET) system, named ScintoTube, which was constructed using a continuous (edgeless) LYSO:Ce scintillator. The PET compatibility tests with high-field Magnetic Resonance Imaging (MRI) scanners are also reported.&#xD;Approach: We constructed a preclinical PET system based on a single, continuous-annular LYSO:Ce scintillator, with inner and outer diameters of 64 mm and 80 mm, respectively, and an axial coverage of 96 mm. The system has 24 virtual detectors, being each one composed of a matrix of 9×9 Silicon Photomultipliers (SiPMs). A novel trigger topology was implemented to retrieve the entire Light Distribution (LD) profiles. This information was used to provide the 3D photon impact coordinates which included the Depth Of Interaction (DOI) information.&#xD;To evaluate the ScintoTube performance, the NEMA NU 4-2008 protocol was followed. Dead Time and quantification corrections were implemented in the reconstruction process. Moreover, since the system is intended to be used as an insert for high-field MRI scanners, it was evaluated when working under the influence of 7T and 9.4T MRI scanners by acquiring data with different MRI sequences. &#xD;Results: This work successfully implements the edgeless concept for small animal PET insert and demonstrates that it is possible to retrieve homogeneous 3D photon impact positioning accuracy (in the 1 mm range) across the axial Field Of View (FOV) by using an edgeless design. The reported results also validate the capabilities of the PET insert to work under the influence of high-field MRI. There is almost no influence of the MR in our PET insert regarding spatial and energy resolutions and photopeak position. All PET parameter deviations are within the ±5% range when compared to non-MRI case.&#xD;Significance: Overall, the obtained results show that the designed ScintoTube is a promising system to be used as an insert with unique capabilities such as fully characterizing the entire LD profiles (3D positioning), suppressing edge effects in the transaxial and axial directions, and improving sensitivity.",
    "abstract_zh": "**翻译：**<br><br>本研究旨在评估一款名为ScintoTube的临床前正电子发射断层扫描 (PET) 系统的性能，该系统采用连续的（无边缘）LYSO:Ce 闪烁体构建。此外，本文还报告了该PET系统与高场磁共振成像 (MRI) 扫描仪的兼容性测试结果。<br><br>方法：我们构建了一个基于单个连续环形 LYSO:Ce 闪烁体的临床前PET系统，其内径和外径分别为 64 mm 和 80 mm，轴向覆盖范围为 96 mm。该系统具有 24 个虚拟探测器，每个探测器由 9×9 硅光电倍增管 (SiPM) 矩阵组成。我们实施了一种新型触发拓扑结构，用于检索完整的光分布 (LD) 剖面。此信息用于提供三维光子撞击坐标，其中包含相互作用深度 (DOI) 信息。<br><br>为了评估 ScintoTube 的性能，我们遵循了 NEMA NU 4-2008 协议。在重建过程中实施了死时间和定量校正。此外，由于该系统旨在用作高场 MRI 扫描仪的插件，因此在 7T 和 9.4T MRI 扫描仪的影响下，通过采集不同 MRI 序列的数据对其进行了评估。<br><br>结果：本研究成功地将无边缘概念应用于小动物PET插件，并证明使用无边缘设计可以在整个轴向视场 (FOV) 内实现均匀的三维光子撞击定位精度（在 1 mm 范围内）。报告的结果还验证了PET插件在高场MRI影响下工作的能力。MR对我们的PET插件在空间分辨率、能量分辨率和光电峰位置方面几乎没有影响。与非MRI情况相比，所有PET参数偏差均在 ±5% 范围内。<br><br>意义：总而言之，获得的结果表明，设计的 ScintoTube 是一款有前景的系统，可作为插件使用，具有独特的功能，例如完全表征整个 LD 剖面（三维定位）、抑制横向和轴向的边缘效应，以及提高灵敏度。",
    "summary_zh": "本研究评估了基于无边缘LYSO:Ce闪烁体的临床前PET系统ScintoTube的性能及其与高场MRI的兼容性。实验结果表明，ScintoTube能在高场MRI环境下保持良好的空间和能量分辨率，且通过无边缘设计实现了均匀的三维光子撞击定位精度，是一款有潜力用作MRI插件的PET系统，具有独特的3D定位、边缘效应抑制和灵敏度提升等优势。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/ade842",
    "link": "https://doi.org/10.1088/1361-6560/ade842"
  },
  {
    "title": "Simulation and one-ring prototyping of 1 mm-rod-resolution hemispherical brain PET with TOF-DOI detectors.",
    "authors": [
      "Kurumi Narita",
      "Go Akamatsu",
      "Eiji Yoshida",
      "Hideaki Tashima",
      "Yuma Iwao",
      "Miwako Takahashi",
      "Taiga Yamaya"
    ],
    "abstract": "Objective.Brain positron emission tomography (PET) imaging plays crucial roles in research and diagnosis of various brain diseases. To achieve high spatial resolution and high sensitivity, we proposed a hemispherical geometry which offers higher sensitivity with fewer detectors than a conventional cylindrical geometry. Our developed hemispherical brain PET system, Vrain, has indeed achieved a rod resolution of 2.2 mm with a 229 ps time-of-flight (TOF) resolution. To further improve the spatial resolution, we will use TOF and depth-of-interaction (DOI) detectors with our original crosshair light-sharing (CLS) configuration. This study aimed at estimating the performance of the hemispherical brain PET with TOF-DOI detectors and at developing a one-ring PET prototype with 1.6 mm scintillator pitch CLS-based TOF-DOI detectors.Approach.The sensitivity, rod resolution, and image quality of the TOF-DOI hemispherical brain PET (TDHBP-sim) and Vrain (Vrain-sim) were estimated using Geant4 simulation. A one-ring prototype with a 30 cm diameter was developed using the CLS-based TOF-DOI detectors. The energy resolution, TOF timing resolution, rod resolution, and the Hoffman brain phantom image quality of the prototype were evaluated.Main results.In the simulation study, TDHBP-sim achieved 1.4 times better sensitivity than Vrain-sim. TDHBP-sim visualized 1.0 mm rods and gyri and sulci structures in the brain phantom. In the one-ring experiment, the energy resolution was 11.6% at 511 keV, the TOF timing resolution was 294.6 ps, and 1.0 mm rods were resolved at the central 10 cm-diameter field-of-view. The 0.8 mm-thick radioactivity distribution could be identified in the Hoffman phantom.Significance.The study findings suggested that a hemispherical brain PET with 1.6 mm scintillator pitch TOF-DOI detectors should offer excellent performance including 1 mm rod resolution.",
    "abstract_zh": "**翻译：**<br><br>**目的。** 脑部正电子发射断层扫描(PET)成像在各种脑部疾病的研究和诊断中发挥着至关重要的作用。为了实现高空间分辨率和高灵敏度，我们提出了一种半球形几何结构，与传统的圆柱形几何结构相比，它能够用更少的探测器提供更高的灵敏度。我们开发的半球形脑部PET系统Vrain确实实现了2.2毫米的杆状分辨率和229皮秒的飞行时间(TOF)分辨率。为了进一步提高空间分辨率，我们将采用TOF和深度-相互作用(DOI)探测器，并结合我们原创的十字线光共享(CLS)配置。本研究旨在评估具有TOF-DOI探测器的半球形脑部PET的性能，并开发一个基于1.6毫米闪烁体间距CLS的TOF-DOI探测器的单环PET原型机。<br><br>**方法。** 使用Geant4模拟软件评估了TOF-DOI半球形脑部PET (TDHBP-sim)和Vrain (Vrain-sim)的灵敏度、杆状分辨率和图像质量。使用基于CLS的TOF-DOI探测器开发了一个直径为30厘米的单环原型机。评估了该原型机的能量分辨率、TOF时间分辨率、杆状分辨率和霍夫曼脑部体模图像质量。<br><br>**主要结果。** 在模拟研究中，TDHBP-sim的灵敏度比Vrain-sim高1.4倍。TDHBP-sim可视化了1.0毫米的杆状结构以及脑部体模中的脑回和脑沟结构。在单环实验中，能量分辨率在511 keV时为11.6%，TOF时间分辨率为294.6 ps，在中心直径10厘米的视场范围内可以分辨出1.0毫米的杆状结构。可以在霍夫曼体模中识别出0.8毫米厚的放射性分布。<br><br>**意义。** 研究结果表明，具有1.6毫米闪烁体间距TOF-DOI探测器的半球形脑部PET系统应能提供卓越的性能，包括1毫米的杆状分辨率。",
    "summary_zh": "该研究旨在提高脑部PET成像的空间分辨率和灵敏度。通过模拟和原型机实验，证明了采用半球形几何结构、TOF-DOI探测器以及十字线光共享(CLS)配置的脑部PET系统，能够显著提高灵敏度，实现1毫米的杆状分辨率，并有效分辨脑部精细结构。结果表明该技术在脑部疾病研究和诊断中具有潜在的应用价值。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/ade2b4",
    "link": "https://doi.org/10.1088/1361-6560/ade2b4"
  },
  {
    "title": "Enhancing image quality in fast neutron-based range verification of proton therapy using a deep learning-based prior in LM-MAP-EM reconstruction.",
    "authors": [
      "Lena M Setterdahl",
      "Kyrre Skjerdal",
      "Hunter N Ratliff",
      "Kristian Smeland Ytre-Hauge",
      "William R B Lionheart",
      "Sean Holman",
      "Helge E S Pettersen",
      "Francesco Blangiardi",
      "Danny Lathouwers",
      "Ilker Meric"
    ],
    "abstract": "Objective.This study investigates the use of list-mode (LM) maximuma posteriori(MAP) expectation maximization (EM) incorporating prior information predicted by a convolutional neural network for image reconstruction in fast neutron (FN)-based proton therapy range verification.Approach. A conditional generative adversarial network (pix2pix) was trained on progressively noisier data, where detector resolution effects were introduced gradually to simulate realistic conditions. FN data were generated using Monte Carlo simulations of an 85 MeV proton pencil beam in a computed tomography-based lung cancer patient model, with range shifts emulating weight gain and loss. The network was trained to estimate the expected two-dimensional ground truth FN production distribution from simple back-projection images. Performance was evaluated using mean squared error, structural similarity index (SSIM), and the correlation between shifts in predicted distributions and true range shifts.Main results. Our results show that pix2pix performs well on noise-free data but suffers from significant degradation when detector resolution effects are introduced. Among the LM-MAP-EM approaches tested, incorporating a mean prior estimate into the reconstruction process improved performance, with LM-MAP-EM using a mean prior estimate outperforming naïve LM maximum likelihood EM (LM-MLEM) and conventional LM-MAP-EM with a smoothing quadratic energy function in terms of SSIM.Significance. Findings suggest that deep learning techniques can enhance iterative reconstruction for range verification in proton therapy. However, the effectiveness of the model is highly dependent on data quality, limiting its robustness in high-noise scenarios.",
    "abstract_zh": "**翻译：**<br><br>**目的。** 本研究旨在探讨使用列表模式（LM）最大后验（MAP）期望最大化（EM）算法，结合卷积神经网络预测的先验信息，进行快速中子（FN）质子治疗射程验证中的图像重建。<br><br>**方法。** 训练了一个条件生成对抗网络（pix2pix），该网络在逐渐增加噪声的数据上进行训练，逐渐引入探测器分辨率效应，以模拟真实条件。FN数据通过蒙特卡罗模拟在基于计算机断层扫描的肺癌患者模型中85 MeV质子笔形束产生，射程偏移模拟体重增加和减少。网络被训练成从简单的反投影图像中估计期望的二维真实FN生成分布。使用均方误差、结构相似性指数（SSIM）以及预测分布偏移和真实射程偏移之间的相关性来评估性能。<br><br>**主要结果。** 我们的结果表明，pix2pix在无噪声数据上表现良好，但当引入探测器分辨率效应时，性能会显著下降。在测试的LM-MAP-EM方法中，将均值先验估计纳入重建过程提高了性能，其中使用均值先验估计的LM-MAP-EM在SSIM方面优于朴素的LM最大似然EM（LM-MLEM）和具有平滑二次能量函数的传统LM-MAP-EM。<br><br>**重要性。** 研究结果表明，深度学习技术可以增强质子治疗中射程验证的迭代重建。然而，模型的有效性高度依赖于数据质量，限制了其在高噪声场景中的鲁棒性。",
    "summary_zh": "本研究探索了利用深度学习（pix2pix）辅助LM-MAP-EM算法，提升快速中子质子治疗射程验证图像重建效果。研究表明，pix2pix在无噪声数据下表现良好，但对探测器分辨率效应敏感。将均值先验估计融入LM-MAP-EM算法可提升重建性能，优于LM-MLEM和传统LM-MAP-EM。虽然深度学习技术有望改进质子治疗射程验证，但其有效性受数据质量限制，在高噪声环境下鲁棒性较差。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/ade198",
    "link": "https://doi.org/10.1088/1361-6560/ade198"
  },
  {
    "title": "Development of an ultrasensitive small animal PET with 4-layer DOI detectors for sub-second dynamic rodent imaging.",
    "authors": [
      "Han Gyu Kang",
      "Hideaki Tashima",
      "Hidekatsu Wakizaka",
      "Go Akamatsu",
      "Yuma Iwao",
      "Chie Toramatsu",
      "Taiga Yamaya"
    ],
    "abstract": "Objective.Dynamic positron emission tomography (PET) imaging is important for preclinical research since it can visualize the functional information of rodent models as a function of time. However, the temporal resolution of small animal PET imaging has been limited to a scale of seconds due to low sensitivity, and it is not sufficient to capture cardiac or brain function accurately. Here, we present an ultrasensitive small-animal PET scanner with total-body coverage for sub-second dynamic imaging of a rat.Methods.The ultrasensitive small animal PET scanner has a 155 mm inner diameter and 325.6 mm axial coverage. The PET scanner has six rings, each of which has 10 depth-of-interaction (DOI) detectors. Each DOI detector consists of a four-layer Zr-doped gadolinium oxyorthosilicate crystal array (2.85 mm pitch, 30 mm total thickness) and 8 × 8 multi-anode photomultiplier tubes. The physical PET performance was evaluated based on the National Electrical Manufacturers Association NU4 protocol. Sub-second dynamic rat imaging was performed with18F-FDG tracer.Main results.The peak absolute sensitivity was 20.2% and spatial resolution was 2.6 mm at the center of the field of view with an energy window of 400-600 keV. Total-body images of a rat were obtained with a single bed position. The cardiac function of a rat was visualized with 0.25 s temporal resolution, which was hardly possible with conventional small animal PET scanners.Significance. The developed ultrasensitive animal PET enabled sub-second dynamic PET imaging in rodent models with total-body coverage. In conclusion, the ultrasensitive small animal PET scanner can serve as a useful molecular imaging tool for preclinical research with its long axial coverage sub-second temporal resolution.",
    "abstract_zh": "**翻译：**<br><br>**目的。** 动态正电子发射断层扫描（PET）成像对于临床前研究至关重要，因为它能够以时间为函数可视化啮齿动物模型的功能信息。然而，由于灵敏度较低，小动物PET成像的时间分辨率一直受限于秒级，不足以准确捕捉心脏或大脑功能。本文介绍了一种超高灵敏度的小动物PET扫描仪，该扫描仪具有全身覆盖范围，可对大鼠进行亚秒级动态成像。<br><br>**方法。** 该超高灵敏度小动物PET扫描仪的内径为155毫米，轴向覆盖范围为325.6毫米。PET扫描仪具有六个环，每个环具有10个深度方向识别（DOI）探测器。每个DOI探测器由一个四层Zr掺杂的硅酸钆晶体阵列（2.85毫米间距，总厚度30毫米）和8×8多阳极光电倍增管组成。基于美国国家电子制造商协会NU4协议评估了PET的物理性能。使用<sup>18</sup>F-FDG示踪剂进行了亚秒级动态大鼠成像。<br><br>**主要结果。** 在400-600 keV的能量窗口下，视野中心的峰值绝对灵敏度为20.2%，空间分辨率为2.6毫米。使用单个床位位置获得了大鼠的全身图像。以0.25秒的时间分辨率可视化了大鼠的心脏功能，这在传统的的小动物PET扫描仪上几乎是不可能实现的。<br><br>**意义。** 开发的超高灵敏度动物PET实现了具有全身覆盖范围的啮齿动物模型的亚秒级动态PET成像。总之，该超高灵敏度小动物PET扫描仪具有较长的轴向覆盖范围和亚秒级时间分辨率，可以作为临床前研究中一种有用的分子成像工具。",
    "summary_zh": "该研究开发了一种超高灵敏度的小动物PET扫描仪，具有全身覆盖能力和亚秒级的时间分辨率。通过使用Zr掺杂的硅酸钆晶体阵列和多阳极光电倍增管，该扫描仪实现了高灵敏度和空间分辨率。实验结果表明，该设备可以清晰地显示大鼠的全身图像和心脏功能，为临床前研究提供了一个强大的分子成像工具。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/ade112",
    "link": "https://doi.org/10.1088/1361-6560/ade112"
  },
  {
    "title": "Physical phantom validation of clustering-initiated factorization in dynamic PET.",
    "authors": [
      "Valerie Kobzarenko",
      "Suzanne L Baker",
      "Mustafa Janabi",
      "Woon-Seng Choong",
      "Grant T Gullberg",
      "Youngho Seo",
      "Rostyslav Boutchko",
      "Debasis Mitra"
    ],
    "abstract": "BACKGROUND: Dynamic positron emission tomography (PET) enables the quantification of physiological parameters of radiotracers employed in the investigation of neuropsychiatric disorders. We previously introduced a factor analysis-based algorithm, Cluster-Initialized Factor Analysis (CIFA), designed to overcome the problem of specifying reference regions. CIFA is capable of automatically extracting distinct radiotracer binding distributions across many modalities based on the differences in tracer dynamics, and thus can distinguish regions of specific- and non-specific binding without requiring prior segmentation.\nPURPOSE: Our goal is to quantitatively validate the ability of CIFA to resolve different dynamic biological processes by comparing the output of the algorithm to an independent benchmark. As an intermediate goal, we aim to create a physical phantom capable of modeling unique aspects of dynamic imaging and to use this phantom as the benchmark in evaluating CIFA.\nMETHODS: CIFA was used to reconstruct 18F-flortaucipir dynamic brain PET datasets acquired at Lawrence Berkeley National Lab. The resulting factor curves served as the foundation for creating dynamic input time-activity curve (TAC) combinations in a physical brain phantom specifically constructed for this purpose. The phantom represented three components: two overlapping tissue types and free radiotracer, constructed with a combination of small hydraulic elements. The physical components were scanned separately to generate a library of images, allowing us to reproduce scans of any duration with prescribed dynamics and realistic partial volume effects. The phantom was designed to produce noisy instances with compartment mixing of dynamic scans with desired activity TACs for free, non-specifically bound, and specifically bound radiotracers. Ten distinct dynamic simulations with varying levels of TAC similarity were estimated with CIFA.\nRESULTS: We directly evaluated CIFA's performance in analyzing each of the 10 dynamic datasets by computing the Pearson correlation coefficient between the estimated outputs and the ground truth tissue TACs and corresponding tissue distributions. For seven out of 10 modeled dynamics, which captured the full spectrum of realistically expected tissue TAC shapes, the curve correlation of the specific binding tissue was above 95%.\nCONCLUSIONS: This work formulated an innovative process by combining a physical phantom design with PET images for evaluating the application of CIFA in the extraction of dynamic TACs from dynamic PET image data. In most cases the CIFA algorithm accurately reproduced the dynamics of the phantom simulated data.",
    "abstract_zh": "**翻译：**<br><br>背景：动态正电子发射断层扫描（PET）能够量化放射性示踪剂的生理参数，这些示踪剂被用于神经精神疾病的研究。我们之前介绍了一种基于因子分析的算法，即聚类初始化因子分析（CIFA），旨在克服指定参考区域的问题。CIFA能够基于示踪剂动力学的差异，自动提取跨多种模态的不同放射性示踪剂结合分布，从而区分特异性结合和非特异性结合区域，而无需预先分割。<br><br>目的：我们的目标是通过将算法的输出与独立的基准进行比较，来定量验证CIFA解析不同动态生物过程的能力。作为一个中间目标，我们旨在创建一个能够模拟动态成像独特方面的物理模型，并将此模型用作评估CIFA的基准。<br><br>方法：我们使用CIFA重建了在劳伦斯伯克利国家实验室获取的18F-flortaucipir动态脑PET数据集。得到的因子曲线构成了在该目的下专门构建的物理脑模型中创建动态输入时间-活动曲线（TAC）组合的基础。该模型代表了三个组成部分：两种重叠的组织类型和游离的放射性示踪剂，由小型液压元件组合构建而成。物理组件被单独扫描以生成图像库，从而使我们能够重现具有规定动力学和真实部分容积效应的任何持续时间的扫描。该模型旨在生成具有动态扫描的室混合的噪声实例，这些动态扫描具有所需的游离、非特异性结合和特异性结合放射性示踪剂的活动TAC。使用CIFA估计了十个具有不同水平TAC相似性的不同动态模拟。<br><br>结果：我们通过计算估计输出与真实组织TAC和相应组织分布之间的Pearson相关系数，直接评估了CIFA在分析这10个动态数据集中的性能。对于10个建模动力学中的7个，这些动力学捕捉了现实预期组织TAC形状的完整范围，特异性结合组织的曲线相关性高于95%。<br><br>结论：这项工作通过将物理模型设计与PET图像相结合，提出了一种创新的过程，用于评估CIFA在从动态PET图像数据中提取动态TAC的应用。在大多数情况下，CIFA算法准确地再现了模型模拟数据的动力学。",
    "summary_zh": "该研究旨在验证一种名为CIFA的算法在动态PET图像分析中的能力。研究人员构建了一个物理脑模型，模拟了不同放射性示踪剂的动态行为，然后利用CIFA算法分析了模型产生的动态PET数据。结果表明，CIFA算法在大多数情况下能够准确地重现模型的动态数据，表明该算法在提取动态PET图像数据中动态TAC方面具有潜力。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17902",
    "link": "https://doi.org/10.1002/mp.17902"
  },
  {
    "title": "Modeling prompt gamma (PG) emission, detection and imaging in real patient anatomy using a novel Compton camera for dose verification in proton therapy.",
    "authors": [
      "V R Sharma",
      "Z Jiang",
      "S Mossahebi",
      "E Shakeri",
      "A Chalise",
      "M K Gobbert",
      "S W Peterson",
      "J C Polf",
      "L Ren"
    ],
    "abstract": "Objective. Prompt gamma (PG) imaging is a promising modality for proton dose verification. Currently, there is a lack of effective tools to investigate the entire PG imaging process in patient anatomy, from PG emission to camera detection and image reconstruction, to evaluate and optimize its efficacy for dose verification in proton therapy.Approach. To address this gap, we developed a Monte-Carlo package, POLARIS J Monte Carlo (PJ-MC), that simulates the entire PG emission and imaging workflow in patient anatomy. We utilized Geant4 classes and G4-ancillary tools, employing the DCMTK external tool with G4PhantomParameterisation to convert patient CT data into voxelized geometries. Proton beams were modeled based on medical physics commissioning data. A novel two-stage POLARIS-J3 Compton-Camera was simulated under the patient couch for recording total, double, and triple scattered PG signals. Proton maximum range calculations from the PJ-MC are compared with dose calculations from a clinical treatment planning system. The detected PG signals data in the simulation were used to reconstruct PG images using Kernel- Weighted-Back-Projection algorithm.Main results. Analysis of gamma energy distribution showed a decay pattern with clear emission lines from nuclear reactions involving oxygen, carbon, nitrogen, and calcium. Neutron-induced reactions contribute significantly less-by an order of magnitude-compared to proton-induced reactions in various tissues. Mean absolute percentage error analysis showed that PG range verification was more stable when considering the range at 80%or 50%ofDmax, as opposed to the range at theDmax, where energy gating slightly improves accuracy but may reduce localization due to photon loss. Results showed that patient anatomy can impact the location of hot spot in the PG images, affecting its accuracy for localizing Bragg peak.Significance. In summary, our simulation package provides additional insights into PG emission and imaging in patient anatomy and serves as a robust tool for evaluating and optimizing PG imaging, enhancing its precision for dose verification in proton therapy.",
    "abstract_zh": "**翻译：**<br><br>**目的。** 即发伽马（PG）成像是一种前景广阔的质子剂量验证方法。目前，缺乏有效的工具来研究在患者解剖结构中从PG发射到相机探测和图像重建的整个PG成像过程，从而评估和优化其在质子治疗中进行剂量验证的有效性。<br><br>**方法。** 为了解决这一问题，我们开发了一个蒙特卡洛软件包，POLARIS J Monte Carlo (PJ-MC)，该软件包能够模拟在患者解剖结构中完整的PG发射和成像工作流程。我们利用了Geant4类和G4辅助工具，并使用带有G4PhantomParameterisation的DCMTK外部工具，将患者CT数据转换为体素化几何结构。质子束的建模基于医学物理调试数据。我们模拟了一种新型的两级POLARIS-J3康普顿相机，将其放置在患者治疗床下，用于记录总散射、双散射和三散射的PG信号。将PJ-MC计算的质子最大射程与临床治疗计划系统中的剂量计算进行比较。模拟中检测到的PG信号数据用于使用核加权反投影算法重建PG图像。<br><br>**主要结果。** 伽马能量分布分析显示出衰减模式，其中包含来自涉及氧、碳、氮和钙的核反应的清晰发射线。中子诱导的反应的贡献明显低于质子诱导的反应，在各种组织中低一个数量级。平均绝对百分比误差分析表明，当考虑80%或50%Dmax处的射程时，PG射程验证更稳定，而不是Dmax处的射程。在Dmax处的射程验证中，能量窗略微提高了准确性，但由于光子损失可能会降低定位精度。结果表明，患者解剖结构会影响PG图像中热点的位置，从而影响其定位布拉格峰的准确性。<br><br>**意义。** 总之，我们的模拟软件包提供了对患者解剖结构中PG发射和成像的额外见解，并作为一个强大的工具，用于评估和优化PG成像，从而提高其在质子治疗中进行剂量验证的精度。",
    "summary_zh": "该研究开发了一个名为POLARIS J Monte Carlo (PJ-MC)的蒙特卡洛模拟软件包，用于模拟质子治疗中即发伽马(PG)成像的完整过程，包括PG发射、探测和图像重建。该软件包利用Geant4，可以将患者CT数据转换为模拟几何结构，并模拟质子束与组织的相互作用。研究分析了伽马射线能量分布和中子/质子反应的贡献，并比较了模拟和临床治疗计划系统的质子射程。研究结果表明，PG射程验证在80%或50%Dmax处更为稳定，且患者解剖结构会影响PG图像中热点的位置，从而影响布拉格峰的定位准确性。PJ-MC软件包为评估和优化PG成像提供了有力的工具，有望提高质子治疗中剂量验证的精度。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/addf0d",
    "link": "https://doi.org/10.1088/1361-6560/addf0d"
  },
  {
    "title": "Machine learning positioning algorithms for long semi-monolithic scintillator PET detectors.",
    "authors": [
      "Samuel Mungai Kinyanjui",
      "Zhonghua Kuang",
      "Zheng Liu",
      "Ning Ren",
      "Yongfeng Yang"
    ],
    "abstract": "Objective.In this work, machine learning positioning algorithms are developed to improve the spatial resolutions of the semi-monolithic scintillator detectors in both monolithic (y) and depth of interaction (z) directions.Approach.Two long semi-monolithic scintillator detectors consisting of 12 lutetium yttrium oxyorthosilicate (LYSO) slabs of 0.96 × 56 × 10 mm3and 14 LYSO slabs of 0.81 × 56 × 10 mm3were manufactured. The scintillator arrays were read out by a 4 × 16 silicon photomultiplier array. 27 × 5 (y, z) positions of each detector were irradiated via a collimated22Na pencil beam. Extreme gradient boosting (XGBoost) machine learning model was used to predict the interaction positions foryandz. The genetic algorithm (GA) or particle swarm optimization (PSO) algorithm was used to optimize hyperparameters for the XGBoost model. The results of the machine learning positioning algorithms were compared to analytical positioning methods.Main results.The GA and PSO algorithms provided similar results. Compared to the analytical methods, the machine learning positioning methods improved bothyandzspatial resolutions especially at both ends of the detectors. The averageyspatial resolutions using the machine learning positioning methods were 0.92 ± 0.41 mm and 0.94 ± 0.44 mm as compared to those obtained with the squared center of gravity method of 1.38 ± 0.23 mm and 1.39 ± 0.25 mm for the two detectors, respectively. The averagezspatial resolutions obtained with the machine learning positioning methods were 1.67 ± 0.41 mm and 1.68 ± 0.45 mm as compared to those obtained with inverse standard deviation method of 2.09 ± 0.82 mm and 2.14 ± 0.81 mm for the two detectors, respectively.Significance.With the machine learning positioning algorithms, the semi-monolithic scintillator detectors with submillimeter slab thickness evaluated in this work provide less than 1 mmyspatial resolution and less than 2 mmzspatial resolution.",
    "abstract_zh": "**翻译：**<br><br>**目标：** 本研究旨在开发机器学习定位算法，以提高半单片闪烁体探测器在单片方向（y）和深度方向（z）上的空间分辨率。<br><br>**方法：** 制造了两个长的半单片闪烁体探测器，分别由12个尺寸为0.96 × 56 × 10 mm³ 和 14个尺寸为 0.81 × 56 × 10 mm³ 的钇铝石榴石镥（LYSO）晶体板组成。闪烁体阵列由一个 4 × 16 的硅光电倍增管阵列读出。每个探测器的 27 × 5 个 (y, z) 位置通过准直的 ²²Na 笔形束进行照射。采用极端梯度提升（XGBoost）机器学习模型来预测 y 和 z 方向的相互作用位置。使用遗传算法（GA）或粒子群优化（PSO）算法来优化 XGBoost 模型的超参数。将机器学习定位算法的结果与解析定位方法进行比较。<br><br>**主要结果：** GA 和 PSO 算法提供了相似的结果。与解析方法相比，机器学习定位方法提高了 y 和 z 方向的空间分辨率，尤其是在探测器的两端。使用机器学习定位方法获得的平均 y 方向空间分辨率分别为 0.92 ± 0.41 mm 和 0.94 ± 0.44 mm，而使用平方重心法获得的平均 y 方向空间分辨率分别为 1.38 ± 0.23 mm 和 1.39 ± 0.25 mm。使用机器学习定位方法获得的平均 z 方向空间分辨率分别为 1.67 ± 0.41 mm 和 1.68 ± 0.45 mm，而使用反标准差方法获得的平均 z 方向空间分辨率分别为 2.09 ± 0.82 mm 和 2.14 ± 0.81 mm。<br><br>**意义：** 通过机器学习定位算法，本研究中评估的具有亚毫米级晶体板厚度的半单片闪烁体探测器可提供小于 1 mm 的 y 方向空间分辨率和小于 2 mm 的 z 方向空间分辨率。",
    "summary_zh": "本研究利用机器学习算法（XGBoost，并用GA或PSO优化超参数）来提升半单片LYSO闪烁体探测器的空间分辨率。实验结果表明，相比传统的解析方法，该机器学习方法显著提高了探测器在y和z方向的空间分辨率，使得y方向分辨率达到亚毫米级（<1 mm），z方向分辨率达到2 mm以内。这表明机器学习算法可有效改善半单片闪烁体探测器的性能。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/addbbe",
    "link": "https://doi.org/10.1088/1361-6560/addbbe"
  },
  {
    "title": "Uncertainty quantification for deep learning-based metastatic lesion segmentation on whole body PET/CT.",
    "authors": [
      "Brayden Schott",
      "Victor Santoro-Fernandes",
      "Žan Klaneček",
      "Scott Perlman",
      "Robert Jeraj"
    ],
    "abstract": "Objective.Deep learning models are increasingly being implemented for automated medical image analysis to inform patient care. Most models, however, lack uncertainty information, without which the reliability of model outputs cannot be ensured. Several uncertainty quantification (UQ) methods exist to capture model uncertainty. Yet, it is not clear which method is optimal for a given task. The purpose of this work was to investigate several commonly used UQ methods for the critical yet understudied task of metastatic lesion segmentation on whole body PET/CT.Approach.59 whole body68Ga-DOTATATE PET/CT images of patients undergoing theranostic treatment of metastatic neuroendocrine tumors were used in this work. A 3D U-Net was trained for lesion segmentation following five-fold cross validation. Uncertainty measures derived from four UQ methods-probability entropy, Monte Carlo dropout, deep ensembles, and test time augmentation-were investigated. Each uncertainty measure was assessed across four quantitative evaluations: (1) its ability to detect artificially degraded image data at low, medium, and high degradation magnitudes; (2) to detect false-positive (FP) predicted regions; (3) to recover false-negative (FN) predicted regions; and (4) to establish correlations with model biomarker extraction and segmentation performance metrics.Mainresults.Test time augmentation and probability entropy respectively achieved the highest and lowest degraded image detection at low (AUC = 0.54 vs. 0.68), medium (AUC = 0.70 vs. 0.82), and high (AUC = 0.83 vs. 0.90) degradation magnitudes. For detecting FPs, all UQ methods achieve strong performance, with AUC values ranging narrowly between 0.77 and 0.81. FN region recovery performance was strongest for test time augmentation and weakest for probability entropy. Performance for the correlation analysis was mixed, where the strongest performance was achieved by test time augmentation for SUVtotalcapture (ρ= 0.57) and segmentation Dice coefficient (ρ= 0.72), by Monte Carlo dropout for SUVmeancapture (ρ= 0.35), and by probability entropy for segmentation cross entropy (ρ= 0.96).Significance.Overall, test time augmentation demonstrated superior UQ performance and is recommended for use in metastatic lesion segmentation task. It also offers the advantage of being post hoc and computationally efficient. In contrast, probability entropy performed the worst, highlighting the need for advanced UQ approaches for this task.",
    "abstract_zh": "**翻译：**<br><br>**目的。** 深度学习模型正日益被应用于自动化医学图像分析，以辅助患者护理。然而，大多数模型缺乏不确定性信息，没有这些信息，模型输出的可靠性就无法保证。目前存在多种不确定性量化（UQ）方法来捕捉模型的不确定性。但是，尚不清楚哪种方法最适合给定的任务。本研究旨在调查几种常用的UQ方法，用于全身PET/CT上转移性病灶分割这一关键但未被充分研究的任务。<br><br>**方法。** 本研究使用了59例接受转移性神经内分泌肿瘤放射性核素治疗的患者的全身<sup>68</sup>Ga-DOTATATE PET/CT图像。训练了一个3D U-Net进行病灶分割，采用五折交叉验证。研究了四种UQ方法（概率熵、蒙特卡洛dropout、深度集成和测试时增强）导出的不确定性度量。每种不确定性度量都通过四个定量评估进行评估：（1）其在低、中、高退化程度下检测人工退化图像数据的能力；（2）检测假阳性（FP）预测区域的能力；（3）恢复假阴性（FN）预测区域的能力；（4）建立与模型生物标志物提取和分割性能指标之间的相关性。<br><br>**主要结果。** 在低（AUC = 0.54 vs. 0.68）、中（AUC = 0.70 vs. 0.82）和高（AUC = 0.83 vs. 0.90）退化程度下，测试时增强和概率熵分别实现了最高和最低的退化图像检测。在检测假阳性方面，所有UQ方法都表现出强大的性能，AUC值窄幅分布在0.77到0.81之间。测试时增强的假阴性区域恢复性能最强，概率熵最弱。相关性分析的性能喜忧参半，测试时增强在SUV<sub>total</sub>截获(ρ= 0.57)和分割Dice系数(ρ= 0.72)方面表现最强，蒙特卡洛dropout在SUV<sub>mean</sub>截获(ρ= 0.35)方面表现最强，概率熵在分割交叉熵(ρ= 0.96)方面表现最强。<br><br>**意义。** 总而言之，测试时增强表现出卓越的UQ性能，建议用于转移性病灶分割任务。它还具有事后且计算效率高的优点。相比之下，概率熵表现最差，突出了针对此任务采用先进UQ方法的需求。",
    "summary_zh": "本研究比较了四种不确定性量化方法（概率熵、蒙特卡洛dropout、深度集成和测试时增强）在全身PET/CT图像转移性病灶分割任务中的表现。结果表明，测试时增强方法在检测退化图像、恢复假阴性区域以及与生物标志物和分割性能指标的相关性方面表现优异，建议用于该任务。概率熵方法表现最差，提示需要更先进的不确定性量化方法。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/add9df",
    "link": "https://doi.org/10.1088/1361-6560/add9df"
  },
  {
    "title": "Predicting and monitoring response to head and neck cancer radiotherapy using multimodality imaging and radiobiological digital twin simulations.",
    "authors": [
      "Eric Aliotta",
      "Jeho Jeong",
      "Ramesh Paudyal",
      "Milan Grkovski",
      "Bill Diplas",
      "James Han",
      "Vaios Hatzoglou",
      "Michalis Aristophanous",
      "Nadeem Riaz",
      "Heiko Schöder",
      "Nancy Y Lee",
      "Amita Shukla-Dave",
      "Joseph O Deasy"
    ],
    "abstract": "Objective.To predict radiotherapy treatment response for head and neck cancer (HNC) using multimodality imaging and personalized radiobiological modeling.Approach.A mechanistic radiobiological model was combined with multi-modality imaging data from diffusion weighted-magnetic resonance imaging and positron emission tomography scans with [18F]Fluorodeoxyglucose (FDG) and [18F]Fluoromisonidazole (FMISO) tracers to develop personalized treatment response models for human papilloma virus associated HNC patients undergoing chemo-radiotherapy. Models were initialized to incorporate patient-specific imaging and updated to reflect longitudinal measurements of nodal gross tumor volume throughout treatment. Prediction accuracy was assessed based on mean absolute error (MAE) of weekly volume predictions and in predicting locoregional recurrence (LRR) following treatment.Main results.Personalized modeling based on pretreatment imaging significantly improved longitudinal volume prediction accuracy and correlation with measurement compared with a generic population model (MAE = 23.4 ± 10.0% vs 24.9 ± 9.0%,p= 0.002 on pairedt-test,R= 0.82 vs 0.72). Adding volume measurements from weeks 1 and 2 further improved prediction accuracy for subsequent weeks (MAE = 12.5 ± 8.1%, 10.7 ± 9.9%). When incorporating feedback with longitudinal measurements, penalizing large deviations from pretreatment model parameters using a variational regularization method was necessary to maintain model stability. Model-predicted volumes based on baseline + week-1 information significantly improved LRR prediction compared with week-1 volume data alone (area under the curve, AUC = 0.83 vs 0.77,p= 0.03) and was similar to prediction using week-3 volume data (AUC = 0.83 vs 0.85,p= non-significant).Significance.The proposed approach, which integrates clinical imaging and radiobiological principles, could be a basis to guide pretreatment prescription personalization as well as on-treatment adaptations.",
    "abstract_zh": "**翻译：**<br><br>**目的：** 旨在利用多模态影像和个性化放射生物学建模预测头颈癌（HNC）的放疗疗效。<br><br>**方法：** 将一个机械放射生物学模型与多模态影像数据相结合，这些影像数据来自弥散加权磁共振成像和正电子发射断层扫描，使用[18F]氟代脱氧葡萄糖（FDG）和[18F]氟米索硝唑（FMISO）示踪剂，以构建针对接受同步放化疗的人乳头瘤病毒相关HNC患者的个性化治疗反应模型。模型被初始化以纳入患者特异性影像，并更新以反映治疗过程中淋巴结大体肿瘤体积的纵向测量值。基于每周体积预测的平均绝对误差（MAE）以及对治疗后局部区域复发（LRR）的预测来评估预测准确性。<br><br>**主要结果：** 与通用人群模型相比，基于治疗前影像的个性化建模显著提高了纵向体积预测的准确性和与测量的相关性（配对t检验，MAE = 23.4 ± 10.0% vs 24.9 ± 9.0%，p= 0.002；R= 0.82 vs 0.72）。添加第1周和第2周的体积测量值进一步提高了后续周的预测准确性（MAE = 12.5 ± 8.1%, 10.7 ± 9.9%）。当结合纵向测量的反馈时，有必要使用变分正则化方法惩罚与治疗前模型参数的大偏差，以维持模型稳定性。基于基线+第1周信息的模型预测体积显著提高了LRR预测，优于仅使用第1周体积数据（曲线下面积，AUC = 0.83 vs 0.77，p= 0.03），并且与使用第3周体积数据的预测相似（AUC = 0.83 vs 0.85，p= 无显著性）。<br><br>**意义：** 提出的方法整合了临床影像和放射生物学原理，可以为指导治疗前处方个性化以及治疗中适应性调整提供基础。",
    "summary_zh": "本研究旨在通过结合多模态影像数据（弥散加权磁共振成像和PET-CT）与机械放射生物学模型，开发个性化的头颈癌（HNC）放疗疗效预测模型。结果表明，与通用模型相比，基于治疗前影像的个性化模型提高了纵向肿瘤体积预测的准确性，并能更准确地预测局部区域复发。该方法有望为头颈癌的治疗前处方个性化和治疗过程中的方案调整提供指导。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/add9de",
    "link": "https://doi.org/10.1088/1361-6560/add9de"
  },
  {
    "title": "Whole-body CT-to-PET synthesis using a customized transformer-enhanced GAN.",
    "authors": [
      "Bangyan Xu",
      "Ziwei Nie",
      "Jian He",
      "Aimei Li",
      "Ting Wu"
    ],
    "abstract": "Background. Positron emission tomography with 2-deoxy-2-[fluorine-18]fluoro-D-glucose integrated with computed tomography (18F-FDG PET-CT) is a multi-modality medical imaging technique widely used for screening and diagnosis of lesions and tumors, in which, CT can provide detailed anatomical structures, while PET can show metabolic activities. Nevertheless, it has disadvantages such as long scanning time, high cost, and relatively high radiation doses.Purpose. We propose a deep learning model for the whole-body CT-to-PET synthesis task, generating high-quality synthetic PET images that are comparable to real ones in both clinical relevance and diagnostic value.Material. We collect 102 pairs of 3D CT and PET scans, which are sliced into 27 240 pairs of 2D CT and PET images (training: 21,855 pairs, validation: 2810 pairs, testing: 2575 pairs).Methods. We propose a transformer-enhanced generative adversarial network (GAN) for whole-body CT-to-PET synthesis task. The CPGAN model uses residual blocks and fully connected transformer residual blocks to capture both local features and global contextual information. A customized loss function incorporating structural consistency is designed to improve the quality of synthesized PET images.Results. Both quantitative and qualitative evaluation results demonstrate effectiveness of the CPGAN model. The mean and standard variance of NRMSE, PSNR and SSIM values on test set are(16.90±12.27)×10-4,28.71±2.67and0.926±0.033, respectively, outperforming other seven state-of-the-art models. Three radiologists independently and blindly evaluated and gave subjective scores to 100 randomly chosen PET images (50 real and 50 synthetic). By Wilcoxon signed rank test, there are no statistical differences between the synthetic PET images and the real ones.Conclusions. Despite the inherent limitations of CT images to directly reflect biological information of metabolic tissues, CPGAN model effectively synthesizes satisfying PET images from CT scans, which has potential in reducing the reliance on actual PET-CT scans.",
    "abstract_zh": "**翻译：**<br><br>**背景：** 正电子发射断层扫描与2-脱氧-2-[氟-18]氟代-D-葡萄糖集成计算机断层扫描（18F-FDG PET-CT）是一种多模态医学影像技术，广泛应用于病灶和肿瘤的筛查和诊断。其中，CT可以提供详细的解剖结构，而PET可以显示代谢活动。然而，它也存在一些缺点，例如扫描时间长、成本高以及相对较高的辐射剂量。<br><br>**目的：** 我们提出一种深度学习模型，用于全身CT到PET的合成任务，生成高质量的合成PET图像，在临床相关性和诊断价值方面与真实图像相当。<br><br>**材料：** 我们收集了102对3D CT和PET扫描图像，将其切片为27240对2D CT和PET图像（训练集：21855对，验证集：2810对，测试集：2575对）。<br><br>**方法：** 我们提出了一种Transformer增强的生成对抗网络（GAN）用于全身CT到PET的合成任务。该CPGAN模型使用残差块和全连接Transformer残差块来捕获局部特征和全局上下文信息。设计了一种包含结构一致性的定制损失函数，以提高合成PET图像的质量。<br><br>**结果：** 定量和定性评估结果均表明CPGAN模型的有效性。测试集上NRMSE、PSNR和SSIM值的平均值和标准差分别为(16.90±12.27)×10-4、28.71±2.67和0.926±0.033，优于其他七种最先进的模型。三位放射科医生独立且盲法地评估了100张随机选择的PET图像（50张真实图像和50张合成图像）并给出了主观评分。通过Wilcoxon符号秩检验，合成PET图像和真实图像之间没有统计学差异。<br><br>**结论：** 尽管CT图像在直接反映代谢组织的生物学信息方面存在固有的局限性，但CPGAN模型能够有效地从CT扫描中合成令人满意的PET图像，这有可能减少对实际PET-CT扫描的依赖。",
    "summary_zh": "该研究提出了一种基于Transformer增强生成对抗网络（CPGAN）的深度学习模型，用于从CT图像合成PET图像，旨在减少对PET-CT扫描的依赖。实验结果表明，该模型生成的合成PET图像在质量和诊断价值上与真实PET图像相当，且放射科医生的主观评估也证实了这一点。该方法有望降低辐射剂量和检查成本，并缩短扫描时间。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/add8dd",
    "link": "https://doi.org/10.1088/1361-6560/add8dd"
  },
  {
    "title": "Generation of synthetic CT from MRI for MRI-based attenuation correction of brain PET images using radiomics and machine learning.",
    "authors": [
      "Amin Hoseinipourasl",
      "Gholam-Ali Hossein-Zadeh",
      "Peyman Sheikhzadeh",
      "Hossein Arabalibeik",
      "Shaghayegh Karimi Alavijeh",
      "Habib Zaidi",
      "Mohammad Reza Ay"
    ],
    "abstract": "BACKGROUND: Accurate quantitative PET imaging in neurological studies requires proper attenuation correction. MRI-guided attenuation correction in PET/MRI remains challenging owing to the lack of direct relationship between MRI intensities and linear attenuation coefficients.\nPURPOSE: This study aims at generating accurate patient-specific synthetic CT volumes, attenuation maps, and attenuation correction factor (ACF) sinograms with continuous values utilizing a combination of machine learning algorithms, image processing techniques, and voxel-based radiomics feature extraction approaches.\nMETHODS: Brain MR images of ten healthy volunteers were acquired using IR-pointwise encoding time reduction with radial acquisition (IR-PETRA) and VIBE-Dixon techniques. synthetic CT (SCT) images, attenuation maps, and attenuation correction factors (ACFs) were generated using the LightGBM, a fast and accurate machine learning algorithm, from the radiomics-based and image processing-based feature maps of MR images. Additionally, ultra-low-dose CT images of the same volunteers were acquired and served as the standard of reference for evaluation. The SCT images, attenuation maps, and ACF sinograms were assessed using qualitative and quantitative evaluation metrics and compared against their corresponding reference images, attenuation maps, and ACF sinograms.\nRESULTS: The voxel-wise and volume-wise comparison between synthetic and reference CT images yielded an average mean absolute error of 60.75 ± 8.8 HUs, an average structural similarity index of 0.88 ± 0.02, and an average peak signal-to-noise ratio of 32.83 ± 2.74 dB. Additionally, we compared MRI-based attenuation maps and ACF sinograms with their CT-based counterparts, revealing average normalized mean absolute errors of 1.48% and 1.33%, respectively.\nCONCLUSION: Quantitative assessments indicated higher correlations and similarities between LightGBM-synthesized CT and Reference CT images. Moreover, the cross-validation results showed the possibility of producing accurate SCT images, MRI-based attenuation maps, and ACF sinograms. This might spur the implementation of MRI-based attenuation correction on PET/MRI and dedicated brain PET scanners with lower computational time using CPU-based processors.",
    "abstract_zh": "**翻译：**<br><br>背景：在神经系统研究中，精确的定量PET成像需要正确的衰减校正。PET/MRI中的MRI引导衰减校正仍然具有挑战性，这是由于MRI信号强度与线性衰减系数之间缺乏直接关系。<br><br>目的：本研究旨在利用机器学习算法、图像处理技术和基于体素的放射组学特征提取方法的组合，生成具有连续值的精确的、患者特异性的合成CT体数据、衰减图和衰减校正因子（ACF）正弦图。<br><br>方法：使用IR-pointwise encoding time reduction with radial acquisition (IR-PETRA)和VIBE-Dixon技术获取了十名健康志愿者的脑部MR图像。利用LightGBM（一种快速而精确的机器学习算法），基于MR图像的放射组学和图像处理特征图，生成了合成CT（SCT）图像、衰减图和衰减校正因子（ACF）。此外，还获取了相同志愿者的超低剂量CT图像，作为评估的参考标准。使用定性和定量评估指标对SCT图像、衰减图和ACF正弦图进行评估，并与相应的参考图像、衰减图和ACF正弦图进行比较。<br><br>结果：合成CT图像和参考CT图像之间的体素和体积比较结果显示，平均绝对误差为60.75 ± 8.8 HU，平均结构相似性指数为0.88 ± 0.02，平均峰值信噪比为32.83 ± 2.74 dB。此外，我们将基于MRI的衰减图和ACF正弦图与基于CT的对应物进行了比较，结果显示平均归一化平均绝对误差分别为1.48%和1.33%。<br><br>结论：定量评估表明，LightGBM合成的CT图像与参考CT图像之间具有更高的相关性和相似性。此外，交叉验证结果表明，生成精确的SCT图像、基于MRI的衰减图和ACF正弦图是可行的。这可能会推动在PET/MRI和专用脑部PET扫描仪上实施基于MRI的衰减校正，并使用基于CPU的处理器降低计算时间。",
    "summary_zh": "本研究旨在解决PET/MRI中由于MRI信号与线性衰减系数关系不明而导致的衰减校正难题。研究人员使用LightGBM机器学习算法，结合放射组学和图像处理技术，从MR图像中生成了合成CT图像、衰减图和ACF正弦图。实验结果表明，生成的合成CT图像与参考CT图像高度相似，基于MRI的衰减图和ACF正弦图与基于CT的对应物误差很小。结论是，LightGBM算法能够生成精确的合成CT图像，有望推动MRI在PET/MRI中的衰减校正应用，并降低计算时间。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17867",
    "link": "https://doi.org/10.1002/mp.17867"
  },
  {
    "title": "Impact of tracer uptake rate on quantification accuracy of myocardial blood flow in PET: A simulation study.",
    "authors": [
      "Xiaotong Hong",
      "Amirhossein Sanaat",
      "Yazdan Salimi",
      "René Nkoulou",
      "Hossein Arabi",
      "Lijun Lu",
      "Habib Zaidi"
    ],
    "abstract": "BACKGROUND: Cardiac perfusion PET is commonly used to assess ischemia and cardiovascular risk, which enables quantitative measurements of myocardial blood flow (MBF) through kinetic modeling. However, the estimation of kinetic parameters is challenging due to the noisy nature of short dynamic frames and limited sample data points.\nPURPOSE: This work aimed to investigate the errors in MBF estimation in PET through a simulation study and to evaluate different parameter estimation approaches, including a deep learning (DL) method.\nMATERIALS AND METHODS: Simulated studies were generated using digital phantoms based on cardiac segmentations from 55 clinical CT images. We employed the irreversible 2-tissue compartmental model and simulated dynamic 13N-ammonia PET scans under both rest and stress conditions (220 cases each). The simulations covered a rest K1 range of 0.6 to 1.2 and a stress K1 range of 1.2 to 3.6 (unit: mL/min/g) in the myocardium. A transformer-based DL model was trained on the simulated dataset to predict parametric images (PIMs) from noisy PET image frames and was validated using 5-fold cross-validation. We compared the DL method with the voxel-wise nonlinear least squares (NLS) fitting applied to the dynamic images, using either Gaussian filter (GF) smoothing (GF-NLS) or a dynamic nonlocal means (DNLM) algorithm for denoising (DNLM-NLS). Two patients with coronary CT angiography (CTA) and fractional flow reserve (FFR) were enrolled to test the feasibility of applying DL models on clinical PET data.\nRESULTS: The DL method showed clearer image structures with reduced noise compared to the traditional NLS-based methods. In terms of mean absolute relative error (MARE), as the rest K1 values increased from 0.6 to 1.2 mL/min/g, the overall bias in myocardium K1 estimates decreased from approximately 58% to 45% for the NLS-based methods while the DL method showed a reduction in MARE from 42% to 18%. For stress data, as the stress K1 decreased from 3.6 to 1.2 mL/min/g, the MARE increased from 30% to 70% for the GF-NLS method. In contrast, both the DNLM-NLS (average: 42%) and the DL methods (average: 20%) demonstrated significantly smaller MARE changes as stress K1 varied. Regarding the regional mean bias (±standard deviation), the GF-NLS method had a bias of 6.30% (±8.35%) of rest K1, compared to 1.10% (±8.21%) for DNLM-NLS and 6.28% (±14.05%) for the DL method. For the stress K1, the GF-NLS showed a mean bias of 10.72% (±9.34%) compared to 1.69% (±8.82%) for DNLM-NLS and -10.55% (±9.81%) for the DL method.\nSIGNIFICANCE: This study showed that an increase in the tracer uptake rate (K1) corresponded to improved accuracy and precision in MBF quantification, whereas lower tracer uptake resulted in higher noise in dynamic PET and poorer parameter estimates. Utilizing denoising techniques or DL approaches can mitigate noise-induced bias in PET parametric imaging.",
    "abstract_zh": "**背景：** 心脏灌注PET常用于评估心肌缺血和心血管风险，它可以通过动力学建模实现心肌血流量(MBF)的定量测量。然而，由于动态帧的噪声特性和有限的样本数据点，动力学参数的估计具有挑战性。<br><br>**目的：** 本研究旨在通过模拟研究调查PET中MBF估计的误差，并评估不同的参数估计方法，包括深度学习(DL)方法。<br><br>**材料与方法：** 基于55例临床CT图像的心脏分割，使用数字体模生成模拟研究数据。我们采用不可逆的二室模型，并模拟了静息和负荷状态下（每种状态各220例）的动态<sup>13</sup>N-氨PET扫描。模拟覆盖了静息状态下0.6至1.2以及负荷状态下1.2至3.6的心肌K1范围（单位：mL/min/g）。基于Transformer的深度学习模型在模拟数据集上进行训练，以从噪声PET图像帧中预测参数图像(PIMs)，并使用5折交叉验证进行验证。我们将深度学习方法与应用于动态图像的逐体素非线性最小二乘(NLS)拟合进行比较，该拟合使用高斯滤波(GF)平滑(GF-NLS)或动态非局部均值(DNLM)算法进行去噪(DNLM-NLS)。招募了两名接受了冠状动脉CT血管造影(CTA)和血流储备分数(FFR)检查的患者，以测试深度学习模型在临床PET数据上的应用可行性。<br><br>**结果：** 与传统的基于NLS的方法相比，深度学习方法显示出更清晰的图像结构，且噪声更低。在平均绝对相对误差(MARE)方面，随着静息K1值从0.6增加到1.2 mL/min/g，基于NLS的方法的心肌K1估计的总体偏差从大约58%降低到45%，而深度学习方法的MARE则从42%降低到18%。对于负荷数据，随着负荷K1从3.6降低到1.2 mL/min/g，GF-NLS方法的MARE从30%增加到70%。相比之下，DNLM-NLS（平均值：42%）和深度学习方法（平均值：20%）都表现出明显更小的MARE随负荷K1变化。关于区域平均偏差（±标准差），GF-NLS方法的静息K1偏差为6.30% (±8.35%)，DNLM-NLS为1.10% (±8.21%)，深度学习方法为6.28% (±14.05%)。对于负荷K1，GF-NLS的平均偏差为10.72% (±9.34%)，DNLM-NLS为1.69% (±8.82%)，深度学习方法为-10.55% (±9.81%)。<br><br>**意义：** 本研究表明，示踪剂摄取率(K1)的增加对应于MBF量化中准确性和精度的提高，而较低的示踪剂摄取导致动态PET中更高的噪声和较差的参数估计。利用去噪技术或深度学习方法可以减轻PET参数成像中噪声引起的偏差。",
    "summary_zh": "本研究通过模拟和临床数据，比较了深度学习与传统方法在心肌血流量(MBF) PET定量分析中的表现。研究发现，示踪剂摄取率的增加能提高MBF量化的准确性，而深度学习方法相较于传统的非线性最小二乘法，在降低噪声、提高参数估计准确性方面更具优势，尤其是在低摄取率情况下。这表明深度学习技术在提高PET心肌血流量定量分析的可靠性方面具有潜力。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17871",
    "link": "https://doi.org/10.1002/mp.17871"
  },
  {
    "title": "Exploiting network optimization stability for enhanced PET image denoising using deep image prior.",
    "authors": [
      "Fumio Hashimoto",
      "Kibo Ote",
      "Yuya Onishi",
      "Hideaki Tashima",
      "Go Akamatsu",
      "Yuma Iwao",
      "Miwako Takahashi",
      "Taiga Yamaya"
    ],
    "abstract": "Objective. Positron emission tomography (PET) is affected by statistical noise due to constraints on tracer dose and scan duration, impacting both diagnostic performance and quantitative accuracy. While deep learning-based PET denoising methods have been used to improve image quality, they may introduce over-smoothing, which can obscure critical structural details and compromise quantitative accuracy. We propose a method for making a deep learning solution more reliable and apply it to the conditional deep image prior (DIP).Approach. We introduce the idea ofstability informationin the optimization process of conditional DIP, enabling the identification of unstable regions within the network's optimization trajectory. Our method incorporates a stability map, which is derived from multiple intermediate outputs of a moderate neural network at different optimization steps. The final denoised PET image is then obtained by computing a linear combination of the DIP output and the original reconstructed PET image, weighted by the stability map.Main results. We employed eight high-resolution brain PET datasets for comparison. Our method effectively reduces background noise while preserving small structure details in brain [18F]FDG PET images. Comparative analysis demonstrated that our approach outperformed existing methods in terms of peak-to-valley ratio and background noise suppression across various low-dose levels. Additionally, region-of-interest analysis confirmed that the proposed method maintains quantitative accuracy without introducing under- or over-estimation. Furthermore, we applied our method to full-dose PET data to assess its impact on image quality. The results revealed that the proposed method significantly reduced background noise while preserving the peak-to-valley ratio at a level comparable to that of unfiltered full-dose PET images.Significance. The proposed method introduces a robust approach to deep learning-based PET denoising, enhancing its reliability and preserving quantitative accuracy. Furthermore, this strategy can potentially advance performance in high-sensitivity PET scanners and surpass the limit of image quality inherent to PET scanners.",
    "abstract_zh": "**翻译：**<br><br>**目的。** 正电子发射断层扫描（PET）受到示踪剂剂量和扫描时长限制引起的统计噪声影响，进而影响诊断性能和定量准确性。虽然基于深度学习的PET去噪方法已被用于改善图像质量，但它们可能引入过度平滑，从而掩盖关键的结构细节并损害定量准确性。我们提出一种方法，使深度学习解决方案更加可靠，并将其应用于条件深度图像先验（DIP）。<br><br>**方法。** 我们在条件DIP的优化过程中引入了*稳定性信息* 的概念，从而能够识别网络优化轨迹中的不稳定区域。我们的方法整合了一个稳定性图，该图是从一个中等规模神经网络在不同优化步骤的多个中间输出中导出的。最终去噪的PET图像是通过计算DIP输出和原始重建PET图像的线性组合来获得的，该线性组合由稳定性图加权。<br><br>**主要结果。** 我们采用了八个高分辨率脑PET数据集进行比较。我们的方法有效地降低了背景噪声，同时保留了脑部[<sup>18</sup>F]FDG PET图像中的小结构细节。比较分析表明，在各种低剂量水平下，我们的方法在峰谷比和背景噪声抑制方面均优于现有方法。此外，感兴趣区分析证实，该方法保持了定量准确性，且没有引入低估或高估。此外，我们将该方法应用于全剂量PET数据，以评估其对图像质量的影响。结果表明，该方法显著降低了背景噪声，同时保持了与未滤波全剂量PET图像相当的峰谷比。<br><br>**意义。** 该方法引入了一种稳健的基于深度学习的PET去噪方法，提高了其可靠性并保留了定量准确性。此外，该策略有可能提高高灵敏度PET扫描仪的性能，并超越PET扫描仪固有的图像质量限制。",
    "summary_zh": "该论文提出了一种基于条件深度图像先验（DIP）并引入“稳定性信息”的PET图像去噪方法。该方法通过稳定性图来识别并处理深度学习优化过程中的不稳定区域，从而在降低背景噪声的同时，保留图像的关键结构细节和定量准确性。实验结果表明，该方法在低剂量和全剂量PET图像中均优于现有方法，有望提高高灵敏度PET扫描仪的性能。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/add63f",
    "link": "https://doi.org/10.1088/1361-6560/add63f"
  },
  {
    "title": "Patient CT-based simulation study of secondary-electron-bremsstrahlung imaging for range verification in proton therapy: comparison with prompt gamma and PET imaging for simplified proton pencil beam and SOBP irradiation scenarios.",
    "authors": [
      "Takuya Yabe",
      "Munetaka Nitta",
      "Mitsutaka Yamaguchi",
      "Marco Pinto",
      "Naoki Kawachi",
      "Katia Parodi"
    ],
    "abstract": "Objective.Secondary electron bremsstrahlung (SEB) imaging, along with prompt gamma (PG) and positron emission tomography (PET) imaging, has been proposed as anin vivorange verification tool for proton therapy. This study presents the first simulation based on patient computed tomography (CT) data to investigate the feasibility of SEB imaging for range verification in proton therapy, while comparing the characteristics of SEB imaging with those of PG and PET imaging.Approach.A Monte Carlo simulation was performed using patient CT data for the irradiation of monoenergetic pencil beams and spread-out Bragg peak proton beams. The physical characteristics of SEB imaging were analyzed at three different anatomical sites and compared with those of PG and PET imaging.Main results. In all the treatment cases, SEB imaging exhibited higher production rates than PG and PET imaging, particularly in the regions with high CT values along the beam path. Although the SEB signal was more affected by scattering and absorption than the PET or PG signals, sufficient statistical counts for range verification (∼3 × 10-3SEBs/proton) could potentially be detected outside the patient geometry. For pencil beam cases, the SEB and PET fall-offs were located 4-5 mm proximal to the dose fall-off, while the PG fall-off was located 0-1 mm distal to it.Significance.Results suggest that SEB imaging has the potential to offer a real-time range verification tool (by comparing measured and expected images), particularly for treating shallow-seated tumors using proton pencil-beam scanning delivery. Thus, this study represents a significant step towards the clinical application of range verification based on SEB imaging and promotes future efforts in this direction.",
    "abstract_zh": "**翻译：**<br><br>**目的。** 二次电子轫致辐射（SEB）成像，连同瞬发伽马（PG）和正电子发射断层扫描（PET）成像，已被提议作为质子治疗中体内射程验证工具。本研究基于患者计算机断层扫描（CT）数据进行了首次模拟，旨在研究SEB成像在质子治疗中用于射程验证的可行性，同时比较SEB成像与PG和PET成像的特性。<br><br>**方法。** 使用患者CT数据对单能铅笔束和扩展布拉格峰质子束的照射进行了蒙特卡罗模拟。在三个不同的解剖部位分析了SEB成像的物理特性，并与PG和PET成像进行了比较。<br><br>**主要结果。** 在所有治疗案例中，SEB成像都表现出比PG和PET成像更高的产生率，尤其是在沿束径具有高CT值的区域。尽管SEB信号比PET或PG信号更容易受到散射和吸收的影响，但在患者几何结构外部，有可能检测到用于射程验证的足够统计计数（∼3 × 10-3 SEBs/质子）。对于铅笔束案例，SEB和PET信号的下降位置位于剂量下降位置近端4-5 mm处，而PG信号的下降位置位于剂量下降位置远端0-1 mm处。<br><br>**意义。** 结果表明，SEB成像有可能提供一种实时射程验证工具（通过比较测量图像和预期图像），特别适用于使用质子铅笔束扫描递送治疗浅表肿瘤。因此，本研究代表了基于SEB成像的射程验证临床应用的重要一步，并促进了未来在该方向上的努力。<br><br>**",
    "summary_zh": "**\n\n该研究利用蒙特卡洛模拟，评估了二次电子轫致辐射（SEB）成像作为质子治疗射程验证工具的可行性，并与瞬发伽马（PG）和正电子发射断层扫描（PET）成像进行了比较。结果表明，SEB成像具有更高的信号产生率，尤其是在高CT值区域。虽然SEB信号易受散射和吸收影响，但仍有望获得足够的统计计数。SEB成像在铅笔束治疗中，信号下降位置与剂量下降位置的相对关系表明其具有潜在的临床应用价值，尤其适用于浅表肿瘤的质子治疗。该研究为SEB成像在质子治疗射程验证中的应用迈出了重要一步。",
    "journal": "Physics in medicine and biology",
    "pubdate": "",
    "doi": "10.1088/1361-6560/add4b7",
    "link": "https://doi.org/10.1088/1361-6560/add4b7"
  },
  {
    "title": "Instantaneous in vivo distal edge verification in intensity-modulated proton therapy by means of PET imaging.",
    "authors": [
      "Brian Zapien-Campos",
      "Zahra Ahmadi Ganjeh",
      "Giuliano Perotti-Bernardini",
      "Jeffrey Free",
      "Stefan Both",
      "Peter Dendooven"
    ],
    "abstract": "BACKGROUND: Intensity-modulated proton therapy (IMPT) holds promise for improving outcomes in head-and-neck cancer (HNC) patients by enhancing organ-at-risk (OAR) sparing. A key challenge in IMPT is ensuring an accurate dose delivery at the distal edge of the tumor, where the steep dose gradients make treatment precision highly sensitive to uncertainties in both proton range and patient setup. Thus, IMPT conformality is increased by incorporating robust margins in the treatment optimization. However, an increment in the plan robustness could lead to an OAR overdosing. Therefore, an accurate distal edge verification during dose delivery is crucial to increase IMPT conformality by reducing optimization settings in treatment planning.\nPURPOSE: This work aims to evaluate, in a quasi-clinical setting, a novel approach for accurate instantaneous proton beam distal edge verification in IMPT by means of spot-by-spot positron emission tomography (PET) imaging.\nMETHODS: An anthropomorphic head and neck phantom CIRS-731 HN was irradiated at the head and neck region. The targets were defined as 4 cm diameter spheres. A 60-ms delay was introduced between the proton beam spots in order to enable the spot-by-spot coincidence detection of the 511-keV photons resulting from positron annihilation following the positron emission from very short-lived positron-emitting, mainly 12N (T1/2  = 11.0 ms). Additionally, modified irradiations were carried out using solid water slabs of 2 and 5 mm thickness in the beam path to assess the precision of the approach for detecting range deviations. The positron activity range (PAR) was determined from the 50% distal fall-off position of the 1D longitudinal positron activity profile derived from the 2D image reconstructions. Furthermore, Monte Carlo (MC) simulations were performed using an in-house RayStation/GATE MC framework to predict the positron activity images and verify the PAR measurements.\nRESULTS: PAR measurements achieved a precision between 1.5 and 3.6 mm (at 1.5σ clinical level) at the beam spot level within sub-second time scales. Measured PAR shifts of 1.6-2.1  and 4.2--.7 mm were observed with the 2- and 5-mm thickness range shifters, respectively, aligning with the corresponding proton dose range (PDR) shifts of 1.3-1.8 and 3.9-4.3 mm. The simulated PAR agrees with the measured PARs, showing an average range difference of ∼0.4 mm.\nCONCLUSION: This study demonstrated the feasibility of instantaneous distal edge verification using PET imaging by introducing beam spot delays during dose delivery. The findings represent a first step toward the clinical implementation of instantaneous in vivo distal edge verification. The approach contributes to the development of real-time range verification aimed at improving IMPT treatments by mitigating range and setup uncertainties, thereby reducing dose to organs-at-risk and ultimately enhancing patient outcomes.",
    "abstract_zh": "以下是翻译和总结：<br><br>**翻译：**<br><br>背景：调强质子治疗(IMPT)有望通过增强危及器官(OAR)的保护，改善头颈部肿瘤(HNC)患者的治疗效果。IMPT的一个关键挑战是确保肿瘤远端边缘的剂量精确递送，在该处，陡峭的剂量梯度使得治疗精度对质子射程和患者摆位的不确定性高度敏感。因此，IMPT的适形性通过在治疗优化中加入稳健性容差来提高。然而，增加计划的稳健性可能会导致危及器官的过量照射。因此，在剂量递送过程中进行精确的远端边缘验证对于通过减少治疗计划中的优化设置来提高IMPT的适形性至关重要。<br><br>目的：本研究旨在在准临床环境中评估一种用于IMPT中精确的瞬时质子束远端边缘验证的新方法，该方法基于逐点正电子发射断层扫描(PET)成像。<br><br>方法：使用CIRS-731 HN人体头部和颈部模型，对头部和颈部区域进行照射。目标被定义为直径4厘米的球体。在质子束点之间引入60毫秒的延迟，以实现对511 keV光子的逐点符合检测，这些光子是由于非常短寿命的正电子发射体（主要是12N (T1/2 = 11.0 ms)）发射正电子后发生正电子湮灭产生的。此外，进行了修改后的照射实验，在光束路径中使用厚度为2和5毫米的固体水板，以评估该方法检测射程偏差的精度。正电子活性范围(PAR)由二维图像重建得到的1D纵向正电子活性曲线的50%远端衰减位置确定。此外，使用内部RayStation/GATE MC框架进行蒙特卡罗(MC)模拟，以预测正电子活性图像并验证PAR测量结果。<br><br>结果：PAR测量在亚秒级时间尺度内，在光束点水平上实现了1.5至3.6毫米的精度（在1.5σ临床水平）。分别使用2毫米和5毫米厚度的射程调节器观察到1.6-2.1毫米和4.2-4.7毫米的PAR偏移，与相应的1.3-1.8毫米和3.9-4.3毫米的质子剂量范围(PDR)偏移一致。模拟的PAR与测量的PAR一致，显示平均射程差异约为0.4毫米。<br><br>结论：本研究证实了通过在剂量递送期间引入光束点延迟，使用PET成像进行瞬时远端边缘验证的可行性。这些发现代表了瞬时体内远端边缘验证临床应用的第一步。该方法有助于开发实时射程验证技术，旨在通过减轻射程和摆位的不确定性来改善IMPT治疗，从而减少危及器官的剂量，最终改善患者的治疗效果。",
    "summary_zh": "本研究提出了一种基于逐点PET成像的瞬时质子束远端边缘验证新方法，用于调强质子治疗(IMPT)。通过体模实验和蒙特卡罗模拟验证了该方法的可行性和精度，结果表明该方法能够在亚秒级时间内实现毫米级的精度，并能有效检测射程偏差。该方法有望在临床上实现实时射程验证，降低危及器官的剂量，提高IMPT治疗效果。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17850",
    "link": "https://doi.org/10.1002/mp.17850"
  },
  {
    "title": "Modeling inter-reader variability in clinical target volume delineation for soft tissue sarcomas using diffusion model.",
    "authors": [
      "Yafei Dong",
      "Thibault Marin",
      "Yue Zhuo",
      "Elie Najem",
      "Arnaud Beddok",
      "Laura Rozenblum",
      "Maryam Moteabbed",
      "Kira Grogg",
      "Fangxu Xing",
      "Jonghye Woo",
      "Yen-Lin E Chen",
      "Ruth Lim",
      "Xiaofeng Liu",
      "Chao Ma",
      "Georges El Fakhri"
    ],
    "abstract": "BACKGROUND: Accurate delineation of the clinical target volume (CTV) is essential in the radiotherapy treatment of soft tissue sarcomas. However, this process is subject to inter-reader variability due to the need for clinical assessment of risk and extent of potential microscopic spread. This can lead to inconsistencies in treatment planning, potentially impacting treatment outcomes. Most existing automatic CTV delineation methods do not account for this variability and can only generate a single CTV for each case.\nPURPOSE: This study aims to develop a deep learning-based technique to generate multiple CTV contours for each case, simulating the inter-reader variability in the clinical practice.\nMETHODS: We employed a publicly available dataset consisting of fluorodeoxyglucose positron emission tomography (FDG-PET), x-ray computed tomography (CT), and pre-contrast T1-weighted magnetic resonance imaging (MRI) scans from 51 patients with soft tissue sarcoma, along with an independent validation set containing five additional patients. An experienced reader drew a contour of the gross tumor volume (GTV) for each patient based on multi-modality images. Subsequently, two additional readers, together with the first one, were responsible for contouring three CTVs in total based on the GTV. We developed a diffusion model-based deep learning method that is capable of generating arbitrary number of different and plausible CTVs to mimic the inter-reader variability in CTV delineation. The proposed model incorporates a separate encoder to extract features from the GTV masks, leveraging the critical role of GTV information in accurate CTV delineation.\nRESULTS: The proposed diffusion model demonstrated superior performance with the highest Dice Index (0.902 compared to values below 0.881 for state-of-the-art models) and the best generalized energy distance (GED) (0.209 compared to values exceeding 0.221 for state-of-the-art models). It also achieved the second-highest recall and precision metrics among the compared ambiguous image segmentation models. Results from both datasets exhibited consistent trends, reinforcing the reliability of our findings. Additionally, ablation studies exploring different model structures and input configurations highlighted the significance of incorporating prior GTV information for accurate CTV delineation.\nCONCLUSIONS: The proposed diffusion model successfully generates multiple plausible CTV contours for soft tissue sarcomas, effectively capturing inter-reader variability in CTV delineation.",
    "abstract_zh": "**翻译：**<br><br>背景：准确勾画临床靶区（CTV）对于软组织肉瘤的放射治疗至关重要。然而，由于需要临床评估潜在微观扩散的风险和范围，这一过程容易受到阅读者间差异的影响。这可能导致治疗计划的不一致，从而潜在地影响治疗结果。大多数现有的自动CTV勾画方法没有考虑这种差异性，只能为每个病例生成单一的CTV。<br><br>目的：本研究旨在开发一种基于深度学习的技术，为每个病例生成多个CTV轮廓，模拟临床实践中阅读者间的差异。<br><br>方法：我们使用了一个公开数据集，其中包含来自51名软组织肉瘤患者的氟代脱氧葡萄糖正电子发射断层扫描（FDG-PET）、X射线计算机断层扫描（CT）和预对比T1加权磁共振成像（MRI）扫描，以及包含5名额外患者的独立验证集。一位经验丰富的阅读者基于多模态图像为每位患者绘制了肉眼肿瘤体积（GTV）的轮廓。随后，另外两位阅读者与第一位阅读者一起负责基于GTV勾画总共三个CTV。我们开发了一种基于扩散模型的深度学习方法，该方法能够生成任意数量的不同且合理的CTV，以模拟CTV勾画中的阅读者间差异。所提出的模型包含一个单独的编码器，用于从GTV掩模中提取特征，从而利用GTV信息在准确CTV勾画中的关键作用。<br><br>结果：所提出的扩散模型表现出卓越的性能，具有最高的Dice指数（0.902，而最先进的模型的值低于0.881）和最佳的广义能量距离（GED）（0.209，而最先进模型的值超过0.221）。在所比较的模糊图像分割模型中，它还获得了第二高的召回率和精确率指标。来自两个数据集的结果都表现出一致的趋势，加强了我们研究结果的可靠性。此外，探索不同模型结构和输入配置的消融研究突出了纳入先验GTV信息对于准确CTV勾画的重要性。<br><br>结论：所提出的扩散模型成功地为软组织肉瘤生成了多个合理的CTV轮廓，有效地捕捉了CTV勾画中的阅读者间差异。",
    "summary_zh": "本研究开发了一种基于扩散模型的深度学习方法，用于自动生成多个临床靶区(CTV)轮廓，旨在解决软组织肉瘤放射治疗中由于阅读者间差异导致的CTV勾画不一致问题。该模型利用多模态医学影像（FDG-PET、CT、MRI）和肉眼肿瘤体积（GTV）信息，能够生成多个不同的、合理的CTV轮廓，有效地模拟了临床实践中阅读者间的差异。实验结果表明，该模型在Dice指数和广义能量距离等指标上优于现有的方法，并且通过消融实验验证了GTV信息对于准确CTV勾画的重要性。该研究成果有望提高软组织肉瘤放射治疗计划的准确性和一致性。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17865",
    "link": "https://doi.org/10.1002/mp.17865"
  },
  {
    "title": "Thorax-encompassing multi-modality PET/CT deep learning model for resected lung cancer prognostication: A retrospective, multicenter study.",
    "authors": [
      "Jaryd R Christie",
      "Perrin Romine",
      "Karen Eddy",
      "Delphine L Chen",
      "Omar Daher",
      "Mohamed Abdelrazek",
      "Richard A Malthaner",
      "Mehdi Qiabi",
      "Rahul Nayak",
      "Paul Kinahan",
      "Viswam S Nair",
      "Sarah A Mattonen"
    ],
    "abstract": "BACKGROUND: Patients with early-stage non-small cell lung cancer (NSCLC) typically receive surgery as their primary form of treatment. However, studies have shown that a high proportion of these patients will experience a recurrence after their resection, leading to an increased risk of death. Cancer staging is currently the gold standard for establishing a patient's prognosis and can help clinicians determine patients who may benefit from additional therapy. However, medical images which are used to help determine the cancer stage, have been shown to hold unutilized prognostic information that can augment clinical data and better identify high-risk NSCLC patients. There remains an unmet need for models to incorporate clinical, pathological, surgical, and imaging information, and extend beyond the current staging system to assist clinicians in identifying patients who could benefit from additional therapy immediately after surgery.\nPURPOSE: We aimed to determine whether a deep learning model (DLM) integrating FDG PET and CT imaging from the thoracic cavity along with clinical, surgical, and pathological information can predict NSCLC recurrence-free survival (RFS) and stratify patients into risk groups better than conventional staging.\nMATERIALS AND METHODS: Surgically resected NSCLC patients enrolled between 2009 and 2018 were retrospectively analyzed from two academic institutions (local institution: 305 patients; external validation: 195 patients). The thoracic cavity (including the lungs, mediastinum, pleural interfaces, and thoracic vertebrae) was delineated on the preoperative FDG PET and CT images and combined with each patient's clinical, surgical, and pathological information. Using the local cohort of patients, a multi-modal DLM using these features was built in a training cohort (n = 225), tuned on a validation cohort (n = 45), and evaluated on testing (n = 35) and external validation (n = 195) cohorts to predict RFS and stratify patients into risk groups. The area under the curve (AUC), Kaplan-Meier curves, and log-rank test were used to assess the prognostic value of the model. The DLM's stratification performance was compared to the conventional staging stratification.\nRESULTS: The multi-modal DLM incorporating imaging, pathological, surgical, and clinical data predicted RFS in the testing cohort (AUC = 0.78 [95% CI:0.63-0.94]) and external validation cohort (AUC = 0.66 [95% CI:0.58-0.73]). The DLM significantly stratified patients into high, medium, and low-risk groups of RFS in both the testing and external validation cohorts (multivariable log-rank p < 0.001) and outperformed conventional staging. Conventional staging was unable to stratify patients into three distinct risk groups of RFS (testing: p = 0.94; external validation: p = 0.38). Lastly, the DLM displayed the ability to further stratify patients significantly into sub-risk groups within each stage in the testing (stage I: p = 0.02, stage II: p = 0.03) and external validation (stage I: p = 0.05, stage II: p = 0.03) cohorts.\nCONCLUSION: This is the first study to use multi-modality imaging along with clinical, surgical, and pathological data to predict RFS of NSCLC patients after surgery. The multi-modal DLM better stratified patients into risk groups of poor outcomes when compared to conventional staging and further stratified patients within each staging classification. This model has the potential to assist clinicians in better identifying patients that may benefit from additional therapy.",
    "abstract_zh": "翻译：<br><br>背景：早期非小细胞肺癌（NSCLC）患者通常接受手术作为主要治疗手段。然而，研究表明，相当一部分患者在切除术后会出现复发，从而增加死亡风险。癌症分期目前是评估患者预后的金标准，有助于临床医生确定可能从额外治疗中获益的患者。然而，用于确定癌症分期的医学影像已被证明包含未被充分利用的预后信息，这些信息可以补充临床数据，从而更好地识别高危NSCLC患者。目前迫切需要一种模型，该模型能够整合临床、病理、手术和影像信息，并超越现有的分期系统，以帮助临床医生识别那些在术后立即可能从额外治疗中获益的患者。<br><br>目的：本研究旨在确定，整合了胸腔FDG PET和CT影像以及临床、手术和病理信息的深度学习模型（DLM）是否能够比传统分期更好地预测NSCLC的无复发生存期（RFS）并对患者进行风险分层。<br><br>材料与方法：回顾性分析了2009年至2018年期间从两家学术机构招募的接受手术切除的NSCLC患者（本地机构：305名患者；外部验证：195名患者）。在术前FDG PET和CT影像上勾勒出胸腔（包括肺、纵隔、胸膜界面和胸椎），并结合每位患者的临床、手术和病理信息。利用本地患者队列，在训练队列（n = 225）中构建了一个使用这些特征的多模态DLM，在验证队列（n = 45）中进行调整，并在测试队列（n = 35）和外部验证队列（n = 195）中进行评估，以预测RFS并将患者分层到风险组中。使用曲线下面积（AUC）、Kaplan-Meier曲线和log-rank检验来评估该模型的预后价值。将DLM的分层性能与传统分期分层进行比较。<br><br>结果：结合了影像、病理、手术和临床数据的多模态DLM预测了测试队列（AUC = 0.78 [95% CI: 0.63-0.94]）和外部验证队列（AUC = 0.66 [95% CI: 0.58-0.73]）中的RFS。DLM在测试和外部验证队列中均将患者显著分层为RFS的高、中、低风险组（多变量log-rank p < 0.001），并且优于传统分期。传统分期无法将患者分层为三个不同的RFS风险组（测试：p = 0.94；外部验证：p = 0.38）。最后，DLM显示出在测试（I期：p = 0.02，II期：p = 0.03）和外部验证（I期：p = 0.05，II期：p = 0.03）队列中的每个分期内进一步显著地将患者分层为亚风险组的能力。<br><br>结论：这是首个使用多模态影像以及临床、手术和病理数据来预测NSCLC患者术后RFS的研究。与传统分期相比，多模态DLM能更好地将患者分层为预后不良的风险组，并进一步将患者分层到每个分期分类中。该模型具有帮助临床医生更好地识别可能从额外治疗中获益的患者的潜力。",
    "summary_zh": "该研究开发了一种多模态深度学习模型（DLM），该模型整合了胸腔FDG PET/CT影像以及临床、手术和病理信息，用于预测早期NSCLC患者术后的无复发生存期（RFS）并进行风险分层。结果表明，该DLM在预测RFS和风险分层方面优于传统分期，能够在测试集和外部验证集中将患者显著地分为高、中、低风险组，并且能够在传统分期的基础上进一步细化风险分层。该模型有望辅助临床医生识别术后需要额外治疗的NSCLC患者。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17862",
    "link": "https://doi.org/10.1002/mp.17862"
  },
  {
    "title": "Evaluation of a motion correction algorithm in lung cancer PET/CT: Phantom validation and patient studies.",
    "authors": [
      "Ziyang Wang",
      "Jianjing Liu",
      "Di Lu",
      "Guoqing Sui",
      "Yaya Wang",
      "Lina Tong",
      "Xueyao Liu",
      "Yan Zhang",
      "Jie Fu",
      "Wengui Xu",
      "Dong Dai"
    ],
    "abstract": "BACKGROUND: Data-driven gating (DDG) is an emerging technology that can reduce the respiratory motion artifacts in positron emission tomography (PET) images.\nPURPOSE: The aim of this study is to use phantom and patient data to validate the performance of DDG with a motion correction algorithm based on the reconstruct, register, and average (RRA) method.\nMETHODS: A customized motion platform drove the phantom (five spheres with diameters of 10-28 mm) using a periodic motion that had a duration of 3-5 s and amplitudes of 2-4 cm. Normalized ratio of ungated and RRA PET relative to the ground-truth static PET was calculated for RSUVmax, RSUVmean, RSUVpeak, RVolume, and relative contrast-to-noise ratio (RCNR). Additionally, 30 lung cancer patients with 76 lung lesions less than 3 cm in diameter were prospectively studied. The overall image quality of patient examination was scored using a 5-point scale by two radiologists. SUVmax, SUVmean, SUVpeak, volume, and CNR of lesions measured in ungated and RRA PET were compared, and subgroup analysis was conducted.\nRESULTS: In RRA PET images, motion artifacts of the spheres in the phantom were effectively mitigated, regardless of changes in movement amplitudes or duration. For all spheres with different ranges of motion and cycles, RSUVmax, RSUVmean, RSUVpeak, and RCNR increased significantly (p ≤ 0.001) and RVolume decreased significantly (p < 0.001) in RRA PET images. The average radiologist scores of image quality were 3.90 ± 0.86 with RRA PET, and 3.03 ± 1.19 with ungated PET. In RRA PET images, the SUVmax (p < 0.001), SUVmean (p < 0.001), SUVpeak (p < 0.001), and CNR (p < 0.001) of the lesions increased, while the volume (p < 0.001) of the lesions decreased. Δ%SUVmax, Δ%SUVmean, Δ%SUVpeak, and Δ%CNR of the lesions increased by 3.9%, 6.5%, 5.6%, and 4.3%, respectively, while Δ%Volume of the lesions decreased by 18.4%. Subgroup analysis showed that in lesions in the upper and middle lobes, only SUVpeak (p < 0.001) significantly increased by 5.6% in RRA PET, while their volume (p < 0.001) notably decreased by 12.4% (p < 0.001).\nCONCLUSION: DDG integrated with RRA motion correction algorithm can effectively mitigate motion artifacts, thus enhancing the quantification accuracy and visual quality of images in lung cancer PET/CT.",
    "abstract_zh": "**翻译：**<br><br>背景：数据驱动门控（DDG）是一种新兴技术，可以减少正电子发射断层扫描（PET）图像中的呼吸运动伪影。<br><br>目的：本研究旨在利用体模和患者数据，验证DDG与基于重建、配准和平均（RRA）方法的运动校正算法的性能。<br><br>方法：定制的运动平台驱动体模（五个直径为10-28毫米的球体），采用周期性运动，其持续时间为3-5秒，幅度为2-4厘米。计算了相对于真实静态PET的未门控和RRA PET的归一化比率，指标包括RSUVmax、RSUVmean、RSUVpeak、RVolume和相对信噪比（RCNR）。此外，前瞻性地研究了30名患有76个直径小于3厘米的肺部病灶的肺癌患者。由两位放射科医生使用5分制对患者检查的总体图像质量进行评分。比较了未门控和RRA PET中病灶的SUVmax、SUVmean、SUVpeak、体积和CNR，并进行了亚组分析。<br><br>结果：在RRA PET图像中，无论运动幅度或持续时间如何变化，体模中球体的运动伪影都得到了有效缓解。对于所有具有不同运动范围和周期的球体，RRA PET图像中的RSUVmax、RSUVmean、RSUVpeak和RCNR显著增加（p≤0.001），RVolume显著降低（p<0.001）。放射科医生对RRA PET图像质量的平均评分是3.90±0.86，对未门控PET图像质量的平均评分是3.03±1.19。在RRA PET图像中，病灶的SUVmax（p<0.001）、SUVmean（p<0.001）、SUVpeak（p<0.001）和CNR（p<0.001）增加，而病灶的体积（p<0.001）减小。病灶的Δ%SUVmax、Δ%SUVmean、Δ%SUVpeak和Δ%CNR分别增加了3.9%、6.5%、5.6%和4.3%，而病灶的Δ%Volume减少了18.4%。亚组分析显示，在上叶和中叶的病灶中，只有SUVpeak（p<0.001）在RRA PET中显著增加了5.6%，而它们的体积（p<0.001）显著减少了12.4%（p<0.001）。<br><br>结论：DDG与RRA运动校正算法相结合可以有效地减轻运动伪影，从而提高肺癌PET/CT图像的定量准确性和视觉质量。",
    "summary_zh": "本研究验证了数据驱动门控(DDG)结合重建、配准和平均(RRA)运动校正算法在肺癌PET/CT成像中的性能。结果表明，该方法能有效减少运动伪影，提高图像质量和定量准确性，包括提高SUVmax、SUVmean、SUVpeak和CNR，并减小病灶体积，尤其是在肺上叶和中叶。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17846",
    "link": "https://doi.org/10.1002/mp.17846"
  },
  {
    "title": "Hepatocellular carcinoma 18F-FDG PET/CT kinetic parameter estimation based on the advantage actor-critic algorithm.",
    "authors": [
      "Jianfeng He",
      "Siming Li",
      "Yiwei Xiong",
      "Yu Yao",
      "Siyu Wang",
      "Sidan Wang",
      "Shaobo Wang"
    ],
    "abstract": "BACKGROUND: Kinetic parameters estimated with dynamic 18F-fluorodeoxyglucose (18F-FDG) positron emission tomography (PET)/computed tomography (CT) help characterize hepatocellular carcinoma (HCC), and deep reinforcement learning (DRL) can improve kinetic parameter estimation.\nPURPOSE: The advantage actor-critic (A2C) algorithm is a DRL algorithm with neural networks that seek the optimal parameters. The aim of this study was to preliminarily assess the role of the A2C algorithm in estimating the kinetic parameters of 18F-FDG PET/CT in patients with HCC.\nMATERIALS AND METHODS: 18F-FDG PET data from 14 liver tissues and 17 HCC tumors obtained via a previously developed, abbreviated acquisition protocol (5-min dynamic PET/CT imaging supplemented with 1-min static imaging at 60 min) were prospectively collected. The A2C algorithm was used to estimate kinetic parameters with a reversible double-input, three-compartment model, and the results were compared with those of the conventional nonlinear least squares (NLLS) algorithm. Fitting errors were compared via the root-mean-square errors (RMSEs) of the time activity curves (TACs).\nRESULTS: Significant differences in K1, k2, k3, k4, fa, and vb according to the A2C algorithm and k3, fa, and vb according to the NLLS algorithm were detected between HCC and normal liver tissues (all p < 0.05). Furthermore, A2C demonstrated superior diagnostic performance over NLLS in terms of k3 and vb (both p < 0.05 in the Delong test). Notably, A2C yielded a smaller fitting error for normal liver tissue (0.62 ± 0.24 vs. 1.04 ± 1.00) and HCC tissue (1.40 ± 0.42 vs. 1.51 ± 0.97) than did NLLS.\nCONCLUSIONS: Compared with the conventional postreconstruction NLLS method, the A2C algorithm can more precisely estimate 18F-FDG kinetic parameters with a reversible double-input, three-compartment model for HCC tumors, attaining better TAC fitting with a lower RMSE.",
    "abstract_zh": "**翻译：**<br><br>背景：利用动态18F-氟代脱氧葡萄糖 (18F-FDG) 正电子发射断层扫描 (PET)/计算机断层扫描 (CT) 估计的动力学参数有助于表征肝细胞癌 (HCC)，而深度强化学习 (DRL) 可以改善动力学参数的估计。<br><br>目的：优势行动者-评论家 (A2C) 算法是一种利用神经网络寻找最优参数的 DRL 算法。本研究旨在初步评估 A2C 算法在估计 HCC 患者 18F-FDG PET/CT 动力学参数中的作用。<br><br>材料与方法：前瞻性地收集了通过先前开发的简短采集方案（5 分钟动态 PET/CT 影像，辅以 60 分钟时的 1 分钟静态影像）获得的 14 个肝脏组织和 17 个 HCC 肿瘤的 18F-FDG PET 数据。采用 A2C 算法，利用可逆双输入三室模型估计动力学参数，并将结果与传统的非线性最小二乘 (NLLS) 算法进行比较。通过时间活性曲线 (TAC) 的均方根误差 (RMSE) 比较拟合误差。<br><br>结果：A2C 算法的 K1、k2、k3、k4、fa 和 vb 以及 NLLS 算法的 k3、fa 和 vb 在 HCC 和正常肝脏组织之间存在显著差异（所有 p < 0.05）。此外，在 k3 和 vb 方面，A2C 显示出优于 NLLS 的诊断性能（DeLong 检验中均为 p < 0.05）。值得注意的是，A2C 在正常肝脏组织 (0.62 ± 0.24 vs. 1.04 ± 1.00) 和 HCC 组织 (1.40 ± 0.42 vs. 1.51 ± 0.97) 中均产生了比 NLLS 更小的拟合误差。<br><br>结论：与传统的后重建 NLLS 方法相比，A2C 算法可以更精确地估计 HCC 肿瘤的 18F-FDG 动力学参数，采用可逆双输入三室模型，并获得更好的 TAC 拟合，具有更低的 RMSE。",
    "summary_zh": "本研究评估了基于深度强化学习的A2C算法在估计HCC患者18F-FDG PET/CT动力学参数中的作用。研究结果表明，A2C算法在区分HCC和正常肝脏组织方面优于传统的NLLS算法，并能更精确地估计动力学参数，获得更好的TAC拟合和更低的RMSE，提示A2C算法在HCC的动态PET成像分析中具有潜在的应用价值。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17851",
    "link": "https://doi.org/10.1002/mp.17851"
  }
]