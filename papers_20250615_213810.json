[
  {
    "title": "Physical phantom validation of clustering-initiated factorization in dynamic PET.",
    "authors": [
      "Valerie Kobzarenko",
      "Suzanne L Baker",
      "Mustafa Janabi",
      "Woon-Seng Choong",
      "Grant T Gullberg",
      "Youngho Seo",
      "Rostyslav Boutchko",
      "Debasis Mitra"
    ],
    "abstract": "BACKGROUND: Dynamic positron emission tomography (PET) enables the quantification of physiological parameters of radiotracers employed in the investigation of neuropsychiatric disorders. We previously introduced a factor analysis-based algorithm, Cluster-Initialized Factor Analysis (CIFA), designed to overcome the problem of specifying reference regions. CIFA is capable of automatically extracting distinct radiotracer binding distributions across many modalities based on the differences in tracer dynamics, and thus can distinguish regions of specific- and non-specific binding without requiring prior segmentation.\nPURPOSE: Our goal is to quantitatively validate the ability of CIFA to resolve different dynamic biological processes by comparing the output of the algorithm to an independent benchmark. As an intermediate goal, we aim to create a physical phantom capable of modeling unique aspects of dynamic imaging and to use this phantom as the benchmark in evaluating CIFA.\nMETHODS: CIFA was used to reconstruct 18F-flortaucipir dynamic brain PET datasets acquired at Lawrence Berkeley National Lab. The resulting factor curves served as the foundation for creating dynamic input time-activity curve (TAC) combinations in a physical brain phantom specifically constructed for this purpose. The phantom represented three components: two overlapping tissue types and free radiotracer, constructed with a combination of small hydraulic elements. The physical components were scanned separately to generate a library of images, allowing us to reproduce scans of any duration with prescribed dynamics and realistic partial volume effects. The phantom was designed to produce noisy instances with compartment mixing of dynamic scans with desired activity TACs for free, non-specifically bound, and specifically bound radiotracers. Ten distinct dynamic simulations with varying levels of TAC similarity were estimated with CIFA.\nRESULTS: We directly evaluated CIFA's performance in analyzing each of the 10 dynamic datasets by computing the Pearson correlation coefficient between the estimated outputs and the ground truth tissue TACs and corresponding tissue distributions. For seven out of 10 modeled dynamics, which captured the full spectrum of realistically expected tissue TAC shapes, the curve correlation of the specific binding tissue was above 95%.\nCONCLUSIONS: This work formulated an innovative process by combining a physical phantom design with PET images for evaluating the application of CIFA in the extraction of dynamic TACs from dynamic PET image data. In most cases the CIFA algorithm accurately reproduced the dynamics of the phantom simulated data.",
    "abstract_zh": "**翻译：**<br><br>**背景：** 动态正电子发射断层扫描 (PET) 可以量化放射性示踪剂的生理参数，这些示踪剂用于神经精神疾病的研究。我们之前引入了一种基于因子分析的算法，即聚类初始化因子分析 (CIFA)，旨在克服指定参考区域的问题。 CIFA 能够基于示踪剂动力学的差异，自动提取跨多种模态的不同放射性示踪剂结合分布，从而区分特异性结合和非特异性结合区域，而无需事先进行分割。<br><br>**目的：** 我们的目标是通过将算法的输出与独立的基准进行比较，来定量验证 CIFA 解析不同动态生物过程的能力。作为一个中间目标，我们旨在创建一个物理模型，能够模拟动态成像的独特方面，并使用该模型作为评估 CIFA 的基准。<br><br>**方法：** CIFA 用于重建在劳伦斯伯克利国家实验室获取的 18F-flortaucipir 动态脑 PET 数据集。得到的因子曲线构成了在专门为此目的而构建的物理脑模型中创建动态输入时间-活动曲线 (TAC) 组合的基础。该模型代表三个组成部分：两种重叠的组织类型和游离的放射性示踪剂，由小型液压元件组合而成。物理组件被单独扫描以生成图像库，从而使我们能够重现任何持续时间的扫描，并具有规定的动力学和真实的偏容积效应。该模型旨在产生具有动态扫描的隔室混合的噪声实例，并具有自由、非特异性结合和特异性结合的放射性示踪剂的期望活动 TAC。CIFA 估计了十个具有不同 TAC 相似度水平的不同动态模拟。<br><br>**结果：** 我们通过计算估计输出与真实组织 TAC 和相应组织分布之间的 Pearson 相关系数，直接评估了 CIFA 在分析 10 个动态数据集中的每一个数据集时的性能。对于 10 个建模动力学中的 7 个，这些动力学捕捉了实际预期的组织 TAC 形状的完整范围，特异性结合组织的曲线相关性高于 95%。<br><br>**结论：** 这项工作通过将物理模型设计与 PET 图像相结合，制定了一种创新的流程，用于评估 CIFA 在从动态 PET 图像数据中提取动态 TAC 中的应用。在大多数情况下，CIFA 算法准确地重现了模型模拟数据的动力学。",
    "summary_zh": "该研究旨在验证CIFA算法在动态PET图像分析中提取动态时间-活动曲线（TAC）的能力。研究人员构建了一个物理脑模型，模拟了两种重叠组织类型和游离放射性示踪剂的动态过程，作为评估CIFA的基准。通过对CIFA在模拟数据上的表现进行评估，结果表明CIFA在大多数情况下能够准确地重现模拟数据的动力学，尤其是在特异性结合组织的TAC曲线相关性方面表现优异。该研究为CIFA在神经精神疾病研究中应用提供了支持，并为动态PET图像分析的算法评估提供了一种创新方法。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17902",
    "link": "https://doi.org/10.1002/mp.17902"
  },
  {
    "title": "Generation of synthetic CT from MRI for MRI-based attenuation correction of brain PET images using radiomics and machine learning.",
    "authors": [
      "Amin Hoseinipourasl",
      "Gholam-Ali Hossein-Zadeh",
      "Peyman Sheikhzadeh",
      "Hossein Arabalibeik",
      "Shaghayegh Karimi Alavijeh",
      "Habib Zaidi",
      "Mohammad Reza Ay"
    ],
    "abstract": "BACKGROUND: Accurate quantitative PET imaging in neurological studies requires proper attenuation correction. MRI-guided attenuation correction in PET/MRI remains challenging owing to the lack of direct relationship between MRI intensities and linear attenuation coefficients.\nPURPOSE: This study aims at generating accurate patient-specific synthetic CT volumes, attenuation maps, and attenuation correction factor (ACF) sinograms with continuous values utilizing a combination of machine learning algorithms, image processing techniques, and voxel-based radiomics feature extraction approaches.\nMETHODS: Brain MR images of ten healthy volunteers were acquired using IR-pointwise encoding time reduction with radial acquisition (IR-PETRA) and VIBE-Dixon techniques. synthetic CT (SCT) images, attenuation maps, and attenuation correction factors (ACFs) were generated using the LightGBM, a fast and accurate machine learning algorithm, from the radiomics-based and image processing-based feature maps of MR images. Additionally, ultra-low-dose CT images of the same volunteers were acquired and served as the standard of reference for evaluation. The SCT images, attenuation maps, and ACF sinograms were assessed using qualitative and quantitative evaluation metrics and compared against their corresponding reference images, attenuation maps, and ACF sinograms.\nRESULTS: The voxel-wise and volume-wise comparison between synthetic and reference CT images yielded an average mean absolute error of 60.75 ± 8.8 HUs, an average structural similarity index of 0.88 ± 0.02, and an average peak signal-to-noise ratio of 32.83 ± 2.74 dB. Additionally, we compared MRI-based attenuation maps and ACF sinograms with their CT-based counterparts, revealing average normalized mean absolute errors of 1.48% and 1.33%, respectively.\nCONCLUSION: Quantitative assessments indicated higher correlations and similarities between LightGBM-synthesized CT and Reference CT images. Moreover, the cross-validation results showed the possibility of producing accurate SCT images, MRI-based attenuation maps, and ACF sinograms. This might spur the implementation of MRI-based attenuation correction on PET/MRI and dedicated brain PET scanners with lower computational time using CPU-based processors.",
    "abstract_zh": "背景：在神经学研究中，准确的定量PET成像需要适当的衰减校正。由于MRI强度与线性衰减系数之间缺乏直接关系，PET/MRI中MRI引导的衰减校正仍然具有挑战性。<br><br>目的：本研究旨在通过结合机器学习算法、图像处理技术和基于体素的放射组学特征提取方法，生成准确的、患者特异性的、具有连续值的合成CT体积、衰减图和衰减校正因子（ACF）正弦图。<br><br>方法：利用IR-PETRA和VIBE-Dixon技术采集了10名健康志愿者的脑部MR图像。利用LightGBM（一种快速准确的机器学习算法），从MR图像的基于放射组学和基于图像处理的特征图中生成合成CT（SCT）图像、衰减图和衰减校正因子（ACF）。此外，还采集了同一批志愿者的超低剂量CT图像，作为评估的参考标准。使用定性和定量评估指标评估SCT图像、衰减图和ACF正弦图，并与相应的参考图像、衰减图和ACF正弦图进行比较。<br><br>结果：合成CT图像和参考CT图像之间的体素和体积比较显示，平均绝对误差为60.75 ± 8.8 HUs，平均结构相似性指数为0.88 ± 0.02，平均峰值信噪比为32.83 ± 2.74 dB。此外，我们将基于MRI的衰减图和ACF正弦图与基于CT的相应图像进行比较，发现平均归一化平均绝对误差分别为1.48%和1.33%。<br><br>结论：定量评估表明，LightGBM合成的CT图像与参考CT图像之间具有更高的相关性和相似性。此外，交叉验证结果表明，有可能生成准确的SCT图像、基于MRI的衰减图和ACF正弦图。这可能会推动PET/MRI和专用脑部PET扫描仪上基于MRI的衰减校正的实施，并在基于CPU的处理器上以更低的计算时间实现。",
    "summary_zh": "本研究提出了一种利用LightGBM机器学习算法，结合放射组学和图像处理技术，从MRI图像生成高质量合成CT（SCT）图像，进而进行衰减校正的方法。实验结果表明，该方法生成的SCT图像与参考CT图像具有高度一致性，且基于此生成的衰减图和衰减校正因子（ACF）正弦图也具有较高的准确性。这有望在PET/MRI和专用脑部PET扫描仪中实现更快速、更准确的MRI引导的衰减校正，降低计算成本。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17867",
    "link": "https://doi.org/10.1002/mp.17867"
  },
  {
    "title": "Impact of tracer uptake rate on quantification accuracy of myocardial blood flow in PET: A simulation study.",
    "authors": [
      "Xiaotong Hong",
      "Amirhossein Sanaat",
      "Yazdan Salimi",
      "René Nkoulou",
      "Hossein Arabi",
      "Lijun Lu",
      "Habib Zaidi"
    ],
    "abstract": "BACKGROUND: Cardiac perfusion PET is commonly used to assess ischemia and cardiovascular risk, which enables quantitative measurements of myocardial blood flow (MBF) through kinetic modeling. However, the estimation of kinetic parameters is challenging due to the noisy nature of short dynamic frames and limited sample data points.\nPURPOSE: This work aimed to investigate the errors in MBF estimation in PET through a simulation study and to evaluate different parameter estimation approaches, including a deep learning (DL) method.\nMATERIALS AND METHODS: Simulated studies were generated using digital phantoms based on cardiac segmentations from 55 clinical CT images. We employed the irreversible 2-tissue compartmental model and simulated dynamic 13N-ammonia PET scans under both rest and stress conditions (220 cases each). The simulations covered a rest K1 range of 0.6 to 1.2 and a stress K1 range of 1.2 to 3.6 (unit: mL/min/g) in the myocardium. A transformer-based DL model was trained on the simulated dataset to predict parametric images (PIMs) from noisy PET image frames and was validated using 5-fold cross-validation. We compared the DL method with the voxel-wise nonlinear least squares (NLS) fitting applied to the dynamic images, using either Gaussian filter (GF) smoothing (GF-NLS) or a dynamic nonlocal means (DNLM) algorithm for denoising (DNLM-NLS). Two patients with coronary CT angiography (CTA) and fractional flow reserve (FFR) were enrolled to test the feasibility of applying DL models on clinical PET data.\nRESULTS: The DL method showed clearer image structures with reduced noise compared to the traditional NLS-based methods. In terms of mean absolute relative error (MARE), as the rest K1 values increased from 0.6 to 1.2 mL/min/g, the overall bias in myocardium K1 estimates decreased from approximately 58% to 45% for the NLS-based methods while the DL method showed a reduction in MARE from 42% to 18%. For stress data, as the stress K1 decreased from 3.6 to 1.2 mL/min/g, the MARE increased from 30% to 70% for the GF-NLS method. In contrast, both the DNLM-NLS (average: 42%) and the DL methods (average: 20%) demonstrated significantly smaller MARE changes as stress K1 varied. Regarding the regional mean bias (±standard deviation), the GF-NLS method had a bias of 6.30% (±8.35%) of rest K1, compared to 1.10% (±8.21%) for DNLM-NLS and 6.28% (±14.05%) for the DL method. For the stress K1, the GF-NLS showed a mean bias of 10.72% (±9.34%) compared to 1.69% (±8.82%) for DNLM-NLS and -10.55% (±9.81%) for the DL method.\nSIGNIFICANCE: This study showed that an increase in the tracer uptake rate (K1) corresponded to improved accuracy and precision in MBF quantification, whereas lower tracer uptake resulted in higher noise in dynamic PET and poorer parameter estimates. Utilizing denoising techniques or DL approaches can mitigate noise-induced bias in PET parametric imaging.",
    "abstract_zh": "**背景：** 心脏灌注PET常用于评估缺血和心血管风险，它可以通过动力学建模对心肌血流量（MBF）进行定量测量。然而，由于短时动态图像的噪声特性和有限的采样数据点，动力学参数的估计具有挑战性。<br><br>**目的：** 本研究旨在通过模拟研究调查PET中MBF估计的误差，并评估不同的参数估计方法，包括一种深度学习（DL）方法。<br><br>**材料与方法：** 基于55例临床CT图像的心脏分割，使用数字体模生成模拟研究数据。我们采用不可逆的二室模型，并模拟了静息和负荷两种状态下的动态<sup>13</sup>N-氨PET扫描（每种状态220例）。模拟覆盖了静息状态下0.6至1.2 mL/min/g的心肌K1范围，以及负荷状态下1.2至3.6 mL/min/g的心肌K1范围。在模拟数据集上训练了一个基于Transformer的DL模型，用于从嘈杂的PET图像帧中预测参数图像（PIMs），并使用5折交叉验证进行验证。我们将DL方法与应用于动态图像的体素级非线性最小二乘（NLS）拟合进行了比较，NLS拟合分别使用了高斯滤波器（GF）平滑（GF-NLS）或动态非局部均值（DNLM）算法进行去噪（DNLM-NLS）。纳入了两名接受了冠状动脉CT血管造影（CTA）和血流储备分数（FFR）的患者，以测试将DL模型应用于临床PET数据的可行性。<br><br>**结果：** 与传统的基于NLS的方法相比，DL方法显示出更清晰的图像结构，并减少了噪声。在平均绝对相对误差（MARE）方面，随着静息K1值从0.6增加到1.2 mL/min/g，基于NLS方法的心肌K1估计的总体偏差从大约58%降至45%，而DL方法的MARE从42%降至18%。对于负荷数据，随着负荷K1从3.6降至1.2 mL/min/g，GF-NLS方法的MARE从30%增加到70%。相比之下，DNLM-NLS（平均值：42%）和DL方法（平均值：20%）均表现出明显较小的MARE变化，不受负荷K1变化的影响。关于区域平均偏差（±标准差），GF-NLS方法的静息K1偏差为6.30%（±8.35%），而DNLM-NLS为1.10%（±8.21%），DL方法为6.28%（±14.05%）。对于负荷K1，GF-NLS显示出10.72%（±9.34%）的平均偏差，而DNLM-NLS为1.69%（±8.82%），DL方法为-10.55%（±9.81%）。<br><br>**意义：** 这项研究表明，示踪剂摄取率（K1）的增加对应于MBF量化中准确性和精度的提高，而较低的示踪剂摄取导致动态PET中更高的噪声和较差的参数估计。利用去噪技术或DL方法可以减轻PET参数成像中噪声引起的偏差。",
    "summary_zh": "该研究通过模拟和初步临床数据验证，比较了深度学习（DL）方法和传统非线性最小二乘法（NLS）在PET心肌血流量（MBF）定量分析中的性能。结果表明，DL方法在降低噪声、提高参数估计准确性方面优于传统方法，尤其是在低示踪剂摄取情况下。该研究强调了噪声对PET定量分析的影响，并提出了使用去噪技术或DL方法来改善参数估计的思路。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17871",
    "link": "https://doi.org/10.1002/mp.17871"
  },
  {
    "title": "Instantaneous in vivo distal edge verification in intensity-modulated proton therapy by means of PET imaging.",
    "authors": [
      "Brian Zapien-Campos",
      "Zahra Ahmadi Ganjeh",
      "Giuliano Perotti-Bernardini",
      "Jeffrey Free",
      "Stefan Both",
      "Peter Dendooven"
    ],
    "abstract": "BACKGROUND: Intensity-modulated proton therapy (IMPT) holds promise for improving outcomes in head-and-neck cancer (HNC) patients by enhancing organ-at-risk (OAR) sparing. A key challenge in IMPT is ensuring an accurate dose delivery at the distal edge of the tumor, where the steep dose gradients make treatment precision highly sensitive to uncertainties in both proton range and patient setup. Thus, IMPT conformality is increased by incorporating robust margins in the treatment optimization. However, an increment in the plan robustness could lead to an OAR overdosing. Therefore, an accurate distal edge verification during dose delivery is crucial to increase IMPT conformality by reducing optimization settings in treatment planning.\nPURPOSE: This work aims to evaluate, in a quasi-clinical setting, a novel approach for accurate instantaneous proton beam distal edge verification in IMPT by means of spot-by-spot positron emission tomography (PET) imaging.\nMETHODS: An anthropomorphic head and neck phantom CIRS-731 HN was irradiated at the head and neck region. The targets were defined as 4 cm diameter spheres. A 60-ms delay was introduced between the proton beam spots in order to enable the spot-by-spot coincidence detection of the 511-keV photons resulting from positron annihilation following the positron emission from very short-lived positron-emitting, mainly 12N (T1/2  = 11.0 ms). Additionally, modified irradiations were carried out using solid water slabs of 2 and 5 mm thickness in the beam path to assess the precision of the approach for detecting range deviations. The positron activity range (PAR) was determined from the 50% distal fall-off position of the 1D longitudinal positron activity profile derived from the 2D image reconstructions. Furthermore, Monte Carlo (MC) simulations were performed using an in-house RayStation/GATE MC framework to predict the positron activity images and verify the PAR measurements.\nRESULTS: PAR measurements achieved a precision between 1.5 and 3.6 mm (at 1.5σ clinical level) at the beam spot level within sub-second time scales. Measured PAR shifts of 1.6-2.1  and 4.2--.7 mm were observed with the 2- and 5-mm thickness range shifters, respectively, aligning with the corresponding proton dose range (PDR) shifts of 1.3-1.8 and 3.9-4.3 mm. The simulated PAR agrees with the measured PARs, showing an average range difference of ∼0.4 mm.\nCONCLUSION: This study demonstrated the feasibility of instantaneous distal edge verification using PET imaging by introducing beam spot delays during dose delivery. The findings represent a first step toward the clinical implementation of instantaneous in vivo distal edge verification. The approach contributes to the development of real-time range verification aimed at improving IMPT treatments by mitigating range and setup uncertainties, thereby reducing dose to organs-at-risk and ultimately enhancing patient outcomes.",
    "abstract_zh": "**翻译：**<br><br>**背景：** 调强质子治疗 (IMPT) 有望通过提高危及器官 (OAR) 的保护，改善头颈癌 (HNC) 患者的治疗效果。IMPT 的一个关键挑战是确保在肿瘤远端边缘实现精确的剂量输送，因为该区域陡峭的剂量梯度使得治疗精度对质子射程和患者摆位的不确定性高度敏感。因此，通过在治疗优化中加入稳健的边缘，可以提高 IMPT 的适形性。然而，计划稳健性的增加可能会导致危及器官的过度照射。因此，在剂量输送过程中进行精确的远端边缘验证对于提高 IMPT 的适形性至关重要，这可以通过减少治疗计划中的优化设置来实现。<br><br>**目的：** 本研究旨在在准临床环境下，评估一种用于在IMPT中通过逐点正电子发射断层扫描 (PET) 成像实现精确的瞬时质子束远端边缘验证的新方法。<br><br>**方法：** 在头颈部区域照射一个人体尺寸的头颈部模型 CIRS-731 HN。目标被定义为直径 4 厘米的球体。在质子束斑点之间引入 60 毫秒的延迟，以便能够逐点进行重合检测，检测由极短寿命的正电子发射体（主要为 12N (T1/2 = 11.0 毫秒)）的正电子湮灭产生的 511 keV 光子。此外，进行了修改后的照射，在光束路径中使用 2 毫米和 5 毫米厚度的固体水板，以评估该方法检测射程偏差的精度。正电子活性射程 (PAR) 由 2D 图像重建得到的 1D 纵向正电子活性分布的 50% 远端下降位置确定。此外，使用内部 RayStation/GATE MC 框架进行蒙特卡洛 (MC) 模拟，以预测正电子活性图像并验证 PAR 测量结果。<br><br>**结果：** PAR 测量在亚秒级的时间尺度内，在光束斑点水平上实现了 1.5 至 3.6 毫米（在 1.5σ 临床水平上）的精度。在使用 2 毫米和 5 毫米厚度的射程偏移器时，观察到 1.6-2.1 毫米和 4.2-4.7 毫米的测量 PAR 偏移，与相应的 1.3-1.8 毫米和 3.9-4.3 毫米的质子剂量射程 (PDR) 偏移一致。模拟的 PAR 与测量的 PAR 一致，显示平均射程差约为 0.4 毫米。<br><br>**结论：** 本研究证明了通过在剂量输送过程中引入光束斑点延迟，使用 PET 成像进行瞬时远端边缘验证的可行性。这些发现代表了朝着瞬时体内远端边缘验证的临床实施迈出的第一步。该方法有助于开发实时射程验证技术，旨在通过减轻射程和摆位不确定性来改善 IMPT 治疗，从而减少危及器官的剂量，并最终改善患者的治疗效果。",
    "summary_zh": "该研究探索了一种利用逐点PET成像技术，在调强质子治疗(IMPT)中实现瞬时、精确的质子束远端边缘验证的新方法。通过对头颈部模型进行照射实验和蒙特卡洛模拟，证明了该方法能够以亚秒级的时间分辨率和较高的精度检测质子射程的偏差。该技术有望用于实时射程验证，降低危及器官的剂量，并改善IMPT治疗效果。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17850",
    "link": "https://doi.org/10.1002/mp.17850"
  },
  {
    "title": "Modeling inter-reader variability in clinical target volume delineation for soft tissue sarcomas using diffusion model.",
    "authors": [
      "Yafei Dong",
      "Thibault Marin",
      "Yue Zhuo",
      "Elie Najem",
      "Arnaud Beddok",
      "Laura Rozenblum",
      "Maryam Moteabbed",
      "Kira Grogg",
      "Fangxu Xing",
      "Jonghye Woo",
      "Yen-Lin E Chen",
      "Ruth Lim",
      "Xiaofeng Liu",
      "Chao Ma",
      "Georges El Fakhri"
    ],
    "abstract": "BACKGROUND: Accurate delineation of the clinical target volume (CTV) is essential in the radiotherapy treatment of soft tissue sarcomas. However, this process is subject to inter-reader variability due to the need for clinical assessment of risk and extent of potential microscopic spread. This can lead to inconsistencies in treatment planning, potentially impacting treatment outcomes. Most existing automatic CTV delineation methods do not account for this variability and can only generate a single CTV for each case.\nPURPOSE: This study aims to develop a deep learning-based technique to generate multiple CTV contours for each case, simulating the inter-reader variability in the clinical practice.\nMETHODS: We employed a publicly available dataset consisting of fluorodeoxyglucose positron emission tomography (FDG-PET), x-ray computed tomography (CT), and pre-contrast T1-weighted magnetic resonance imaging (MRI) scans from 51 patients with soft tissue sarcoma, along with an independent validation set containing five additional patients. An experienced reader drew a contour of the gross tumor volume (GTV) for each patient based on multi-modality images. Subsequently, two additional readers, together with the first one, were responsible for contouring three CTVs in total based on the GTV. We developed a diffusion model-based deep learning method that is capable of generating arbitrary number of different and plausible CTVs to mimic the inter-reader variability in CTV delineation. The proposed model incorporates a separate encoder to extract features from the GTV masks, leveraging the critical role of GTV information in accurate CTV delineation.\nRESULTS: The proposed diffusion model demonstrated superior performance with the highest Dice Index (0.902 compared to values below 0.881 for state-of-the-art models) and the best generalized energy distance (GED) (0.209 compared to values exceeding 0.221 for state-of-the-art models). It also achieved the second-highest recall and precision metrics among the compared ambiguous image segmentation models. Results from both datasets exhibited consistent trends, reinforcing the reliability of our findings. Additionally, ablation studies exploring different model structures and input configurations highlighted the significance of incorporating prior GTV information for accurate CTV delineation.\nCONCLUSIONS: The proposed diffusion model successfully generates multiple plausible CTV contours for soft tissue sarcomas, effectively capturing inter-reader variability in CTV delineation.",
    "abstract_zh": "**翻译：**<br><br>背景：在软组织肉瘤的放射治疗中，准确勾画临床靶区（CTV）至关重要。然而，由于需要对潜在的微观扩散风险和范围进行临床评估，这一过程容易受到阅片者间差异的影响。这可能导致治疗计划的不一致，进而潜在地影响治疗结果。目前大多数自动CTV勾画方法没有考虑到这种差异性，每个病例只能生成一个CTV。<br><br>目的：本研究旨在开发一种基于深度学习的技术，为每个病例生成多个CTV轮廓，模拟临床实践中阅片者间的差异。<br><br>方法：我们采用了一个公开的数据集，该数据集包含来自51名软组织肉瘤患者的氟代脱氧葡萄糖正电子发射断层扫描（FDG-PET）、X射线计算机断层扫描（CT）和预对比T1加权磁共振成像（MRI）扫描，以及包含另外5名患者的独立验证集。一位经验丰富的阅片者根据多模态图像为每位患者绘制了肉眼肿瘤体积（GTV）的轮廓。随后，另外两位阅片者与第一位阅片者一起，负责在GTV的基础上勾画总共三个CTV。我们开发了一种基于扩散模型的深度学习方法，该方法能够生成任意数量的不同且合理的CTV，以模拟CTV勾画中阅片者间的差异。所提出的模型整合了一个单独的编码器来提取GTV掩模的特征，利用GTV信息在准确CTV勾画中的关键作用。<br><br>结果：所提出的扩散模型表现出卓越的性能，具有最高的Dice指数（0.902，而最先进模型的值低于0.881）和最佳的广义能量距离（GED）（0.209，而最先进模型的值超过0.221）。在所比较的模糊图像分割模型中，它还获得了第二高的召回率和精确率指标。来自两个数据集的结果都表现出一致的趋势，增强了我们研究结果的可靠性。此外，探索不同模型结构和输入配置的消融研究突出了纳入先验GTV信息对于准确CTV勾画的重要性。<br><br>结论：所提出的扩散模型成功地为软组织肉瘤生成了多个合理的CTV轮廓，有效地捕捉了CTV勾画中阅片者间的差异。",
    "summary_zh": "本研究开发了一种基于扩散模型的深度学习方法，用于生成软组织肉瘤放射治疗中的多个临床靶区（CTV）轮廓，旨在模拟阅片者之间的差异。该模型利用GTV信息，并通过在公开数据集上的验证，在Dice指数和广义能量距离上均优于现有模型，表明其能有效捕捉CTV勾画的阅片者差异，为提高放射治疗计划的准确性和可靠性提供了可能。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17865",
    "link": "https://doi.org/10.1002/mp.17865"
  },
  {
    "title": "Thorax-encompassing multi-modality PET/CT deep learning model for resected lung cancer prognostication: A retrospective, multicenter study.",
    "authors": [
      "Jaryd R Christie",
      "Perrin Romine",
      "Karen Eddy",
      "Delphine L Chen",
      "Omar Daher",
      "Mohamed Abdelrazek",
      "Richard A Malthaner",
      "Mehdi Qiabi",
      "Rahul Nayak",
      "Paul Kinahan",
      "Viswam S Nair",
      "Sarah A Mattonen"
    ],
    "abstract": "BACKGROUND: Patients with early-stage non-small cell lung cancer (NSCLC) typically receive surgery as their primary form of treatment. However, studies have shown that a high proportion of these patients will experience a recurrence after their resection, leading to an increased risk of death. Cancer staging is currently the gold standard for establishing a patient's prognosis and can help clinicians determine patients who may benefit from additional therapy. However, medical images which are used to help determine the cancer stage, have been shown to hold unutilized prognostic information that can augment clinical data and better identify high-risk NSCLC patients. There remains an unmet need for models to incorporate clinical, pathological, surgical, and imaging information, and extend beyond the current staging system to assist clinicians in identifying patients who could benefit from additional therapy immediately after surgery.\nPURPOSE: We aimed to determine whether a deep learning model (DLM) integrating FDG PET and CT imaging from the thoracic cavity along with clinical, surgical, and pathological information can predict NSCLC recurrence-free survival (RFS) and stratify patients into risk groups better than conventional staging.\nMATERIALS AND METHODS: Surgically resected NSCLC patients enrolled between 2009 and 2018 were retrospectively analyzed from two academic institutions (local institution: 305 patients; external validation: 195 patients). The thoracic cavity (including the lungs, mediastinum, pleural interfaces, and thoracic vertebrae) was delineated on the preoperative FDG PET and CT images and combined with each patient's clinical, surgical, and pathological information. Using the local cohort of patients, a multi-modal DLM using these features was built in a training cohort (n = 225), tuned on a validation cohort (n = 45), and evaluated on testing (n = 35) and external validation (n = 195) cohorts to predict RFS and stratify patients into risk groups. The area under the curve (AUC), Kaplan-Meier curves, and log-rank test were used to assess the prognostic value of the model. The DLM's stratification performance was compared to the conventional staging stratification.\nRESULTS: The multi-modal DLM incorporating imaging, pathological, surgical, and clinical data predicted RFS in the testing cohort (AUC = 0.78 [95% CI:0.63-0.94]) and external validation cohort (AUC = 0.66 [95% CI:0.58-0.73]). The DLM significantly stratified patients into high, medium, and low-risk groups of RFS in both the testing and external validation cohorts (multivariable log-rank p < 0.001) and outperformed conventional staging. Conventional staging was unable to stratify patients into three distinct risk groups of RFS (testing: p = 0.94; external validation: p = 0.38). Lastly, the DLM displayed the ability to further stratify patients significantly into sub-risk groups within each stage in the testing (stage I: p = 0.02, stage II: p = 0.03) and external validation (stage I: p = 0.05, stage II: p = 0.03) cohorts.\nCONCLUSION: This is the first study to use multi-modality imaging along with clinical, surgical, and pathological data to predict RFS of NSCLC patients after surgery. The multi-modal DLM better stratified patients into risk groups of poor outcomes when compared to conventional staging and further stratified patients within each staging classification. This model has the potential to assist clinicians in better identifying patients that may benefit from additional therapy.",
    "abstract_zh": "**翻译：**<br><br>**背景：** 早期非小细胞肺癌（NSCLC）患者通常接受手术作为主要治疗手段。然而，研究表明，相当高比例的患者在切除术后会复发，从而增加死亡风险。癌症分期目前是评估患者预后的金标准，可以帮助临床医生确定可能从额外治疗中获益的患者。但是，用于辅助确定癌症分期的医学影像已显示出未被充分利用的预后信息，这些信息可以增强临床数据，从而更好地识别高风险NSCLC患者。目前仍迫切需要建立一种模型，能够整合临床、病理、手术和影像信息，并超越现有的分期系统，以帮助临床医生识别术后立即可能从额外治疗中获益的患者。<br><br>**目的：** 我们的目标是确定一种深度学习模型（DLM）是否能够整合胸腔的FDG PET和CT影像，以及临床、手术和病理信息，从而比传统分期更好地预测NSCLC的无复发生存期（RFS）并将患者分层到不同的风险组。<br><br>**材料与方法：** 回顾性分析了2009年至2018年期间在两家学术机构接受手术切除的NSCLC患者（本地机构：305名患者；外部验证：195名患者）。在术前FDG PET和CT影像上勾画出胸腔（包括肺、纵隔、胸膜界面和胸椎），并结合每位患者的临床、手术和病理信息。使用本地患者队列，在训练队列（n=225）中构建了使用这些特征的多模态DLM，在验证队列（n=45）中进行调整，并在测试（n=35）和外部验证（n=195）队列中进行评估，以预测RFS并将患者分层到不同的风险组。使用曲线下面积（AUC）、Kaplan-Meier曲线和log-rank检验来评估该模型的预后价值。将DLM的分层表现与传统分期分层进行比较。<br><br>**结果：** 整合了影像、病理、手术和临床数据的多模态DLM预测了测试队列（AUC = 0.78 [95% CI: 0.63-0.94]）和外部验证队列（AUC = 0.66 [95% CI: 0.58-0.73]）中的RFS。DLM在测试和外部验证队列中均将患者显著分层为RFS的高、中、低风险组（多变量log-rank p < 0.001），并且优于传统分期。传统分期无法将患者分层为RFS的三个不同风险组（测试：p = 0.94；外部验证：p = 0.38）。最后，DLM还能够将测试（I期：p = 0.02，II期：p = 0.03）和外部验证（I期：p = 0.05，II期：p = 0.03）队列中每个分期内的患者进一步显著分层到子风险组。<br><br>**结论：** 这是首个使用多模态影像以及临床、手术和病理数据来预测NSCLC患者术后RFS的研究。与传统分期相比，多模态DLM更好地将患者分层到预后不良的风险组，并且进一步将每个分期分类中的患者进行了分层。该模型具有帮助临床医生更好地识别可能从额外治疗中获益的患者的潜力。",
    "summary_zh": "本研究旨在开发一种新型深度学习模型（DLM），该模型整合了FDG PET/CT影像、临床、手术和病理信息，用于预测早期NSCLC患者术后的无复发生存期（RFS）。研究结果表明，该DLM在预测RFS和患者风险分层方面优于传统分期方法，能够更准确地识别高风险患者，并有助于指导术后辅助治疗的决策。该模型有望提升NSCLC患者的个体化治疗水平。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17862",
    "link": "https://doi.org/10.1002/mp.17862"
  },
  {
    "title": "Evaluation of a motion correction algorithm in lung cancer PET/CT: Phantom validation and patient studies.",
    "authors": [
      "Ziyang Wang",
      "Jianjing Liu",
      "Di Lu",
      "Guoqing Sui",
      "Yaya Wang",
      "Lina Tong",
      "Xueyao Liu",
      "Yan Zhang",
      "Jie Fu",
      "Wengui Xu",
      "Dong Dai"
    ],
    "abstract": "BACKGROUND: Data-driven gating (DDG) is an emerging technology that can reduce the respiratory motion artifacts in positron emission tomography (PET) images.\nPURPOSE: The aim of this study is to use phantom and patient data to validate the performance of DDG with a motion correction algorithm based on the reconstruct, register, and average (RRA) method.\nMETHODS: A customized motion platform drove the phantom (five spheres with diameters of 10-28 mm) using a periodic motion that had a duration of 3-5 s and amplitudes of 2-4 cm. Normalized ratio of ungated and RRA PET relative to the ground-truth static PET was calculated for RSUVmax, RSUVmean, RSUVpeak, RVolume, and relative contrast-to-noise ratio (RCNR). Additionally, 30 lung cancer patients with 76 lung lesions less than 3 cm in diameter were prospectively studied. The overall image quality of patient examination was scored using a 5-point scale by two radiologists. SUVmax, SUVmean, SUVpeak, volume, and CNR of lesions measured in ungated and RRA PET were compared, and subgroup analysis was conducted.\nRESULTS: In RRA PET images, motion artifacts of the spheres in the phantom were effectively mitigated, regardless of changes in movement amplitudes or duration. For all spheres with different ranges of motion and cycles, RSUVmax, RSUVmean, RSUVpeak, and RCNR increased significantly (p ≤ 0.001) and RVolume decreased significantly (p < 0.001) in RRA PET images. The average radiologist scores of image quality were 3.90 ± 0.86 with RRA PET, and 3.03 ± 1.19 with ungated PET. In RRA PET images, the SUVmax (p < 0.001), SUVmean (p < 0.001), SUVpeak (p < 0.001), and CNR (p < 0.001) of the lesions increased, while the volume (p < 0.001) of the lesions decreased. Δ%SUVmax, Δ%SUVmean, Δ%SUVpeak, and Δ%CNR of the lesions increased by 3.9%, 6.5%, 5.6%, and 4.3%, respectively, while Δ%Volume of the lesions decreased by 18.4%. Subgroup analysis showed that in lesions in the upper and middle lobes, only SUVpeak (p < 0.001) significantly increased by 5.6% in RRA PET, while their volume (p < 0.001) notably decreased by 12.4% (p < 0.001).\nCONCLUSION: DDG integrated with RRA motion correction algorithm can effectively mitigate motion artifacts, thus enhancing the quantification accuracy and visual quality of images in lung cancer PET/CT.",
    "abstract_zh": "**翻译：**<br><br>背景：数据驱动门控（DDG）是一项新兴技术，可以减少正电子发射断层扫描（PET）图像中的呼吸运动伪影。<br><br>目的：本研究旨在利用体模和患者数据，验证DDG与基于重建、配准和平均（RRA）方法的运动校正算法的性能。<br><br>方法：一个定制的运动平台驱动体模（五个直径为10-28毫米的球体），进行周期性运动，运动持续时间为3-5秒，振幅为2-4厘米。计算了未门控和RRA PET相对于真实静态PET的归一化比率，指标包括RSUVmax、RSUVmean、RSUVpeak、RVolume和相对信噪比（RCNR）。此外，前瞻性地研究了30名肺癌患者，共包含76个直径小于3厘米的肺部病灶。由两位放射科医生使用5分制量表对患者检查的总体图像质量进行评分。比较了未门控和RRA PET中病灶的SUVmax、SUVmean、SUVpeak、体积和CNR，并进行了亚组分析。<br><br>结果：在RRA PET图像中，体模中球体的运动伪影得到了有效缓解，与运动振幅或持续时间的变化无关。对于所有具有不同运动范围和周期的球体，RRA PET图像中的RSUVmax、RSUVmean、RSUVpeak和RCNR显著增加（p ≤ 0.001），而RVolume显著减少（p < 0.001）。RRA PET的平均放射科医生图像质量评分为3.90 ± 0.86，未门控PET的平均评分为3.03 ± 1.19。在RRA PET图像中，病灶的SUVmax（p < 0.001）、SUVmean（p < 0.001）、SUVpeak（p < 0.001）和CNR（p < 0.001）增加，而病灶的体积（p < 0.001）减小。病灶的Δ%SUVmax、Δ%SUVmean、Δ%SUVpeak和Δ%CNR分别增加了3.9%、6.5%、5.6%和4.3%，而病灶的Δ%Volume减少了18.4%。亚组分析表明，在上叶和中叶的病灶中，只有SUVpeak在RRA PET中显著增加了5.6%（p < 0.001），而体积显著减少了12.4%（p < 0.001）。<br><br>结论：DDG与RRA运动校正算法相结合，可以有效缓解运动伪影，从而提高肺癌PET/CT图像的定量准确性和视觉质量。",
    "summary_zh": "该研究验证了数据驱动门控（DDG）结合重建、配准和平均（RRA）运动校正算法在减少PET图像呼吸运动伪影方面的有效性。通过体模实验和肺癌患者研究，发现DDG-RRA显著提高了病灶的SUV值和信噪比，降低了体积测量误差，改善了图像质量。结论表明，该方法可以提高肺癌PET/CT的定量准确性和视觉质量。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17846",
    "link": "https://doi.org/10.1002/mp.17846"
  },
  {
    "title": "Hepatocellular carcinoma 18F-FDG PET/CT kinetic parameter estimation based on the advantage actor-critic algorithm.",
    "authors": [
      "Jianfeng He",
      "Siming Li",
      "Yiwei Xiong",
      "Yu Yao",
      "Siyu Wang",
      "Sidan Wang",
      "Shaobo Wang"
    ],
    "abstract": "BACKGROUND: Kinetic parameters estimated with dynamic 18F-fluorodeoxyglucose (18F-FDG) positron emission tomography (PET)/computed tomography (CT) help characterize hepatocellular carcinoma (HCC), and deep reinforcement learning (DRL) can improve kinetic parameter estimation.\nPURPOSE: The advantage actor-critic (A2C) algorithm is a DRL algorithm with neural networks that seek the optimal parameters. The aim of this study was to preliminarily assess the role of the A2C algorithm in estimating the kinetic parameters of 18F-FDG PET/CT in patients with HCC.\nMATERIALS AND METHODS: 18F-FDG PET data from 14 liver tissues and 17 HCC tumors obtained via a previously developed, abbreviated acquisition protocol (5-min dynamic PET/CT imaging supplemented with 1-min static imaging at 60 min) were prospectively collected. The A2C algorithm was used to estimate kinetic parameters with a reversible double-input, three-compartment model, and the results were compared with those of the conventional nonlinear least squares (NLLS) algorithm. Fitting errors were compared via the root-mean-square errors (RMSEs) of the time activity curves (TACs).\nRESULTS: Significant differences in K1, k2, k3, k4, fa, and vb according to the A2C algorithm and k3, fa, and vb according to the NLLS algorithm were detected between HCC and normal liver tissues (all p < 0.05). Furthermore, A2C demonstrated superior diagnostic performance over NLLS in terms of k3 and vb (both p < 0.05 in the Delong test). Notably, A2C yielded a smaller fitting error for normal liver tissue (0.62 ± 0.24 vs. 1.04 ± 1.00) and HCC tissue (1.40 ± 0.42 vs. 1.51 ± 0.97) than did NLLS.\nCONCLUSIONS: Compared with the conventional postreconstruction NLLS method, the A2C algorithm can more precisely estimate 18F-FDG kinetic parameters with a reversible double-input, three-compartment model for HCC tumors, attaining better TAC fitting with a lower RMSE.",
    "abstract_zh": "**翻译：**<br><br>背景：利用动态18F-氟代脱氧葡萄糖（18F-FDG）正电子发射断层扫描（PET）/计算机断层扫描（CT）估计的动力学参数有助于表征肝细胞癌（HCC），而深度强化学习（DRL）可以提高动力学参数的估计精度。<br><br>目的：优势演员-评论家（A2C）算法是一种利用神经网络寻找最优参数的DRL算法。本研究旨在初步评估A2C算法在估计HCC患者18F-FDG PET/CT动力学参数中的作用。<br><br>材料与方法：前瞻性收集了通过先前开发的简化采集方案（5分钟动态PET/CT成像，并补充在60分钟时进行1分钟静态成像）获得的14个肝脏组织和17个HCC肿瘤的18F-FDG PET数据。采用A2C算法，使用可逆双输入三室模型估计动力学参数，并将结果与传统非线性最小二乘（NLLS）算法的结果进行比较。通过时间-活度曲线（TAC）的均方根误差（RMSE）比较拟合误差。<br><br>结果：在HCC和正常肝脏组织之间，A2C算法检测到K1、k2、k3、k4、fa和vb存在显著差异，NLLS算法检测到k3、fa和vb存在显著差异（所有p < 0.05）。此外，在k3和vb方面，A2C算法表现出优于NLLS算法的诊断性能（DeLong检验中均为p < 0.05）。值得注意的是，与NLLS算法相比，A2C算法对正常肝脏组织（0.62 ± 0.24 vs. 1.04 ± 1.00）和HCC组织（1.40 ± 0.42 vs. 1.51 ± 0.97）产生了更小的拟合误差。<br><br>结论：与传统的后重建NLLS方法相比，A2C算法可以更精确地估计HCC肿瘤的可逆双输入三室模型18F-FDG动力学参数，从而获得更好的TAC拟合效果和更低的RMSE。",
    "summary_zh": "本研究评估了深度强化学习算法A2C在肝细胞癌(HCC) 18F-FDG PET/CT动力学参数估计中的应用。结果表明，A2C算法在区分HCC与正常肝脏组织，以及在k3和vb等参数的诊断性能上优于传统的NLLS方法，并能实现更精确的动力学参数估计和更低的拟合误差。该研究提示A2C算法在HCC的PET成像分析中具有潜在的应用价值。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17851",
    "link": "https://doi.org/10.1002/mp.17851"
  },
  {
    "title": "Predicting [177Lu]Lu-DOTA-TATE dosimetry by using pre-therapy [68Ga]Ga-DOTA-TATE PET/CT and biomarkers in patient with neuroendocrine tumors.",
    "authors": [
      "Hongxing Yang",
      "Ming Qi",
      "Zhihao Chen",
      "Fei Liu",
      "Junyan Xu",
      "Xiaoping Xu",
      "Qing Kong",
      "Jianping Zhang",
      "Shaoli Song"
    ],
    "abstract": "BACKGROUND: Lutetium-177 DOTA-TATE peptide receptor radionuclide therapy (PRRT) is an established and effective treatment modality for patients with metastatic neuroendocrine tumors (NETs).\nPURPOSE: This study aims to predict patient-absorbed doses from [177Lu]Lu-DOTA-TATE PRRT in the liver, kidney and lesion by utilizing patient-specific absorbed doses from pre-therapeutic [68Ga]Ga-DOTA-TATE PET/CT.\nMETHODS: Before the treatment of cycle 1, 11 patients with NETs underwent PET/CT scans at 0.5, 1.0, 2.0 and 4.0 h after the injection of [68Ga]Ga-DOTA-TATE. Patients then received [177Lu]Lu-DOTA-TATE PRRT and underwent SPECT/CT scans at 4, 24, 96, and 168 h post-administration. The segmentations and dosimetry were performed by using a professional software. The linear regression model used the absorbed doses from [68Ga]Ga-DOTA-TATE alone as the predictor variable. The multiple linear regression model used the absorbed doses from [68Ga]Ga-DOTA-TATE and the relevant clinical biomarkers as the predictor variables.\nRESULTS: The mean absorbed doses from [177Lu]Lu-DOTA-TATE PRRT in kidney and liver were 4.1 and 2.1 Gy, respectively. In comparison, the mean absorbed doses from [68Ga]Ga-DOTA-TATE were significantly lower: 18.0 mGy and 11.0 mGy, respectively. For lesions, the maximum absorbed dose from [68Ga]Ga-DOTA-TATE ranged from 24.1 to 170.4 mGy, while the maximum absorbed dose from [177Lu]Lu-DOTA-TATE PRRT was significantly higher, ranging from 9.6 to 77.9 Gy. The linear regression model yielded moderate R-squared values of 0.50, 0.59, and 0.36 for kidney, liver and lesion, respectively. The performance of multiple linear regression model was better, with R-squared values increasing to 0.81, 0.77, and 0.84.\nCONCLUSION: Absorbed doses from [177Lu]Lu-DOTA-TATE PRRT can be accurately predicted. Moreover, our models are formalized into simple equations.",
    "abstract_zh": "**翻译：**<br><br>背景：镥-177 DOTA-TATE 肽受体放射性核素治疗 (PRRT) 是一种针对转移性神经内分泌肿瘤 (NETs) 患者的成熟且有效的治疗方式。<br><br>目的：本研究旨在利用治疗前 [68Ga]Ga-DOTA-TATE PET/CT 的患者特异性吸收剂量，预测 [177Lu]Lu-DOTA-TATE PRRT 在肝脏、肾脏和病灶中的患者吸收剂量。<br><br>方法：在首个治疗周期前，11 名 NETs 患者在注射 [68Ga]Ga-DOTA-TATE 后 0.5、1.0、2.0 和 4.0 小时进行了 PET/CT 扫描。随后，患者接受了 [177Lu]Lu-DOTA-TATE PRRT，并在给药后 4、24、96 和 168 小时进行了 SPECT/CT 扫描。使用专业的软件进行分割和剂量测定。线性回归模型仅使用 [68Ga]Ga-DOTA-TATE 的吸收剂量作为预测变量。多元线性回归模型使用 [68Ga]Ga-DOTA-TATE 的吸收剂量和相关的临床生物标志物作为预测变量。<br><br>结果：[177Lu]Lu-DOTA-TATE PRRT 在肾脏和肝脏中的平均吸收剂量分别为 4.1 Gy 和 2.1 Gy。相比之下，[68Ga]Ga-DOTA-TATE 的平均吸收剂量显著较低：分别为 18.0 mGy 和 11.0 mGy。对于病灶，[68Ga]Ga-DOTA-TATE 的最大吸收剂量范围为 24.1 至 170.4 mGy，而 [177Lu]Lu-DOTA-TATE PRRT 的最大吸收剂量显著较高，范围为 9.6 至 77.9 Gy。线性回归模型对肾脏、肝脏和病灶的 R 平方值分别为 0.50、0.59 和 0.36，呈现中等水平。多元线性回归模型的性能更好，R 平方值增加到 0.81、0.77 和 0.84。<br><br>结论：[177Lu]Lu-DOTA-TATE PRRT 的吸收剂量可以被准确预测。此外，我们的模型被形式化为简单的方程式。",
    "summary_zh": "本研究利用治疗前的[68Ga]Ga-DOTA-TATE PET/CT数据预测[177Lu]Lu-DOTA-TATE PRRT在NETs患者肝肾和病灶中的吸收剂量。结果表明，基于[68Ga]Ga-DOTA-TATE的吸收剂量，结合临床生物标志物的多元线性回归模型能够更准确地预测[177Lu]Lu-DOTA-TATE PRRT的吸收剂量，并将模型简化为简单方程。此方法可用于个体化PRRT治疗方案的制定。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17852",
    "link": "https://doi.org/10.1002/mp.17852"
  },
  {
    "title": "Predictive models of epidermal growth factor receptor mutation in lung adenocarcinoma using PET/CT-based radiomics features.",
    "authors": [
      "Zhikang Deng",
      "Di Jin",
      "Pei Huang",
      "Changchun Wang",
      "Yaohong Deng",
      "Rong Xu",
      "Bing Fan"
    ],
    "abstract": "BACKGROUND: Lung adenocarcinoma (LAC) comprises a substantial subset of non-small cell lung cancer (NSCLC) diagnoses, where epidermal growth factor receptor (EGFR) mutations play a pivotal role as indicators for therapeutic intervention with targeted agents. The emerging field of radiomics, which involves the extraction of numerous quantitative attributes from medical imaging, when coupled with positron emission tomography/ computed tomography (PET/CT) technology, has demonstrated promise in the prognostication of EGFR mutation status. The objective of this investigation is to construct and validate predictive models for EGFR mutations in LAC by leveraging PET/CT-derived radiomics features, thereby refining diagnostic precision and facilitating tailored treatment strategies.\nPURPOSE: The aim of this study was to develop a non-invasive radiomics model based on PET/CT with excellent performance for predicting the EGFR mutation status in LAC. Thus, it can provide the basis for the individualized treatment decision of patients.\nMETHODS: Positron emission tomography (PET), computed tomography (CT), clinical and pathological data of 112 patients with LAC admitted to our hospital from January 2019 to June 2023 were retrospectively analyzed. This research cohort encompassed 54 LAC patients with EGFR wild type and 58 LAC patients with EGFR mutated type. The participants were randomly assigned to the training group (n = 78) and the validation group (n = 34) in a 7:3 ratio. A sum of 3562 radiomics attributes were derived from PET/CT scans. The minimal absolute shrinkage and selection operator method was employed to identify 13 notable features. Based on these characteristics, support vector machine (SVM), gradient boosting decision tree (GBDT), random forest (RF) and extreme gradient boosting (XGBOOST) were constructed. The forecasting effectiveness of the model was assessed using the area under the receiver operating characteristic (ROC) Curve, the DeLong test, and decision curve analysis (DCA).\nRESULTS: SVM performance in PET/CT radiomics model was higher than that of other machine learning models (training group areas under the curve [AUC] of 0.916 and validation group AUC of 0.945, respectively). The integration of radiomics and clinical data did not yield a superior predictive performance compared to the radiomics model alone in terms of estimating EGFR mutation status (AUC: 0.916 vs. 0.921, 0.945 vs. 0.955, p> 0.05, in both the training and validation groups).\nCONCLUSIONS: The SVM model has emerged as a commendable non-invasive technique, showing high precision and dependability in forecasting EGFR mutation statuses in individuals with LAC. The radiomics model derived from PET/CT scans holds promise as a prognostic indicator of EGFR mutations in LAC, offering a valuable tool that could refine personalized therapeutic strategies and ultimately enhance the prognosis for LAC patients.",
    "abstract_zh": "**翻译：**<br><br>背景：肺腺癌（LAC）是非小细胞肺癌（NSCLC）的重要亚型，表皮生长因子受体（EGFR）突变是靶向药物治疗的重要指标。新兴的放射组学领域，通过从医学影像中提取大量定量特征，结合正电子发射断层扫描/计算机断层扫描（PET/CT）技术，已展现出预测EGFR突变状态的潜力。本研究旨在构建和验证基于PET/CT放射组学特征的LAC EGFR突变预测模型，从而提高诊断精确度，并促进个体化治疗策略的制定。<br><br>目的：本研究旨在建立一种基于PET/CT的无创放射组学模型，该模型在预测LAC中EGFR突变状态方面具有优异的性能，从而为患者的个体化治疗决策提供依据。<br><br>方法：回顾性分析2019年1月至2023年6月期间在我院就诊的112例LAC患者的正电子发射断层扫描（PET）、计算机断层扫描（CT）以及临床病理数据。该研究队列包括54例EGFR野生型LAC患者和58例EGFR突变型LAC患者。参与者以7:3的比例随机分配到训练组（n = 78）和验证组（n = 34）。从PET/CT扫描中提取了总计3562个放射组学特征。采用最小绝对收缩和选择算子方法（LASSO）识别出13个显著特征。基于这些特征，构建了支持向量机（SVM）、梯度提升决策树（GBDT）、随机森林（RF）和极端梯度提升（XGBOOST）模型。使用受试者工作特征曲线（ROC）下面积、DeLong检验和决策曲线分析（DCA）评估模型的预测效果。<br><br>结果：PET/CT放射组学模型中，SVM的性能优于其他机器学习模型（训练组曲线下面积[AUC]为0.916，验证组AUC为0.945）。在评估EGFR突变状态方面，与单独的放射组学模型相比，整合放射组学和临床数据并未产生更优的预测性能（训练组和验证组的AUC分别为0.916 vs. 0.921, 0.945 vs. 0.955, p > 0.05）。<br><br>结论：SVM模型已成为一种值得称赞的无创技术，在预测LAC患者的EGFR突变状态方面表现出高精度和可靠性。基于PET/CT扫描的放射组学模型有望成为LAC中EGFR突变的预后指标，为优化个体化治疗策略并最终改善LAC患者的预后提供了一种有价值的工具。",
    "summary_zh": "本研究旨在利用PET/CT放射组学构建预测肺腺癌(LAC)患者EGFR突变状态的无创模型。研究人员从112例LAC患者的PET/CT图像中提取大量放射组学特征，并利用多种机器学习算法构建预测模型。结果显示，SVM模型表现最优，且整合临床数据并未显著提升预测性能。结论表明，基于PET/CT的放射组学SVM模型有望成为预测LAC患者EGFR突变状态的可靠工具，从而指导个体化治疗。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17780",
    "link": "https://doi.org/10.1002/mp.17780"
  },
  {
    "title": "Hybrid method for estimating lung ventilation from CT by combining intensity and motion information.",
    "authors": [
      "Paris Tzitzimpasis",
      "Mario Ries",
      "Bas W Raaymakers",
      "Cornel Zachiu"
    ],
    "abstract": "BACKGROUND: Functional lung imaging modalities allow for capturing regional lung ventilation information. Computed Tomography based ventilation imaging (CTVI) has been proposed as a surrogate modality that relies on time-resolved anatomical data and image processing. However, generating accurate ventilation maps using solely computed tomography (CT) image information remains a challenging task, due to the need to derive functional information of ventilation from anatomical observations.\nPURPOSE: We introduce the hybrid estimation of computed tomography obtained respiratory function (HECTOR) method that consists of two components: a volume- and a density-based ventilation estimate. For the first component, a deformable image registration (DIR)-based solution for accurate volumetric CTVI generation is proposed, integrating the physical characteristics of the lung deformations in its design. For the second component, an already established air-tissue density model is used. Furthermore, a novel method is developed for combining the two components.\nMETHODS: The proposed method consists of four principal steps: (1) Application of a specially tailored DIR algorithm to estimate respiratory motion between inhale and exhale phases. (2) Conversion of the motion information to volumetric change maps using a variation of the Jacobian determinant method. (3) Computation of a HU-based method that estimates the local product of air-tissue densities. (4) Combination of the metrics estimated in steps 2 and 3 by means of a smooth minimum function. The proposed approach is validated using the publicly available VAMPIRE dataset consisting of two subgroups: 25 subjects scanned with Galligas 4DPET/CT and 21 subjects scanned with DTPA-SPECT. Another dataset of 18 patients available at The Cancer Imaging Archive (TCIA) was used for further validation. All datasets contain inhale/exhale CT scans paired with ground-truth ventilation images (RefVIs). The CTVIs generated by the proposed HECTOR method were tested against the RefVIs using the Spearman correlation coefficient and Dice overlap of low- and high-function lung (DSC-low and DSC-high, respectively).\nRESULTS: The proposed method achieved mean Spearman, DSC-high and DSC-low coefficients of 0.62, 0.55, and 0.59 on the Galligas PET subgroup and 0.49,0,48, and 0.50 on the DTPA-SPECT subgroup of the VAMPIRE dataset. This performance was better than the highest performing method reported in the original challenge. The same metrics for the TCIA dataset were 0.66, 0.60, and 0.60. The proposed hybrid ventilation method achieved higher Spearman correlation scores than the individual volume- and density-based components in all datasets. Additionally, the use of the specially tailored DIR algorithm was found to achieve higher scores than previously reported volume-based methods.\nCONCLUSIONS: Our work provides a novel processing workflow for CT ventilation imaging that can consistently generate ventilation maps with high fidelity compared to reference approaches. This study also provides further insights into the benefits of combining different types of information to model the complex dynamics of respiratory function. Such information can be useful for potential applications in radiation therapy treatment planning and thoracic dose-response assessment.",
    "abstract_zh": "**翻译：**<br><br>**背景：** 功能性肺部成像技术能够获取区域性肺通气信息。基于计算机断层扫描的通气成像(CTVI)已被提出作为一种替代方法，它依赖于时间分辨的解剖数据和图像处理。然而，仅使用计算机断层扫描(CT)图像信息生成精确的通气图仍然是一项具有挑战性的任务，因为需要从解剖学观察中推导出通气的功能信息。<br><br>**目的：** 我们介绍了一种混合估计计算机断层扫描获得呼吸功能(HECTOR)的方法，该方法由两个部分组成：基于体积的和基于密度的通气估计。对于第一部分，提出了一种基于可变形图像配准(DIR)的解决方案，用于生成精确的体积CTVI，并在其设计中整合了肺部形变的物理特性。对于第二部分，使用了一种已建立的空气-组织密度模型。此外，还开发了一种新方法来组合这两个部分。<br><br>**方法：** 提出的方法包括四个主要步骤：(1)应用专门定制的DIR算法来估计吸气和呼气阶段之间的呼吸运动。(2)使用雅可比行列式方法的一种变体，将运动信息转换为体积变化图。(3)计算一种基于HU的方法，该方法估计空气-组织密度的局部乘积。(4)通过平滑最小值函数组合在步骤2和3中估计的指标。所提出的方法使用公开可用的VAMPIRE数据集进行验证，该数据集包含两个亚组：25名受试者使用Galligas 4DPET/CT扫描，21名受试者使用DTPA-SPECT扫描。来自癌症影像档案馆(TCIA)的另一个包含18名患者的数据集用于进一步验证。所有数据集都包含与地面实况通气图像(RefVI)配对的吸气/呼气CT扫描。使用Spearman相关系数和低功能和高功能肺的Dice重叠（分别为DSC-low和DSC-high）测试了所提出的HECTOR方法生成的CTVI与RefVI的对比。<br><br>**结果：** 在VAMPIRE数据集的Galligas PET亚组中，提出的方法获得了平均Spearman系数0.62、DSC-high系数0.55和DSC-low系数0.59，在DTPA-SPECT亚组中，这些系数分别为0.49、0.48和0.50。这种性能优于原始挑战中报告的性能最佳的方法。对于TCIA数据集，相同的指标分别为0.66、0.60和0.60。在所有数据集中，提出的混合通气方法都比单独的基于体积和基于密度的部分获得了更高的Spearman相关性得分。此外，发现使用专门定制的DIR算法比先前报告的基于体积的方法获得了更高的分数。<br><br>**结论：** 我们的工作为CT通气成像提供了一种新的处理流程，与参考方法相比，该流程可以持续生成高保真的通气图。这项研究还进一步深入了解了组合不同类型的信息以建模呼吸功能复杂动态的好处。这些信息可用于放射治疗计划制定和胸腔剂量-反应评估中的潜在应用。",
    "summary_zh": "本研究提出了一种名为HECTOR的混合方法，用于从CT图像中生成更准确的肺通气图。该方法结合了基于体积变化和密度变化的两种估计方法，并使用专门设计的DIR算法优化体积估计。通过VAMPIRE和TCIA两个数据集的验证，HECTOR方法在性能上优于现有方法，能够生成高保真的通气图，并展现了不同信息融合的优势。该方法有望应用于放射治疗计划和胸腔剂量评估。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17787",
    "link": "https://doi.org/10.1002/mp.17787"
  },
  {
    "title": "3D lymphoma segmentation on PET/CT images via multi-scale information fusion with cross-attention.",
    "authors": [
      "Huan Huang",
      "Liheng Qiu",
      "Shenmiao Yang",
      "Longxi Li",
      "Jiaofen Nan",
      "Yanting Li",
      "Chuang Han",
      "Fubao Zhu",
      "Chen Zhao",
      "Weihua Zhou"
    ],
    "abstract": "BACKGROUND: Accurate segmentation of diffuse large B-cell lymphoma (DLBCL) lesions is challenging due to their complex patterns in medical imaging. Traditional methods often struggle to delineate these lesions accurately.\nOBJECTIVE: This study aims to develop a precise segmentation method for DLBCL using 18F-fluorodeoxyglucose (18F-FDG) positron emission tomography (PET) and computed tomography (CT) images.\nMETHODS: We propose a 3D segmentation method based on an encoder-decoder architecture. The encoder incorporates a dual-branch design based on the shifted window transformer to extract features from both PET and CT modalities. To enhance feature integration, we introduce a multi-scale information fusion (MSIF) module that performs multi-scale feature fusion using cross-attention mechanisms with a shifted window framework. A gated neural network within the MSIF module dynamically adjusts feature weights to balance the contributions from each modality. The model is optimized using the dice similarity coefficient (DSC) loss function, minimizing discrepancies between the model prediction and ground truth. Additionally, we computed the total metabolic tumor volume (TMTV) and performed statistical analyses on the results.\nRESULTS: The model was trained and validated on a private dataset of 165 DLBCL patients and a publicly available dataset (autoPET) containing 145 PET/CT scans of lymphoma patients. Both datasets were analyzed using five-fold cross-validation. On the private dataset, our model achieved a DSC of 0.7512, sensitivity of 0.7548, precision of 0.7611, an average surface distance (ASD) of 3.61 mm, and a Hausdorff distance at the 95th percentile (HD95) of 15.25 mm. On the autoPET dataset, the model achieved a DSC of 0.7441, sensitivity of 0.7573, precision of 0.7427, ASD of 5.83 mm, and HD95 of 21.27 mm, outperforming state-of-the-art methods (p < 0.05, t-test). For TMTV quantification, Pearson correlation coefficients of 0.91 (private dataset) and 0.86 (autoPET) were observed, with R2 values of 0.89 and 0.75, respectively. Extensive ablation studies demonstrated the MSIF module's contribution to enhanced segmentation accuracy.\nCONCLUSION: This study presents an effective automatic segmentation method for DLBCL that leverages the complementary strengths of PET and CT imaging. The method demonstrates robust performance on both private and publicly available datasets, ensuring its reliability and generalizability. Our method provides clinicians with more precise tumor delineation, which can improve the accuracy of diagnostic interpretations and assist in treatment planning for DLBCL patients. The code for the proposed method is available at https://github.com/chenzhao2023/lymphoma_seg.",
    "abstract_zh": "**翻译：**<br><br>背景：弥漫大B细胞淋巴瘤（DLBCL）病灶在医学影像中呈现复杂的形态，因此对其进行精确分割极具挑战性。传统方法常常难以准确地勾勒出这些病灶的边界。<br><br>目的：本研究旨在开发一种精确的分割方法，用于利用18F-氟代脱氧葡萄糖（18F-FDG）正电子发射断层扫描（PET）和计算机断层扫描（CT）图像对DLBCL进行分割。<br><br>方法：我们提出了一种基于编码器-解码器结构的3D分割方法。编码器采用基于移位窗口Transformer的双分支设计，从PET和CT两种模态中提取特征。为了增强特征融合，我们引入了一个多尺度信息融合（MSIF）模块，该模块使用带有移位窗口框架的交叉注意力机制执行多尺度特征融合。MSIF模块中的门控神经网络动态调整特征权重，以平衡来自每种模态的贡献。该模型使用Dice相似系数（DSC）损失函数进行优化，以最小化模型预测与真实值之间的差异。此外，我们计算了总代谢肿瘤体积（TMTV），并对结果进行了统计分析。<br><br>结果：该模型在一个包含165名DLBCL患者的私有数据集和一个包含145个淋巴瘤患者PET/CT扫描的公开数据集（autoPET）上进行了训练和验证。两个数据集均使用五折交叉验证进行分析。在私有数据集上，我们的模型实现了0.7512的DSC、0.7548的灵敏度、0.7611的精确度、3.61 mm的平均表面距离（ASD）以及15.25 mm的第95百分位数Hausdorff距离（HD95）。在autoPET数据集上，该模型实现了0.7441的DSC、0.7573的灵敏度、0.7427的精确度、5.83 mm的ASD以及21.27 mm的HD95，优于最先进的方法（p < 0.05，t检验）。对于TMTV量化，观察到皮尔逊相关系数分别为0.91（私有数据集）和0.86（autoPET），R2值分别为0.89和0.75。广泛的消融研究表明，MSIF模块有助于提高分割精度。<br><br>结论：本研究提出了一种有效的DLBCL自动分割方法，该方法利用了PET和CT成像的互补优势。该方法在私有和公开数据集上均表现出强大的性能，确保了其可靠性和泛化能力。我们的方法为临床医生提供了更精确的肿瘤勾勒，从而可以提高诊断解释的准确性，并有助于DLBCL患者的治疗计划。所提出方法的代码可在https://github.com/chenzhao2023/lymphoma_seg 获得。",
    "summary_zh": "本研究提出了一种基于深度学习的3D分割方法，用于精确分割DLBCL病灶，该方法融合了PET和CT图像的信息。该方法利用移位窗口Transformer和多尺度信息融合模块，在两个数据集上都取得了优异的分割性能，优于现有方法，并表现出良好的泛化能力。该方法能够为临床医生提供更准确的肿瘤分割，从而提升诊断和治疗计划的制定。相关代码已开源。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17763",
    "link": "https://doi.org/10.1002/mp.17763"
  },
  {
    "title": "Multimodal feature-guided diffusion model for low-count PET image denoising.",
    "authors": [
      "Gengjia Lin",
      "Yuxi Jin",
      "Zhenxing Huang",
      "Zixiang Chen",
      "Haizhou Liu",
      "Chao Zhou",
      "Xu Zhang",
      "Wei Fan",
      "Na Zhang",
      "Dong Liang",
      "Peng Cao",
      "Zhanli Hu"
    ],
    "abstract": "BACKGROUND: To minimize radiation exposure while obtaining high-quality Positron Emission Tomography (PET) images, various methods have been developed to derive standard-count PET (SPET) images from low-count PET (LPET) images. Although deep learning methods have enhanced LPET images, they rarely utilize the rich complementary information from MR images. Even when MR images are used, these methods typically employ early, intermediate, or late fusion strategies to merge features from different CNN streams, failing to fully exploit the complementary properties of multimodal fusion.\nPURPOSE: In this study, we introduce a novel multimodal feature-guided diffusion model, termed MFG-Diff, designed for the denoising of LPET images with the full utilization of MRI.\nMETHODS: MFG-Diff replaces random Gaussian noise with LPET images and introduces a novel degradation operator to simulate the physical degradation processes of PET imaging. Besides, it uses a novel cross-modal guided restoration network to fully exploit the modality-specific features provided by the LPET and MR images and utilizes a multimodal feature fusion module employing cross-attention mechanisms and positional encoding at multiple feature levels for better feature fusion.\nRESULTS: Under four counts (2.5%, 5.0%, 10%,  and 25%), the images generated by our proposed network showed superior performance compared to those produced by other networks in both qualitative and quantitative evaluations, as well as in statistical analysis. In particular, the peak-signal-to-noise ratio of the generated PET images improved by more than 20% under a 2.5% count, the structural similarity index improved by more than 16%, and the root mean square error reduced by nearly 50%. On the other hand, our generated PET images had significant correlation (Pearson correlation coefficient, 0.9924), consistency, and excellent quantitative evaluation results with the SPET images.\nCONCLUSIONS: The proposed method outperformed existing state-of-the-art LPET denoising models and can be used to generate highly correlated and consistent SPET images obtained from LPET images.",
    "abstract_zh": "**翻译：**<br><br>背景：为了在获得高质量正电子发射断层扫描（PET）图像的同时，最大限度地减少辐射暴露，人们开发了多种方法来从低计数PET（LPET）图像中推导出标准计数PET（SPET）图像。虽然深度学习方法增强了LPET图像，但它们很少利用磁共振（MR）图像中丰富的互补信息。即使使用MR图像，这些方法通常也采用早期、中期或晚期融合策略来合并来自不同卷积神经网络（CNN）流的特征，未能充分利用多模态融合的互补特性。<br><br>目的：在本研究中，我们提出了一种新型的多模态特征引导扩散模型，称为MFG-Diff，旨在充分利用MRI对LPET图像进行去噪。<br><br>方法：MFG-Diff使用LPET图像代替随机高斯噪声，并引入了一种新的退化算子来模拟PET成像的物理退化过程。此外，它使用了一种新的跨模态引导恢复网络，以充分利用LPET和MR图像提供的模态特定特征，并利用一个多模态特征融合模块，该模块在多个特征层面上采用交叉注意力机制和位置编码，以实现更好的特征融合。<br><br>结果：在四种计数水平（2.5%、5.0%、10%和25%）下，我们提出的网络生成的图像在定性和定量评估以及统计分析中均表现出优于其他网络的性能。特别地，在2.5%的计数水平下，生成的PET图像的峰值信噪比提高了20%以上，结构相似性指数提高了16%以上，均方根误差降低了近50%。另一方面，我们生成的PET图像与SPET图像具有显著的相关性（皮尔逊相关系数为0.9924）、一致性以及出色的定量评估结果。<br><br>结论：所提出的方法优于目前最先进的LPET去噪模型，可用于从LPET图像生成高度相关且一致的SPET图像。",
    "summary_zh": "该研究提出了一种名为MFG-Diff的新型多模态特征引导扩散模型，用于提高低计数PET (LPET) 图像的质量，同时减少辐射暴露。MFG-Diff充分利用了MRI的互补信息，采用新的退化算子模拟PET成像物理过程，并使用跨模态引导恢复网络和多模态特征融合模块。实验结果表明，MFG-Diff在多种计数水平下均优于现有方法，生成的PET图像与标准计数PET图像具有高度相关性和一致性，具有显著的性能提升。该方法有望用于从低剂量PET图像中生成高质量图像。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17764",
    "link": "https://doi.org/10.1002/mp.17764"
  },
  {
    "title": "Flexible and modular PET: Evaluating the potential of TOF-DOI panel detectors.",
    "authors": [
      "Gašper Razdevšek",
      "Georges El Fakhri",
      "Thibault Marin",
      "Rok Dolenec",
      "Matic Orehar",
      "Yanis Chemli",
      "Alberto Giacomo Gola",
      "David Gascon",
      "Stan Majewski",
      "Rok Pestotnik"
    ],
    "abstract": "BACKGROUND: Panel detectors have the potential to provide a flexible, modular approach to Positron Emission Tomography (PET), enabling customization to meet patient-specific needs and scan objectives. The panel design allows detectors to be positioned close to the patient, aiming to enhance sensitivity and spatial resolution through improved geometric coverage and reduced noncollinearity blurring. Parallax error can be mitigated using depth of interaction (DOI) information.\nPURPOSE: One of the key questions the article addresses is: Do panel detectors offer viable clinical imaging capabilities, or does limited angular sampling restrict their utility by causing image distortions and artifacts? Additionally, this article explores the scalability of panel detectors for constructing scanners with a long axial field of view (LAFOV).\nMETHODS: Monte Carlo simulations using GATE software were used to assess the performance of panel detectors with various DOI resolutions and Time-of-Flight (TOF) resolutions as fine as 70 ps. The 30 × $\\times$  30 cm panels comprised pixelated 3 × $\\times$  3 × $\\times$  20 mm LSO crystals. Simulations were run on large high-performance computing clusters (122,000 CPU cores). Open-source CASToR software was used for (TOF MLEM) image reconstruction. The image quality of the scanners was assessed using a range of phantoms (NEMA, Derenzo, XCAT, and a high-resolution brain phantom). The Siemens Biograph Vision PET/CT scanner served as the reference model. The performance of larger 120 × $\\times$  60 cm panels was also evaluated.\nRESULTS: Sensitivity increases over threefold when panel-panel distance is reduced from 80 to 40 cm. The noise equivalent count rate, unmodified by TOF gain, of the panel detectors matches that of the reference clinical scanner at a distance of approximately 50 cm between the panels. Spatial resolution perpendicular to the panels improves from 8.7 to 1.6 mm when the panel-panel distance is reduced, and 70 ps + DOI detectors are used instead of 200 ps, no-DOI detectors. With enhanced TOF and DOI capabilities, panel detectors achieve image quality that matches or surpasses the reference scanner while using about four times less detector material. These detectors can be extended for LAFOV imaging without distortions or artifacts. Additionally, improving TOF and DOI performance enhances contrast-to-noise ratios, thereby improving lesion detection.\nCONCLUSIONS: A compact 2-panel PET scanner can match the performance of conventional scanners, producing high-quality, distortion-free images. Its mobility and flexibility enable novel applications, including bedside imaging and intensive care unitdiagnostics, as well as imaging in positions such as sitting or standing. Furthermore, the modularity of panel detectors offers the potential to construct cost-effective, high-performance total-body imaging systems.",
    "abstract_zh": "**翻译：**<br><br>**背景：** 面板探测器具有为正电子发射断层扫描(PET)提供灵活、模块化方法的潜力，从而能够进行定制以满足患者特定需求和扫描目标。面板设计允许将探测器放置在靠近患者的位置，旨在通过改善几何覆盖率和减少非共线性模糊来提高灵敏度和空间分辨率。视差误差可以使用深度交互(DOI)信息来缓解。<br><br>**目的：** 本文探讨的关键问题之一是：面板探测器是否提供可行的临床成像能力，还是有限的角度采样通过引起图像失真和伪影来限制它们的效用？此外，本文还探讨了面板探测器在构建具有长轴向视野(LAFOV)的扫描仪方面的可扩展性。<br><br>**方法：** 使用GATE软件的蒙特卡罗模拟被用于评估具有不同DOI分辨率和飞行时间(TOF)分辨率（细至70 ps）的面板探测器的性能。30 × 30 cm的面板由像素化的3 × 3 × 20 mm LSO晶体制成。模拟在大型高性能计算集群（122,000个CPU核心）上运行。开源CASToR软件用于(TOF MLEM)图像重建。使用一系列体模（NEMA、Derenzo、XCAT和一个高分辨率脑体模）评估扫描仪的图像质量。西门子Biograph Vision PET/CT扫描仪作为参考模型。还评估了更大的120 × 60 cm面板的性能。<br><br>**结果：** 当面板-面板距离从80 cm减小到40 cm时，灵敏度提高了三倍以上。在面板之间距离约为50 cm时，面板探测器的噪声等效计数率（未经TOF增益修改）与参考临床扫描仪的计数率相匹配。当面板-面板距离减小，并且使用70 ps + DOI探测器代替200 ps、无DOI探测器时，垂直于面板的空间分辨率从8.7 mm提高到1.6 mm。通过增强的TOF和DOI能力，面板探测器实现了与参考扫描仪相当甚至更高的图像质量，同时使用的探测器材料减少了约四倍。这些探测器可以扩展用于LAFOV成像，而不会产生失真或伪影。此外，提高TOF和DOI性能可以提高对比噪声比，从而改善病灶检测。<br><br>**结论：** 紧凑型双面板PET扫描仪可以与传统扫描仪的性能相媲美，从而产生高质量、无失真的图像。其移动性和灵活性使其能够实现新的应用，包括床旁成像和重症监护病房诊断，以及诸如坐姿或站姿的成像。此外，面板探测器的模块化为构建经济高效的高性能全身成像系统提供了潜力。",
    "summary_zh": "该研究通过蒙特卡洛模拟评估了面板探测器在PET成像中的应用潜力。结果表明，紧凑型双面板PET扫描仪在灵敏度、空间分辨率和图像质量上能够与传统扫描仪媲美甚至超越，同时减少探测器材料的使用。增强的TOF和DOI技术进一步提高了图像质量和病灶检测能力。面板探测器的模块化设计使其适用于床旁成像、重症监护诊断以及全身成像等多种应用场景，并具有构建经济高效的全身成像系统的潜力。该研究为开发新一代PET扫描仪提供了理论依据和技术支持。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17741",
    "link": "https://doi.org/10.1002/mp.17741"
  },
  {
    "title": "A comparative analysis of GEANT4, MCNP6 and FLUKA on proton-induced gamma-ray simulation.",
    "authors": [
      "Hugo Freitas",
      "Esmaeil Nobakht",
      "Florian Grüner",
      "Joao Seco"
    ],
    "abstract": "BACKGROUND: Precise range verification is essential in proton therapy to minimize treatment margins due to the steep dose fall-off of proton beams. The emission of secondary radiation from nuclear reactions between incident particles and tissues stands out as a promising method for range verification. Two prominent techniques are PET and Prompt Gamma-Ray Spectroscopy (PGS). PGS holds significant promise due to its real-time capability for range monitoring. This method allows for prompt detection and quantification of any disparities between planned and actual dose delivery, facilitating adaptive treatment strategies. Given the key role of Monte Carlo (MC) codes in understanding the PGS mechanisms during proton therapy, it is essential to address the current lack of validated codes covering the full energy spectrum of emitted gamma-rays.\nPURPOSE: Addressing the need for precise range monitoring in proton therapy, our study aims to develop and validate MC codes for PGS. We focus on analyse MCNP6, GEANT4, and FLUKA codes, conducting rigorous validation process by comparing our simulation results with experimental data. Additionally, we propose optimal models and parameters to refine the accuracy of simulations for prompt gamma-ray (PG) spectra.\nMETHODS: Various proton data libraries, models and cross-sections values were used in this study to simulate proton-induced gamma-rays in MCNP6, GEANT4 and FLUKA. To validate these simulations, PGS spectra of  15.0  cm 3  $15.0 \\,{\\rm cm}^{3}$  PMMA block irradiation were obtained with  CeBr 3 ${\\rm CeBr}_3$  inorganic scintillator detector for different proton energies, raging from approximately  90 $\\hskip.001pt 90$  to  130  MeV $130 \\,{\\rm MeV}$  .\nRESULTS: GEANT4 was the only MC code capable of successfully reproducing    10 B $^{10}{\\rm B}$  PG lines, while the FLUKA aligned better with experimental data for mid-range energies. At higher energies, FLUKA overestimated the    12 C $^{12}{\\rm C}$  PG line (   2 + → 0 +  $2^{+} \\rightarrow 0^{+}$  ) at  4.44  MeV $4.44 \\,{\\rm MeV}$  , whereas GEANT4 underestimated it; MCNP6 provided the closest match. Additionally, GEANT4, FLUKA, and MCNP6 failed to accurately reproduce the    16 O $^{16}{\\rm O}$  PG line (   3 - → 0 +  $3^{-} \\rightarrow 0^{+}$  ) at  6.13  MeV $6.13 \\,{\\rm MeV}$  , consistent with previous findings. To address this limitation, a new model based on experimental and theoretical data from literature was developed.\nCONCLUSIONS: This study emphasizes the need for updates to the data tables in MC simulations and underscores the importance of further theoretical and experimental research on PG de-excitation lines relevant to proton therapy. The newly developed model, designed to address discrepancies in the simulation of    12 C $^{12}{\\rm C}$  and    16 O $^{16}{\\rm O}$  de-excitation lines across different toolkits, successfully improved the accuracy of the oxygen de-excitation line, which was previously not well-reproduced.",
    "abstract_zh": "**背景：** 在质子治疗中，精确的射程验证至关重要，因为质子束的剂量衰减非常陡峭，需要尽可能缩小治疗边界。入射粒子与组织之间的核反应产生的次级辐射，是一种很有前景的射程验证方法。两种主要技术是正电子发射断层扫描（PET）和即发伽马射线谱（PGS）。PGS具有实时射程监测能力，因此极具潜力。这种方法可以立即检测并量化计划剂量与实际剂量之间的任何差异，从而促进自适应治疗策略的实施。由于蒙特卡罗（MC）代码在理解质子治疗过程中PGS机制方面发挥着关键作用，因此亟需解决当前缺乏覆盖完整发射伽马射线能量谱的已验证代码的问题。<br><br>**目的：** 为了满足质子治疗中精确射程监测的需求，本研究旨在开发和验证用于PGS的MC代码。我们重点分析MCNP6、GEANT4和FLUKA代码，通过将模拟结果与实验数据进行比较，进行严格的验证过程。此外，我们提出了优化的模型和参数，以提高即发伽马射线（PG）谱模拟的准确性。<br><br>**方法：** 本研究使用了各种质子数据库、模型和截面值，在MCNP6、GEANT4和FLUKA中模拟质子诱发的伽马射线。为了验证这些模拟，使用CeBr3无机闪烁体探测器获取了15.0 cm3 PMMA块在不同质子能量（约90 MeV至130 MeV）下的PGS谱。<br><br>**结果：** GEANT4是唯一能够成功重现$^{10}$B PG谱线的MC代码，而FLUKA在中等能量范围内与实验数据吻合得更好。在较高能量下，FLUKA高估了4.44 MeV处的$^{12}$C PG谱线(2+ → 0+)，而GEANT4低估了该谱线；MCNP6提供了最接近的匹配结果。此外，GEANT4、FLUKA和MCNP6都未能准确重现6.13 MeV处的$^{16}$O PG谱线(3- → 0+)，这与之前的研究结果一致。为了解决这一局限性，我们基于文献中的实验和理论数据开发了一个新模型。<br><br>**结论：** 本研究强调了更新MC模拟中数据表的必要性，并强调了进一步开展与质子治疗相关的PG退激发谱线的理论和实验研究的重要性。新开发的模型旨在解决不同工具包在模拟$^{12}$C和$^{16}$O退激发谱线时存在的差异，该模型成功提高了先前未能很好地重现的氧退激发谱线的准确性。",
    "summary_zh": "该研究旨在验证并优化蒙特卡罗（MC）代码（MCNP6、GEANT4和FLUKA）在质子治疗即发伽马射线谱（PGS）模拟中的准确性，用于精确射程验证。研究人员通过实验数据验证了不同代码的性能，发现GEANT4能较好地模拟硼谱线，FLUKA在中等能量范围内表现更佳，而MCNP6在高能量下模拟碳谱线更准确。所有代码均未能准确模拟氧谱线。研究人员开发了一个新模型，成功改进了氧谱线的模拟准确性，并强调了更新MC模拟数据表以及进一步开展相关理论和实验研究的重要性。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17754",
    "link": "https://doi.org/10.1002/mp.17754"
  },
  {
    "title": "Knowledge relay: Synergetic generation and transfer learning for pancreatic tumor segmentation on multimodal images.",
    "authors": [
      "Shuiping Gou",
      "Ningtao Liu",
      "Wenbo Liu",
      "Yao Yao"
    ],
    "abstract": "BACKGROUND: Pancreatic cancer is among the most lethal malignancies, with the lowest survival rates. The use of image-guided radiotherapy has shown significant potential in enhancing surgical outcomes for pancreatic cancer. However, accurate segmentation of pancreatic tumors prior to radiotherapy remains a challenge due to the small size, irregular shape, and indistinct boundaries of the pancreas and tumor in monomodal imaging. Furthermore, the availability of multimodal images that meet the requirements for precise pancreatic segmentation is highly limited, leading to the datasets that fail to provide comprehensive knowledge for effective image representation in pancreatic tumor segmentation.\nPURPOSE: This study aims to develop a method for accurately segmenting pancreatic tumors under very harsh data conditions, in which the currently available datasets are fragmented with the issues, such as limited sample sizes, inconsistent lesion matching, and incomplete modalities.\nMETHODS: We propose a knowledge relay framework that leverages synergistic generation and transfer learning strategies. The relay comprises three batons: pancreatic PET image generation, coarse detection, and fine segmentation. Multimodal images, including CT, MR, and PET from three separate datasets, are integrated within this framework. The knowledge contained in each dataset is sequentially transferred and aggregated through the batons by the strategies of transfer learning and fine-tuning. Additionally, we introduce a mask-constrained CycleGAN and an inter-attention UNet within this framework to enhance the extraction and utilization of knowledge for accurate pancreatic tumor segmentation.\nRESULTS: The proposed knowledge relay framework achieves the state-of-the-art performance in pancreatic tumor segmentation on PET/MR images. On the images collected from 19 subjects, our method attained a DSC $\\text{DSC}$  of 80.06%, SEN $\\text{SEN}$  of 83.39%, SPE $\\text{SPE}$  of 99.81%, ASD $\\text{ASD}$  of 4.87 mm $\\text{mm}$  , and  95 HD $95 \\text{HD}$  of 12.69 mm $\\text{mm}$  .\nCONCLUSIONS: The results of comparison and ablation experiments validate the effectiveness of the proposed knowledge relay framework in extracting and integrating knowledge from fragmented datasets under constrained conditions. The comprehensive and enriched knowledge significantly enhances the accuracy of pancreatic tumor segmentation.",
    "abstract_zh": "**翻译：**<br><br>背景：胰腺癌是最致命的恶性肿瘤之一，生存率最低。图像引导放射疗法在提高胰腺癌手术效果方面显示出巨大的潜力。然而，由于单模态成像中胰腺和肿瘤的体积小、形状不规则且边界不清晰，因此在放射疗法前对胰腺肿瘤进行精确分割仍然是一个挑战。此外，满足精确胰腺分割要求的多模态图像的可用性非常有限，导致数据集无法提供全面的知识，从而无法有效地表示胰腺肿瘤分割中的图像。<br><br>目的：本研究旨在开发一种在极其苛刻的数据条件下精确分割胰腺肿瘤的方法，在这种条件下，目前可用的数据集存在碎片化问题，例如样本量有限、病灶匹配不一致以及模态不完整。<br><br>方法：我们提出了一种知识中继框架，该框架利用协同生成和迁移学习策略。该中继包含三个接力棒：胰腺PET图像生成、粗略检测和精细分割。来自三个独立数据集的多模态图像，包括CT、MR和PET，被整合到该框架中。每个数据集中包含的知识通过迁移学习和微调策略，通过接力棒按顺序传递和聚合。此外，我们在该框架内引入了掩码约束的CycleGAN和内部注意力UNet，以增强知识的提取和利用，从而实现精确的胰腺肿瘤分割。<br><br>结果：所提出的知识中继框架在PET/MR图像上的胰腺肿瘤分割方面实现了最先进的性能。在从19名受试者收集的图像上，我们的方法获得了80.06%的DSC，83.39%的SEN，99.81%的SPE，4.87 mm的ASD和12.69 mm的95 HD。<br><br>结论：对比实验和消融实验的结果验证了所提出的知识中继框架在受限条件下从碎片化数据集中提取和整合知识的有效性。全面而丰富的知识显著提高了胰腺肿瘤分割的准确性。",
    "summary_zh": "本研究针对胰腺肿瘤分割中数据碎片化问题，提出了一种知识中继框架，通过协同生成和迁移学习策略，整合来自不同数据集（CT、MR、PET）的知识。该框架包含胰腺PET图像生成、粗略检测和精细分割三个阶段，并引入了掩码约束CycleGAN和内部注意力UNet来增强知识提取和利用。实验结果表明，该方法在PET/MR图像上的胰腺肿瘤分割中取得了显著的性能提升，验证了其在处理受限和碎片化数据方面的有效性。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17713",
    "link": "https://doi.org/10.1002/mp.17713"
  },
  {
    "title": "Characterization of artificial intelligence performance for lesion detection using synthetic lesions in PET imaging.",
    "authors": [
      "Quinn de Bourbon",
      "Shadab Ahamed",
      "Paul Blanc-Durand",
      "Arman Rahmim",
      "Ran Klein"
    ],
    "abstract": "BACKGROUND: The use of artificial intelligence (AI) for lesion detection has witnessed increased interest and efforts in recent years. Meanwhile, task-specific characterization and comparison of AI performance is lacking as supportive evidence prior to its implementation in the clinical setting.\nPURPOSE: To evaluate the use of synthetic lesions in positron emission tomography (PET) and computed tomography (CT) to characterize the performance of lesion detection AI in terms of their limits of detection.\nMETHODS: An image library was constructed containing 565 well-characterized synthetic lesions in 114 reconstructed studies from 56 real, disease-free PET/CT patient data. Using the Lesion Synthesis Toolbox (LST), lesions were manually defined in terms of location, size and intensity. These lesions were then synthesized, forward projected, and added to the raw patient PET data before reconstruction using the same methods used clinically. Lesions were also appended to the reconstructed CT images. This library was sent to two external research teams developing AI for lesion detection in fluorodeoxyglucose (18F-FDG) PET. AI reported lesions were compared to ground truth data and labelled as hit, miss, or false positive. Psychophysical response models were fitted to each AI's responses to characterize their performance.\nRESULTS: Both AI methods confirmed higher lesion detection rates with increased lesion size and contrast. One AI consistently outperformed the other in terms of number of reported lesions, sensitivity, and precision. The fitted psychophysical response model demonstrated both graphically and parametrically an ability of this model to detect smaller lesions for a given degree of reliability. For example, 10 mm diameter lesions could be detected with 90% sensitivity at 8:1 versus 16:1 lesion to background ratio for the two algorithms. Likewise, 3:1 contrast lesions could be detected with 90% sensitivity when lesion diameters were approximately 16 and 31 mm for each algorithm respectively. Compared to defined lesions parameters, the corresponding AI segmented lesions had lower contrast, consistent with partial volume effects in PET imaging, and also smaller size.\nCONCLUSION: Synthetic lesions are a useful tool to characterize the performance of lesion detection by an observer. Visual and psychometric response models of lesion detection performance with respect to lesion characteristics are effective to objectively compare AI performance on the merit of limits of detection. These methods can be applied to objectively compare lesion detection performance with any alternative decision support tool including human and machine observers, display technologies, and image generation systems.",
    "abstract_zh": "**翻译：**<br><br>背景：近年来，使用人工智能（AI）进行病灶检测的兴趣和投入日益增长。然而，在临床应用之前，缺乏针对特定任务的AI性能表征和比较作为支持性证据。<br><br>目的：评估在正电子发射断层扫描（PET）和计算机断层扫描（CT）中使用合成病灶来表征病灶检测AI的性能，尤其是在检测极限方面。<br><br>方法：构建了一个图像库，其中包含来自56例真实的、无病PET/CT患者数据的114项重建研究中的565个特征明确的合成病灶。使用病灶合成工具箱（LST），手动定义病灶的位置、大小和强度。然后将这些病灶进行合成、正向投影，并在使用与临床相同的方法重建之前添加到原始患者PET数据中。病灶也被附加到重建后的CT图像上。该图像库被发送给两个外部研究团队，用于开发氟代脱氧葡萄糖（18F-FDG）PET中的病灶检测AI。将AI报告的病灶与真实数据进行比较，并标记为命中、未命中或假阳性。将心理物理反应模型拟合到每个AI的反应，以表征其性能。<br><br>结果：两种AI方法都证实，随着病灶大小和对比度的增加，病灶检测率更高。在报告的病灶数量、灵敏度和精确度方面，一种AI始终优于另一种AI。拟合的心理物理反应模型以图形和参数化的方式展示了该模型检测给定可靠程度下较小病灶的能力。例如，对于两种算法，可以在8:1与16:1的病灶与背景比率下以90%的灵敏度检测到直径为10 mm的病灶。同样，当病灶直径对于每种算法分别约为16 mm和31 mm时，可以以90%的灵敏度检测到3:1对比度的病灶。与定义的病灶参数相比，相应的AI分割病灶具有较低的对比度（与PET成像中的部分体积效应一致）和较小的尺寸。<br><br>结论：合成病灶是表征观察者病灶检测性能的有用工具。关于病灶特征的病灶检测性能的视觉和心理测量反应模型可有效地客观比较AI在检测极限方面的性能。这些方法可以应用于客观地比较病灶检测性能与任何替代决策支持工具，包括人类和机器观察者、显示技术和图像生成系统。",
    "summary_zh": "本研究利用合成病灶，在PET/CT图像中对两种病灶检测AI的性能进行了客观评估，尤其关注其检测极限。结果表明，AI的检测率与病灶大小和对比度正相关，且不同AI的性能存在差异。心理物理模型能够有效表征AI的检测能力，并量化其对病灶大小和对比度的依赖性。研究证实合成病灶是一种有用的评估工具，可以用于比较各种决策支持工具（包括AI）的病灶检测能力。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17694",
    "link": "https://doi.org/10.1002/mp.17694"
  },
  {
    "title": "Results of a Geant4 benchmarking study for bio-medical applications, performed with the G4-Med system.",
    "authors": [
      "Pedro Arce",
      "Jay W Archer",
      "Lorenzo Arsini",
      "Alexander Bagulya",
      "David Bolst",
      "Jeremy M C Brown",
      "Barbara Caccia",
      "Andrew Chacon",
      "Giuseppe Antonio Pablo Cirrone",
      "Miguel Antonio Cortés-Giraldo",
      "Dean Cutajar",
      "Giacomo Cuttone",
      "Paolo Dondero",
      "Andrea Dotti",
      "Bruce Faddegon",
      "Serena Fattori",
      "Christian Fedon",
      "Susanna Guatelli",
      "Akihiro Haga",
      "Sebastien Incerti",
      "Vladimir Ivanchenko",
      "Dmitri Konstantinov",
      "Ioanna Kyriakou",
      "Albert Le",
      "Zhuxin Li",
      "Michel Maire",
      "Alessandra Malaroda",
      "Carlo Mancini-Terracciano",
      "Alfonso Mantero",
      "Claire Michelet",
      "Giuliana Milluzzo",
      "Francesca Nicolanti",
      "Mihaly Novak",
      "Chihiro Omachi",
      "Luciano Pandola",
      "Jake Harold Pensavalle",
      "Álvaro Perales",
      "Yann Perrot",
      "Giada Petringa",
      "Silvia Pozzi",
      "José Manuel Quesada",
      "José Ramos-Méndez",
      "Francesco Romano",
      "Anatoly B Rosenfeld",
      "Mitra Safavi-Naeini",
      "Dousatsu Sakata",
      "Luis G Sarmiento",
      "Takashi Sasaki",
      "Yoshihide Sato",
      "Alberto Sciuto",
      "Ioannis Sechopoulos",
      "Edward C Simpson",
      "Ronny Stanzani",
      "Alessandra Tomal",
      "Toshiyuki Toshito",
      "Hoang Ngoc Tran",
      "Christopher White",
      "Dennis H Wright"
    ],
    "abstract": "BACKGROUND: Geant4, a Monte Carlo Simulation Toolkit extensively used in bio-medical physics, is in continuous evolution to include newest research findings to improve its accuracy and to respond to the evolving needs of a very diverse user community. In 2014, the G4-Med benchmarking system was born from the effort of the Geant4 Medical Simulation Benchmarking Group, to benchmark and monitor the evolution of Geant4 for medical physics applications. The G4-Med system was first described in our Medical Physics Special Report published in 2021. Results of the tests were reported for Geant4 10.5.\nPURPOSE: In this work, we describe the evolution of the G4-Med benchmarking system.\nMETHODS: The G4-Med benchmarking suite currently includes 23 tests, which benchmark Geant4 from the calculation of basic physical quantities to the simulation of more clinically relevant set-ups. New tests concern the benchmarking of Geant4-DNA physics and chemistry components for regression testing purposes, dosimetry for brachytherapy with a    125 I $^{125}I$  source, dosimetry for external x-ray and electron FLASH radiotherapy, experimental microdosimetry for proton therapy, and in vivo PET for carbon and oxygen beams. Regression testing has been performed between Geant4 10.5 and 11.1. Finally, a simple Geant4 simulation has been developed and used to compare Geant4 EM physics constructors and physics lists in terms of execution times.\nRESULTS: In summary, our EM tests show that the parameters of the multiple scattering in the Geant4 EM constructor G4EmStandardPhysics_option3 in Geant4 11.1, while improving the modeling of the electron backscattering in high atomic number targets, are not adequate for dosimetry for clinical x-ray and electron beams. Therefore, these parameters have been reverted back to those of Geant4 10.5 in Geant4 11.2.1. The x-ray radiotherapy test shows significant differences in the modeling of the bremsstrahlung process, especially between G4EmPenelopePhysics and the other constructors under study (G4EmLivermorePhysics, G4EmStandardPhysics_option3, and G4EmStandardPhysics_option4). These differences will be studied in an in-depth investigation within our Group. Improvement in Geant4 11.1 has been observed for the modeling of the proton and carbon ion Bragg peak with energies of clinical interest, thanks to the adoption of ICRU90 to calculate the low energy proton stopping powers in water and of the Linhard-Sorensen ion model, available in Geant4 since version 11.0. Nuclear fragmentation tests of interest for carbon ion therapy show differences between Geant4 10.5 and 11.1 in terms of fragment yields. In particular, a higher production of boron fragments is observed with Geant4 11.1, leading to a better agreement with reference data for this fragment.\nCONCLUSIONS: Based on the overall results of our tests, we recommend to use G4EmStandardPhysics_option4 as EM constructor and QGSP_BIC_HP with G4EmStandardPhysics_option4, for hadrontherapy applications. The Geant4-DNA physics lists report differences in modeling electron interactions in water, however, the tests have a pure regression testing purpose so no recommendation can be formulated.",
    "abstract_zh": "**翻译：**<br><br>背景：Geant4是一个广泛应用于生物医学物理领域的蒙特卡洛模拟工具包，它不断发展，纳入最新的研究成果，以提高其精确性，并满足极其多样化的用户群体不断变化的需求。2014年，Geant4医学模拟基准测试组致力于为医学物理应用对Geant4进行基准测试并监控其发展，由此诞生了G4-Med基准测试系统。G4-Med系统最初在2021年发表的《医学物理学》特别报告中进行了描述。测试结果已针对Geant4 10.5版本进行了报告。<br><br>目的：在这项工作中，我们描述了G4-Med基准测试系统的发展演变。<br><br>方法：G4-Med基准测试套件目前包含23项测试，这些测试对Geant4进行了基准测试，范围从基本物理量的计算到更具临床相关性的设置的模拟。新的测试涉及Geant4-DNA物理和化学组件的基准测试，以进行回归测试，用于 $^{125}I$ 源的近距离放射治疗剂量学，用于外部X射线和电子FLASH放射治疗的剂量学，质子治疗的实验微剂量学，以及碳和氧束的体内PET。已在Geant4 10.5和11.1之间进行了回归测试。最后，开发了一个简单的Geant4模拟，并用于比较Geant4 EM物理构造器和物理列表在执行时间方面的差异。<br><br>结果：总之，我们的EM测试表明，Geant4 11.1中Geant4 EM构造器G4EmStandardPhysics_option3中多重散射的参数，虽然改善了高原子序数靶中电子反散射的建模，但不足以进行临床X射线和电子束的剂量学。因此，这些参数在Geant4 11.2.1中已恢复到Geant4 10.5的状态。X射线放射治疗测试表明，在轫致辐射过程的建模中存在显着差异，尤其是在G4EmPenelopePhysics与其他研究中的构造器（G4EmLivermorePhysics，G4EmStandardPhysics_option3和G4EmStandardPhysics_option4）之间。这些差异将在我们小组内部进行深入研究。由于采用了ICRU90来计算水中低能质子阻止本领以及自11.0版本以来Geant4中提供的Linhard-Sorensen离子模型，因此观察到Geant4 11.1在建模临床感兴趣能量的质子和碳离子布拉格峰方面有所改进。对碳离子治疗感兴趣的核碎裂测试表明，Geant4 10.5和11.1在碎片产量方面存在差异。特别是，用Geant4 11.1观察到更高的硼碎片产生，从而与该碎片的参考数据更好地吻合。<br><br>结论：根据我们测试的总体结果，我们建议将G4EmStandardPhysics_option4用作EM构造器，并将QGSP_BIC_HP与G4EmStandardPhysics_option4一起用于强子治疗应用。Geant4-DNA物理列表报告了在模拟电子与水相互作用方面的差异，但是，这些测试具有纯回归测试的目的，因此无法提出任何建议。",
    "summary_zh": "该摘要介绍了G4-Med基准测试系统的发展演变，该系统用于评估Geant4在医学物理应用中的性能。研究比较了不同Geant4版本（10.5到11.2.1）在电磁物理、强子物理和Geant4-DNA物理等方面的差异，并针对临床应用，特别是X射线和粒子放射治疗，提出了EM构造器和物理列表的建议。结果表明G4EmStandardPhysics_option3的参数调整存在问题，影响临床剂量学；G4EmPenelopePhysics在轫致辐射建模方面与其他构造器存在差异；Geant4 11.1在质子和碳离子布拉格峰建模方面有所改进；Geant4-DNA的测试仅用于回归测试，不提供建议。 总体建议是使用G4EmStandardPhysics_option4作为EM构造器，并结合QGSP_BIC_HP用于强子治疗。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17678",
    "link": "https://doi.org/10.1002/mp.17678"
  },
  {
    "title": "A magnetic field compatible readout circuit for enhanced coincidence time resolution in BGO Cherenkov radiation-based TOF-PET detectors.",
    "authors": [
      "Shirin Pourashraf",
      "Joshua W Cates",
      "Craig S Levin"
    ],
    "abstract": "BACKGROUND: Developing time-of-flight positron emission tomography/magnetic resonance imaging (TOF-PET/MRI) detectors that exploit prompt Cherenkov photons from bismuth germanate (BGO) crystals for estimating 511 keV photon arrival time.\nPURPOSE: To present a low-noise, high-speed electronic readout circuit design for BGO-based TOF-PET detectors that achieves enhanced coincidence time resolution (CTR) in presence of a strong magnetic field.\nMETHODS: The CTR of a BGO-based TOF-PET test detector employing a high-speed, low-noise electronic readout chain was evaluated in a strong magnetic field produced by a permanent magnet placed directly on top of the circuit. For these experiments, which exploit Cherenkov radiation for precise measurement of annihilation photon time arrival time difference, a point source of 22Na was positioned between a pair of 3 × 3 × 15 mm3 polished BGO crystals wrapped in Teflon tape and optically coupled to 3 × 3 mm2 ultra-violet (UV)-sensitive silicon photomultipliers (SiPMs).\nRESULTS: By incorporating both Cherenkov (prompt) and standard (slow) luminescence components, 283 ± 8 ps and 275 ± 10 ps full-width-half-maximum (FWHM) CTR were achieved without and with the permanent magnet present, respectfully. These values improved to 236 ± 4 ps and 216 ± 17 ps FWHM when only the Cherenkov components of the timing signal (events with the fastest rise time) were considered.\nCONCLUSIONS: Results indicate we have designed a high-performance readout circuit that achieves significantly the same CTR in BGO with or without a strong magnetic field present. This further demonstrates that UV SiPMs can effectively operate in a strong magnetic field while remaining highly advantageous for detecting Cherenkov radiation, thus highlighting their potential to be used in BGO-based TOF-PET/MRI scanners.",
    "abstract_zh": "**翻译：**<br><br>背景：开发飞行时间正电子发射断层扫描/磁共振成像（TOF-PET/MRI）探测器，利用锗酸铋（BGO）晶体产生的瞬时切伦科夫光子来估计511 keV光子的到达时间。<br><br>目的：提出一种用于基于BGO的TOF-PET探测器的低噪声、高速电子读出电路设计，该设计在强磁场下实现增强的符合时间分辨率（CTR）。<br><br>方法：在一个永磁体直接放置在电路顶部产生的强磁场中，评估了采用高速、低噪声电子读出链的基于BGO的TOF-PET测试探测器的CTR。在这些实验中，利用切伦科夫辐射来精确测量湮灭光子到达的时间差，一个<sup>22</sup>Na点源被放置在一对用特氟龙胶带包裹并光学耦合到3 × 3 mm<sup>2</sup>紫外（UV）敏感硅光电倍增管（SiPMs）的3 × 3 × 15 mm<sup>3</sup>抛光BGO晶体之间。<br><br>结果：通过结合切伦科夫（瞬时）和标准（慢速）发光成分，在有和没有永磁体存在的情况下，分别实现了283 ± 8 ps和275 ± 10 ps半峰全宽（FWHM）CTR。当仅考虑定时信号的切伦科夫成分（具有最快上升时间的事件）时，这些值分别改善到236 ± 4 ps和216 ± 17 ps FWHM。<br><br>结论：结果表明，我们设计了一种高性能读出电路，在有或没有强磁场的情况下，在BGO中实现了基本相同的CTR。这进一步证明了紫外SiPMs可以在强磁场中有效工作，同时保持了检测切伦科夫辐射的高度优势，从而突出了它们在基于BGO的TOF-PET/MRI扫描仪中的应用潜力。",
    "summary_zh": "该研究设计了一种低噪声、高速的电子读出电路，用于基于BGO晶体的TOF-PET探测器。通过结合BGO晶体的切伦科夫光子和传统发光，并在强磁场环境下进行测试，验证了该电路能有效提高符合时间分辨率（CTR），且紫外SiPMs能够在这种环境下稳定工作，表明其在BGO-based TOF-PET/MRI扫描仪中有良好的应用前景。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17643",
    "link": "https://doi.org/10.1002/mp.17643"
  },
  {
    "title": "Realistic total-body J-PET geometry optimization: Monte Carlo study.",
    "authors": [
      "Jakub Baran",
      "Wojciech Krzemien",
      "Szymon Parzych",
      "Lech Raczyński",
      "Mateusz Bała",
      "Aurélien Coussat",
      "Neha Chug",
      "Eryk Czerwiński",
      "Catalina Oana Curceanu",
      "Meysam Dadgar",
      "Kamil Dulski",
      "Kavya Eliyan",
      "Jan Gajewski",
      "Aleksander Gajos",
      "Beatrix C Hiesmayr",
      "Krzysztof Kacprzak",
      "Łukasz Kapłon",
      "Konrad Klimaszewski",
      "Grzegorz Korcyl",
      "Tomasz Kozik",
      "Deepak Kumar",
      "Szymon Niedźwiecki",
      "Dominik Panek",
      "Elena Perez Del Rio",
      "Antoni Ruciński",
      "Sushil Sharma",
      "Shivani",
      "Roman Y Shopa",
      "Magdalena Skurzok",
      "Ewa Stępień",
      "Faranak Tayefiardebili",
      "Keyvan Tayefiardebili",
      "Wojciech Wiślicki",
      "Paweł Moskal"
    ],
    "abstract": "BACKGROUND: Total-body (TB) Positron Emission Tomography (PET) is one of the most promising medical diagnostics modalities, opening new perspectives for personalized medicine, low-dose imaging, multi-organ dynamic imaging or kinetic modeling. The high sensitivity provided by total-body technology can be advantageous for novel tomography methods like positronium imaging, demanding the registration of triple coincidences. Currently, state-of-the-art PET scanners use inorganic scintillators. However, the high acquisition cost reduces the accessibility of TB PET technology. Several efforts are ongoing to mitigate this problem. Among the alternatives, the Jagiellonian PET (J-PET) technology, based on axially arranged plastic scintillator strips, offers a low-cost alternative solution for TB PET.\nPURPOSE: The work aimed to compare five total-body J-PET geometries with plastic scintillators suitable for multi-organ and positronium tomography as a possible next-generation J-PET scanner design.\nMETHODS: We present comparative studies of performance characteristics of the cost-effective total-body PET scanners using J-PET technology. We investigated in silico five TB scanner geometries, varying the number of rings, scanner radii, and other parameters. Monte Carlo simulations of the anthropomorphic XCAT phantom, the extended 2-m sensitivity line source and positronium sensitivity phantoms were used to assess the performance of the geometries. Two hot spheres were placed in the lungs and in the liver of the XCAT phantom to mimic the pathological changes. We compared the sensitivity profiles and performed quantitative analysis of the reconstructed images by using quality metrics such as contrast recovery coefficient, background variability and root mean squared error. The studies are complemented by the determination of sensitivity for the positronium lifetime tomography and the relative cost analysis of the studied setups.\nRESULTS: The analysis of the reconstructed XCAT images reveals the superiority of the seven-ring scanners over the three-ring setups. However, the three-ring scanners would be approximately 2-3 times cheaper. The peak sensitivity values for two-gamma vary from 20 to 34 cps/kBq and are dominated by the differences in geometrical acceptance of the scanners. The sensitivity curves for the positronium tomography have a similar shape to the two-gamma sensitivity profiles. The peak values are lower compared to the two-gamma cases, from about 20-28 times, with a maximum value of 1.66 cps/kBq. This can be contrasted with the 50-cm one-layer J-PET modular scanner used to perform the first in-vivo positronium imaging with a sensitivity of 0.06 cps/kBq.\nCONCLUSIONS: The results show the feasibility of multi-organ imaging of all the systems to be considered for the next generation of TB J-PET designs. Among the scanner parameters, the most important ones are related to the axial field-of-view coverage. The two-gamma sensitivity and XCAT image reconstruction analyzes show the advantage of seven-ring scanners. However, the cost of the scintillator materials and SiPMs is more than two times higher for the longer modalities compared to the three-ring solutions. Nevertheless, the relative cost for all the scanners is about 10-4 times lower compared to the cost of the uExplorer. These properties coupled together with J-PET cost-effectiveness and triggerless acquisition mode enabling three-gamma positronium imaging, make the J-PET technology an attractive solution for broad application in clinics.",
    "abstract_zh": "**翻译：**<br><br>背景：全身正电子发射断层扫描（TB PET）是最有前景的医学诊断技术之一，为个性化医疗、低剂量成像、多器官动态成像或动力学建模开辟了新的视角。全身技术提供的高灵敏度对于正电子素成像等新型断层扫描方法非常有利，后者需要注册三重符合事件。目前，最先进的PET扫描仪使用无机闪烁体。然而，高昂的购置成本降低了全身PET技术的普及性。目前正在进行多项工作以缓解这个问题。在替代方案中，基于轴向排列的塑料闪烁体条的亚捷隆尼PET（J-PET）技术，为全身PET提供了一种低成本的替代解决方案。<br><br>目的：本研究旨在比较五种采用塑料闪烁体的全身J-PET几何结构，这些结构适用于多器官和正电子素断层扫描，可作为下一代J-PET扫描仪的设计方案。<br><br>方法：我们展示了使用J-PET技术的、具有成本效益的全身PET扫描仪的性能特征的比较研究。我们通过计算机模拟研究了五种全身扫描仪几何结构，改变了环数、扫描仪半径和其他参数。使用人体测量XCAT体模、延伸的2米灵敏度线源和正电子素灵敏度体模的蒙特卡罗模拟来评估这些几何结构的性能。在XCAT体模的肺部和肝脏中放置了两个热球，以模拟病理变化。我们比较了灵敏度曲线，并使用对比度恢复系数、背景变异性和均方根误差等质量指标，对重建图像进行了定量分析。这些研究还补充了正电子素寿命断层扫描的灵敏度测定以及所研究设置的相对成本分析。<br><br>结果：对重建的XCAT图像的分析表明，七环扫描仪优于三环设置。然而，三环扫描仪的成本大约便宜2-3倍。两伽马峰值灵敏度值在20到34 cps/kBq之间，并且主要受扫描仪几何接收度的差异影响。正电子素断层扫描的灵敏度曲线与两伽马灵敏度曲线的形状相似。与两伽马情况相比，峰值较低，大约低20-28倍，最大值为1.66 cps/kBq。相比之下，用于执行首次体内正电子素成像的50厘米单层J-PET模块化扫描仪的灵敏度为0.06 cps/kBq。<br><br>结论：结果表明，所有系统都适用于下一代全身J-PET设计的多器官成像。在扫描仪参数中，最重要的是与轴向视野覆盖范围相关的参数。两伽马灵敏度和XCAT图像重建分析表明，七环扫描仪具有优势。然而，与三环解决方案相比，较长模态的闪烁体材料和SiPM的成本高出两倍以上。尽管如此，所有扫描仪的相对成本比uExplorer的成本低约10-4倍。这些特性，再加上J-PET的成本效益和能够进行三伽马正电子素成像的无触发采集模式，使J-PET技术成为一种有吸引力的临床广泛应用解决方案。",
    "summary_zh": "本研究旨在评估五种基于塑料闪烁体的全身J-PET扫描仪几何结构，以期设计出下一代低成本的全身PET系统。通过模拟XCAT体模、灵敏度线源和正电子素灵敏度体模，评估了不同几何结构的性能，包括灵敏度、图像质量和成本。结果表明，七环扫描仪在图像质量上优于三环扫描仪，但成本更高。尽管如此，J-PET扫描仪的成本远低于传统的全身PET扫描仪，且具备正电子素成像能力，使其成为一种极具潜力的临床应用方案。",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17627",
    "link": "https://doi.org/10.1002/mp.17627"
  }
]