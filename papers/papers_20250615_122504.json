[
  {
    "title": "Physical phantom validation of clustering-initiated factorization in dynamic PET.",
    "authors": [
      "Valerie Kobzarenko",
      "Suzanne L Baker",
      "Mustafa Janabi",
      "Woon-Seng Choong",
      "Grant T Gullberg",
      "Youngho Seo",
      "Rostyslav Boutchko",
      "Debasis Mitra"
    ],
    "abstract": "BACKGROUND: Dynamic positron emission tomography (PET) enables the quantification of physiological parameters of radiotracers employed in the investigation of neuropsychiatric disorders. We previously introduced a factor analysis-based algorithm, Cluster-Initialized Factor Analysis (CIFA), designed to overcome the problem of specifying reference regions. CIFA is capable of automatically extracting distinct radiotracer binding distributions across many modalities based on the differences in tracer dynamics, and thus can distinguish regions of specific- and non-specific binding without requiring prior segmentation.\nPURPOSE: Our goal is to quantitatively validate the ability of CIFA to resolve different dynamic biological processes by comparing the output of the algorithm to an independent benchmark. As an intermediate goal, we aim to create a physical phantom capable of modeling unique aspects of dynamic imaging and to use this phantom as the benchmark in evaluating CIFA.\nMETHODS: CIFA was used to reconstruct 18F-flortaucipir dynamic brain PET datasets acquired at Lawrence Berkeley National Lab. The resulting factor curves served as the foundation for creating dynamic input time-activity curve (TAC) combinations in a physical brain phantom specifically constructed for this purpose. The phantom represented three components: two overlapping tissue types and free radiotracer, constructed with a combination of small hydraulic elements. The physical components were scanned separately to generate a library of images, allowing us to reproduce scans of any duration with prescribed dynamics and realistic partial volume effects. The phantom was designed to produce noisy instances with compartment mixing of dynamic scans with desired activity TACs for free, non-specifically bound, and specifically bound radiotracers. Ten distinct dynamic simulations with varying levels of TAC similarity were estimated with CIFA.\nRESULTS: We directly evaluated CIFA's performance in analyzing each of the 10 dynamic datasets by computing the Pearson correlation coefficient between the estimated outputs and the ground truth tissue TACs and corresponding tissue distributions. For seven out of 10 modeled dynamics, which captured the full spectrum of realistically expected tissue TAC shapes, the curve correlation of the specific binding tissue was above 95%.\nCONCLUSIONS: This work formulated an innovative process by combining a physical phantom design with PET images for evaluating the application of CIFA in the extraction of dynamic TACs from dynamic PET image data. In most cases the CIFA algorithm accurately reproduced the dynamics of the phantom simulated data.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17902",
    "link": "https://doi.org/10.1002/mp.17902"
  },
  {
    "title": "Generation of synthetic CT from MRI for MRI-based attenuation correction of brain PET images using radiomics and machine learning.",
    "authors": [
      "Amin Hoseinipourasl",
      "Gholam-Ali Hossein-Zadeh",
      "Peyman Sheikhzadeh",
      "Hossein Arabalibeik",
      "Shaghayegh Karimi Alavijeh",
      "Habib Zaidi",
      "Mohammad Reza Ay"
    ],
    "abstract": "BACKGROUND: Accurate quantitative PET imaging in neurological studies requires proper attenuation correction. MRI-guided attenuation correction in PET/MRI remains challenging owing to the lack of direct relationship between MRI intensities and linear attenuation coefficients.\nPURPOSE: This study aims at generating accurate patient-specific synthetic CT volumes, attenuation maps, and attenuation correction factor (ACF) sinograms with continuous values utilizing a combination of machine learning algorithms, image processing techniques, and voxel-based radiomics feature extraction approaches.\nMETHODS: Brain MR images of ten healthy volunteers were acquired using IR-pointwise encoding time reduction with radial acquisition (IR-PETRA) and VIBE-Dixon techniques. synthetic CT (SCT) images, attenuation maps, and attenuation correction factors (ACFs) were generated using the LightGBM, a fast and accurate machine learning algorithm, from the radiomics-based and image processing-based feature maps of MR images. Additionally, ultra-low-dose CT images of the same volunteers were acquired and served as the standard of reference for evaluation. The SCT images, attenuation maps, and ACF sinograms were assessed using qualitative and quantitative evaluation metrics and compared against their corresponding reference images, attenuation maps, and ACF sinograms.\nRESULTS: The voxel-wise and volume-wise comparison between synthetic and reference CT images yielded an average mean absolute error of 60.75 ± 8.8 HUs, an average structural similarity index of 0.88 ± 0.02, and an average peak signal-to-noise ratio of 32.83 ± 2.74 dB. Additionally, we compared MRI-based attenuation maps and ACF sinograms with their CT-based counterparts, revealing average normalized mean absolute errors of 1.48% and 1.33%, respectively.\nCONCLUSION: Quantitative assessments indicated higher correlations and similarities between LightGBM-synthesized CT and Reference CT images. Moreover, the cross-validation results showed the possibility of producing accurate SCT images, MRI-based attenuation maps, and ACF sinograms. This might spur the implementation of MRI-based attenuation correction on PET/MRI and dedicated brain PET scanners with lower computational time using CPU-based processors.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17867",
    "link": "https://doi.org/10.1002/mp.17867"
  },
  {
    "title": "Impact of tracer uptake rate on quantification accuracy of myocardial blood flow in PET: A simulation study.",
    "authors": [
      "Xiaotong Hong",
      "Amirhossein Sanaat",
      "Yazdan Salimi",
      "René Nkoulou",
      "Hossein Arabi",
      "Lijun Lu",
      "Habib Zaidi"
    ],
    "abstract": "BACKGROUND: Cardiac perfusion PET is commonly used to assess ischemia and cardiovascular risk, which enables quantitative measurements of myocardial blood flow (MBF) through kinetic modeling. However, the estimation of kinetic parameters is challenging due to the noisy nature of short dynamic frames and limited sample data points.\nPURPOSE: This work aimed to investigate the errors in MBF estimation in PET through a simulation study and to evaluate different parameter estimation approaches, including a deep learning (DL) method.\nMATERIALS AND METHODS: Simulated studies were generated using digital phantoms based on cardiac segmentations from 55 clinical CT images. We employed the irreversible 2-tissue compartmental model and simulated dynamic 13N-ammonia PET scans under both rest and stress conditions (220 cases each). The simulations covered a rest K1 range of 0.6 to 1.2 and a stress K1 range of 1.2 to 3.6 (unit: mL/min/g) in the myocardium. A transformer-based DL model was trained on the simulated dataset to predict parametric images (PIMs) from noisy PET image frames and was validated using 5-fold cross-validation. We compared the DL method with the voxel-wise nonlinear least squares (NLS) fitting applied to the dynamic images, using either Gaussian filter (GF) smoothing (GF-NLS) or a dynamic nonlocal means (DNLM) algorithm for denoising (DNLM-NLS). Two patients with coronary CT angiography (CTA) and fractional flow reserve (FFR) were enrolled to test the feasibility of applying DL models on clinical PET data.\nRESULTS: The DL method showed clearer image structures with reduced noise compared to the traditional NLS-based methods. In terms of mean absolute relative error (MARE), as the rest K1 values increased from 0.6 to 1.2 mL/min/g, the overall bias in myocardium K1 estimates decreased from approximately 58% to 45% for the NLS-based methods while the DL method showed a reduction in MARE from 42% to 18%. For stress data, as the stress K1 decreased from 3.6 to 1.2 mL/min/g, the MARE increased from 30% to 70% for the GF-NLS method. In contrast, both the DNLM-NLS (average: 42%) and the DL methods (average: 20%) demonstrated significantly smaller MARE changes as stress K1 varied. Regarding the regional mean bias (±standard deviation), the GF-NLS method had a bias of 6.30% (±8.35%) of rest K1, compared to 1.10% (±8.21%) for DNLM-NLS and 6.28% (±14.05%) for the DL method. For the stress K1, the GF-NLS showed a mean bias of 10.72% (±9.34%) compared to 1.69% (±8.82%) for DNLM-NLS and -10.55% (±9.81%) for the DL method.\nSIGNIFICANCE: This study showed that an increase in the tracer uptake rate (K1) corresponded to improved accuracy and precision in MBF quantification, whereas lower tracer uptake resulted in higher noise in dynamic PET and poorer parameter estimates. Utilizing denoising techniques or DL approaches can mitigate noise-induced bias in PET parametric imaging.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17871",
    "link": "https://doi.org/10.1002/mp.17871"
  },
  {
    "title": "Instantaneous in vivo distal edge verification in intensity-modulated proton therapy by means of PET imaging.",
    "authors": [
      "Brian Zapien-Campos",
      "Zahra Ahmadi Ganjeh",
      "Giuliano Perotti-Bernardini",
      "Jeffrey Free",
      "Stefan Both",
      "Peter Dendooven"
    ],
    "abstract": "BACKGROUND: Intensity-modulated proton therapy (IMPT) holds promise for improving outcomes in head-and-neck cancer (HNC) patients by enhancing organ-at-risk (OAR) sparing. A key challenge in IMPT is ensuring an accurate dose delivery at the distal edge of the tumor, where the steep dose gradients make treatment precision highly sensitive to uncertainties in both proton range and patient setup. Thus, IMPT conformality is increased by incorporating robust margins in the treatment optimization. However, an increment in the plan robustness could lead to an OAR overdosing. Therefore, an accurate distal edge verification during dose delivery is crucial to increase IMPT conformality by reducing optimization settings in treatment planning.\nPURPOSE: This work aims to evaluate, in a quasi-clinical setting, a novel approach for accurate instantaneous proton beam distal edge verification in IMPT by means of spot-by-spot positron emission tomography (PET) imaging.\nMETHODS: An anthropomorphic head and neck phantom CIRS-731 HN was irradiated at the head and neck region. The targets were defined as 4 cm diameter spheres. A 60-ms delay was introduced between the proton beam spots in order to enable the spot-by-spot coincidence detection of the 511-keV photons resulting from positron annihilation following the positron emission from very short-lived positron-emitting, mainly 12N (T1/2  = 11.0 ms). Additionally, modified irradiations were carried out using solid water slabs of 2 and 5 mm thickness in the beam path to assess the precision of the approach for detecting range deviations. The positron activity range (PAR) was determined from the 50% distal fall-off position of the 1D longitudinal positron activity profile derived from the 2D image reconstructions. Furthermore, Monte Carlo (MC) simulations were performed using an in-house RayStation/GATE MC framework to predict the positron activity images and verify the PAR measurements.\nRESULTS: PAR measurements achieved a precision between 1.5 and 3.6 mm (at 1.5σ clinical level) at the beam spot level within sub-second time scales. Measured PAR shifts of 1.6-2.1  and 4.2--.7 mm were observed with the 2- and 5-mm thickness range shifters, respectively, aligning with the corresponding proton dose range (PDR) shifts of 1.3-1.8 and 3.9-4.3 mm. The simulated PAR agrees with the measured PARs, showing an average range difference of ∼0.4 mm.\nCONCLUSION: This study demonstrated the feasibility of instantaneous distal edge verification using PET imaging by introducing beam spot delays during dose delivery. The findings represent a first step toward the clinical implementation of instantaneous in vivo distal edge verification. The approach contributes to the development of real-time range verification aimed at improving IMPT treatments by mitigating range and setup uncertainties, thereby reducing dose to organs-at-risk and ultimately enhancing patient outcomes.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17850",
    "link": "https://doi.org/10.1002/mp.17850"
  },
  {
    "title": "Modeling inter-reader variability in clinical target volume delineation for soft tissue sarcomas using diffusion model.",
    "authors": [
      "Yafei Dong",
      "Thibault Marin",
      "Yue Zhuo",
      "Elie Najem",
      "Arnaud Beddok",
      "Laura Rozenblum",
      "Maryam Moteabbed",
      "Kira Grogg",
      "Fangxu Xing",
      "Jonghye Woo",
      "Yen-Lin E Chen",
      "Ruth Lim",
      "Xiaofeng Liu",
      "Chao Ma",
      "Georges El Fakhri"
    ],
    "abstract": "BACKGROUND: Accurate delineation of the clinical target volume (CTV) is essential in the radiotherapy treatment of soft tissue sarcomas. However, this process is subject to inter-reader variability due to the need for clinical assessment of risk and extent of potential microscopic spread. This can lead to inconsistencies in treatment planning, potentially impacting treatment outcomes. Most existing automatic CTV delineation methods do not account for this variability and can only generate a single CTV for each case.\nPURPOSE: This study aims to develop a deep learning-based technique to generate multiple CTV contours for each case, simulating the inter-reader variability in the clinical practice.\nMETHODS: We employed a publicly available dataset consisting of fluorodeoxyglucose positron emission tomography (FDG-PET), x-ray computed tomography (CT), and pre-contrast T1-weighted magnetic resonance imaging (MRI) scans from 51 patients with soft tissue sarcoma, along with an independent validation set containing five additional patients. An experienced reader drew a contour of the gross tumor volume (GTV) for each patient based on multi-modality images. Subsequently, two additional readers, together with the first one, were responsible for contouring three CTVs in total based on the GTV. We developed a diffusion model-based deep learning method that is capable of generating arbitrary number of different and plausible CTVs to mimic the inter-reader variability in CTV delineation. The proposed model incorporates a separate encoder to extract features from the GTV masks, leveraging the critical role of GTV information in accurate CTV delineation.\nRESULTS: The proposed diffusion model demonstrated superior performance with the highest Dice Index (0.902 compared to values below 0.881 for state-of-the-art models) and the best generalized energy distance (GED) (0.209 compared to values exceeding 0.221 for state-of-the-art models). It also achieved the second-highest recall and precision metrics among the compared ambiguous image segmentation models. Results from both datasets exhibited consistent trends, reinforcing the reliability of our findings. Additionally, ablation studies exploring different model structures and input configurations highlighted the significance of incorporating prior GTV information for accurate CTV delineation.\nCONCLUSIONS: The proposed diffusion model successfully generates multiple plausible CTV contours for soft tissue sarcomas, effectively capturing inter-reader variability in CTV delineation.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17865",
    "link": "https://doi.org/10.1002/mp.17865"
  },
  {
    "title": "Thorax-encompassing multi-modality PET/CT deep learning model for resected lung cancer prognostication: A retrospective, multicenter study.",
    "authors": [
      "Jaryd R Christie",
      "Perrin Romine",
      "Karen Eddy",
      "Delphine L Chen",
      "Omar Daher",
      "Mohamed Abdelrazek",
      "Richard A Malthaner",
      "Mehdi Qiabi",
      "Rahul Nayak",
      "Paul Kinahan",
      "Viswam S Nair",
      "Sarah A Mattonen"
    ],
    "abstract": "BACKGROUND: Patients with early-stage non-small cell lung cancer (NSCLC) typically receive surgery as their primary form of treatment. However, studies have shown that a high proportion of these patients will experience a recurrence after their resection, leading to an increased risk of death. Cancer staging is currently the gold standard for establishing a patient's prognosis and can help clinicians determine patients who may benefit from additional therapy. However, medical images which are used to help determine the cancer stage, have been shown to hold unutilized prognostic information that can augment clinical data and better identify high-risk NSCLC patients. There remains an unmet need for models to incorporate clinical, pathological, surgical, and imaging information, and extend beyond the current staging system to assist clinicians in identifying patients who could benefit from additional therapy immediately after surgery.\nPURPOSE: We aimed to determine whether a deep learning model (DLM) integrating FDG PET and CT imaging from the thoracic cavity along with clinical, surgical, and pathological information can predict NSCLC recurrence-free survival (RFS) and stratify patients into risk groups better than conventional staging.\nMATERIALS AND METHODS: Surgically resected NSCLC patients enrolled between 2009 and 2018 were retrospectively analyzed from two academic institutions (local institution: 305 patients; external validation: 195 patients). The thoracic cavity (including the lungs, mediastinum, pleural interfaces, and thoracic vertebrae) was delineated on the preoperative FDG PET and CT images and combined with each patient's clinical, surgical, and pathological information. Using the local cohort of patients, a multi-modal DLM using these features was built in a training cohort (n = 225), tuned on a validation cohort (n = 45), and evaluated on testing (n = 35) and external validation (n = 195) cohorts to predict RFS and stratify patients into risk groups. The area under the curve (AUC), Kaplan-Meier curves, and log-rank test were used to assess the prognostic value of the model. The DLM's stratification performance was compared to the conventional staging stratification.\nRESULTS: The multi-modal DLM incorporating imaging, pathological, surgical, and clinical data predicted RFS in the testing cohort (AUC = 0.78 [95% CI:0.63-0.94]) and external validation cohort (AUC = 0.66 [95% CI:0.58-0.73]). The DLM significantly stratified patients into high, medium, and low-risk groups of RFS in both the testing and external validation cohorts (multivariable log-rank p < 0.001) and outperformed conventional staging. Conventional staging was unable to stratify patients into three distinct risk groups of RFS (testing: p = 0.94; external validation: p = 0.38). Lastly, the DLM displayed the ability to further stratify patients significantly into sub-risk groups within each stage in the testing (stage I: p = 0.02, stage II: p = 0.03) and external validation (stage I: p = 0.05, stage II: p = 0.03) cohorts.\nCONCLUSION: This is the first study to use multi-modality imaging along with clinical, surgical, and pathological data to predict RFS of NSCLC patients after surgery. The multi-modal DLM better stratified patients into risk groups of poor outcomes when compared to conventional staging and further stratified patients within each staging classification. This model has the potential to assist clinicians in better identifying patients that may benefit from additional therapy.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17862",
    "link": "https://doi.org/10.1002/mp.17862"
  },
  {
    "title": "Evaluation of a motion correction algorithm in lung cancer PET/CT: Phantom validation and patient studies.",
    "authors": [
      "Ziyang Wang",
      "Jianjing Liu",
      "Di Lu",
      "Guoqing Sui",
      "Yaya Wang",
      "Lina Tong",
      "Xueyao Liu",
      "Yan Zhang",
      "Jie Fu",
      "Wengui Xu",
      "Dong Dai"
    ],
    "abstract": "BACKGROUND: Data-driven gating (DDG) is an emerging technology that can reduce the respiratory motion artifacts in positron emission tomography (PET) images.\nPURPOSE: The aim of this study is to use phantom and patient data to validate the performance of DDG with a motion correction algorithm based on the reconstruct, register, and average (RRA) method.\nMETHODS: A customized motion platform drove the phantom (five spheres with diameters of 10-28 mm) using a periodic motion that had a duration of 3-5 s and amplitudes of 2-4 cm. Normalized ratio of ungated and RRA PET relative to the ground-truth static PET was calculated for RSUVmax, RSUVmean, RSUVpeak, RVolume, and relative contrast-to-noise ratio (RCNR). Additionally, 30 lung cancer patients with 76 lung lesions less than 3 cm in diameter were prospectively studied. The overall image quality of patient examination was scored using a 5-point scale by two radiologists. SUVmax, SUVmean, SUVpeak, volume, and CNR of lesions measured in ungated and RRA PET were compared, and subgroup analysis was conducted.\nRESULTS: In RRA PET images, motion artifacts of the spheres in the phantom were effectively mitigated, regardless of changes in movement amplitudes or duration. For all spheres with different ranges of motion and cycles, RSUVmax, RSUVmean, RSUVpeak, and RCNR increased significantly (p ≤ 0.001) and RVolume decreased significantly (p < 0.001) in RRA PET images. The average radiologist scores of image quality were 3.90 ± 0.86 with RRA PET, and 3.03 ± 1.19 with ungated PET. In RRA PET images, the SUVmax (p < 0.001), SUVmean (p < 0.001), SUVpeak (p < 0.001), and CNR (p < 0.001) of the lesions increased, while the volume (p < 0.001) of the lesions decreased. Δ%SUVmax, Δ%SUVmean, Δ%SUVpeak, and Δ%CNR of the lesions increased by 3.9%, 6.5%, 5.6%, and 4.3%, respectively, while Δ%Volume of the lesions decreased by 18.4%. Subgroup analysis showed that in lesions in the upper and middle lobes, only SUVpeak (p < 0.001) significantly increased by 5.6% in RRA PET, while their volume (p < 0.001) notably decreased by 12.4% (p < 0.001).\nCONCLUSION: DDG integrated with RRA motion correction algorithm can effectively mitigate motion artifacts, thus enhancing the quantification accuracy and visual quality of images in lung cancer PET/CT.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17846",
    "link": "https://doi.org/10.1002/mp.17846"
  },
  {
    "title": "Hepatocellular carcinoma 18F-FDG PET/CT kinetic parameter estimation based on the advantage actor-critic algorithm.",
    "authors": [
      "Jianfeng He",
      "Siming Li",
      "Yiwei Xiong",
      "Yu Yao",
      "Siyu Wang",
      "Sidan Wang",
      "Shaobo Wang"
    ],
    "abstract": "BACKGROUND: Kinetic parameters estimated with dynamic 18F-fluorodeoxyglucose (18F-FDG) positron emission tomography (PET)/computed tomography (CT) help characterize hepatocellular carcinoma (HCC), and deep reinforcement learning (DRL) can improve kinetic parameter estimation.\nPURPOSE: The advantage actor-critic (A2C) algorithm is a DRL algorithm with neural networks that seek the optimal parameters. The aim of this study was to preliminarily assess the role of the A2C algorithm in estimating the kinetic parameters of 18F-FDG PET/CT in patients with HCC.\nMATERIALS AND METHODS: 18F-FDG PET data from 14 liver tissues and 17 HCC tumors obtained via a previously developed, abbreviated acquisition protocol (5-min dynamic PET/CT imaging supplemented with 1-min static imaging at 60 min) were prospectively collected. The A2C algorithm was used to estimate kinetic parameters with a reversible double-input, three-compartment model, and the results were compared with those of the conventional nonlinear least squares (NLLS) algorithm. Fitting errors were compared via the root-mean-square errors (RMSEs) of the time activity curves (TACs).\nRESULTS: Significant differences in K1, k2, k3, k4, fa, and vb according to the A2C algorithm and k3, fa, and vb according to the NLLS algorithm were detected between HCC and normal liver tissues (all p < 0.05). Furthermore, A2C demonstrated superior diagnostic performance over NLLS in terms of k3 and vb (both p < 0.05 in the Delong test). Notably, A2C yielded a smaller fitting error for normal liver tissue (0.62 ± 0.24 vs. 1.04 ± 1.00) and HCC tissue (1.40 ± 0.42 vs. 1.51 ± 0.97) than did NLLS.\nCONCLUSIONS: Compared with the conventional postreconstruction NLLS method, the A2C algorithm can more precisely estimate 18F-FDG kinetic parameters with a reversible double-input, three-compartment model for HCC tumors, attaining better TAC fitting with a lower RMSE.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17851",
    "link": "https://doi.org/10.1002/mp.17851"
  },
  {
    "title": "Predicting [177Lu]Lu-DOTA-TATE dosimetry by using pre-therapy [68Ga]Ga-DOTA-TATE PET/CT and biomarkers in patient with neuroendocrine tumors.",
    "authors": [
      "Hongxing Yang",
      "Ming Qi",
      "Zhihao Chen",
      "Fei Liu",
      "Junyan Xu",
      "Xiaoping Xu",
      "Qing Kong",
      "Jianping Zhang",
      "Shaoli Song"
    ],
    "abstract": "BACKGROUND: Lutetium-177 DOTA-TATE peptide receptor radionuclide therapy (PRRT) is an established and effective treatment modality for patients with metastatic neuroendocrine tumors (NETs).\nPURPOSE: This study aims to predict patient-absorbed doses from [177Lu]Lu-DOTA-TATE PRRT in the liver, kidney and lesion by utilizing patient-specific absorbed doses from pre-therapeutic [68Ga]Ga-DOTA-TATE PET/CT.\nMETHODS: Before the treatment of cycle 1, 11 patients with NETs underwent PET/CT scans at 0.5, 1.0, 2.0 and 4.0 h after the injection of [68Ga]Ga-DOTA-TATE. Patients then received [177Lu]Lu-DOTA-TATE PRRT and underwent SPECT/CT scans at 4, 24, 96, and 168 h post-administration. The segmentations and dosimetry were performed by using a professional software. The linear regression model used the absorbed doses from [68Ga]Ga-DOTA-TATE alone as the predictor variable. The multiple linear regression model used the absorbed doses from [68Ga]Ga-DOTA-TATE and the relevant clinical biomarkers as the predictor variables.\nRESULTS: The mean absorbed doses from [177Lu]Lu-DOTA-TATE PRRT in kidney and liver were 4.1 and 2.1 Gy, respectively. In comparison, the mean absorbed doses from [68Ga]Ga-DOTA-TATE were significantly lower: 18.0 mGy and 11.0 mGy, respectively. For lesions, the maximum absorbed dose from [68Ga]Ga-DOTA-TATE ranged from 24.1 to 170.4 mGy, while the maximum absorbed dose from [177Lu]Lu-DOTA-TATE PRRT was significantly higher, ranging from 9.6 to 77.9 Gy. The linear regression model yielded moderate R-squared values of 0.50, 0.59, and 0.36 for kidney, liver and lesion, respectively. The performance of multiple linear regression model was better, with R-squared values increasing to 0.81, 0.77, and 0.84.\nCONCLUSION: Absorbed doses from [177Lu]Lu-DOTA-TATE PRRT can be accurately predicted. Moreover, our models are formalized into simple equations.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17852",
    "link": "https://doi.org/10.1002/mp.17852"
  },
  {
    "title": "Predictive models of epidermal growth factor receptor mutation in lung adenocarcinoma using PET/CT-based radiomics features.",
    "authors": [
      "Zhikang Deng",
      "Di Jin",
      "Pei Huang",
      "Changchun Wang",
      "Yaohong Deng",
      "Rong Xu",
      "Bing Fan"
    ],
    "abstract": "BACKGROUND: Lung adenocarcinoma (LAC) comprises a substantial subset of non-small cell lung cancer (NSCLC) diagnoses, where epidermal growth factor receptor (EGFR) mutations play a pivotal role as indicators for therapeutic intervention with targeted agents. The emerging field of radiomics, which involves the extraction of numerous quantitative attributes from medical imaging, when coupled with positron emission tomography/ computed tomography (PET/CT) technology, has demonstrated promise in the prognostication of EGFR mutation status. The objective of this investigation is to construct and validate predictive models for EGFR mutations in LAC by leveraging PET/CT-derived radiomics features, thereby refining diagnostic precision and facilitating tailored treatment strategies.\nPURPOSE: The aim of this study was to develop a non-invasive radiomics model based on PET/CT with excellent performance for predicting the EGFR mutation status in LAC. Thus, it can provide the basis for the individualized treatment decision of patients.\nMETHODS: Positron emission tomography (PET), computed tomography (CT), clinical and pathological data of 112 patients with LAC admitted to our hospital from January 2019 to June 2023 were retrospectively analyzed. This research cohort encompassed 54 LAC patients with EGFR wild type and 58 LAC patients with EGFR mutated type. The participants were randomly assigned to the training group (n = 78) and the validation group (n = 34) in a 7:3 ratio. A sum of 3562 radiomics attributes were derived from PET/CT scans. The minimal absolute shrinkage and selection operator method was employed to identify 13 notable features. Based on these characteristics, support vector machine (SVM), gradient boosting decision tree (GBDT), random forest (RF) and extreme gradient boosting (XGBOOST) were constructed. The forecasting effectiveness of the model was assessed using the area under the receiver operating characteristic (ROC) Curve, the DeLong test, and decision curve analysis (DCA).\nRESULTS: SVM performance in PET/CT radiomics model was higher than that of other machine learning models (training group areas under the curve [AUC] of 0.916 and validation group AUC of 0.945, respectively). The integration of radiomics and clinical data did not yield a superior predictive performance compared to the radiomics model alone in terms of estimating EGFR mutation status (AUC: 0.916 vs. 0.921, 0.945 vs. 0.955, p> 0.05, in both the training and validation groups).\nCONCLUSIONS: The SVM model has emerged as a commendable non-invasive technique, showing high precision and dependability in forecasting EGFR mutation statuses in individuals with LAC. The radiomics model derived from PET/CT scans holds promise as a prognostic indicator of EGFR mutations in LAC, offering a valuable tool that could refine personalized therapeutic strategies and ultimately enhance the prognosis for LAC patients.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17780",
    "link": "https://doi.org/10.1002/mp.17780"
  },
  {
    "title": "Hybrid method for estimating lung ventilation from CT by combining intensity and motion information.",
    "authors": [
      "Paris Tzitzimpasis",
      "Mario Ries",
      "Bas W Raaymakers",
      "Cornel Zachiu"
    ],
    "abstract": "BACKGROUND: Functional lung imaging modalities allow for capturing regional lung ventilation information. Computed Tomography based ventilation imaging (CTVI) has been proposed as a surrogate modality that relies on time-resolved anatomical data and image processing. However, generating accurate ventilation maps using solely computed tomography (CT) image information remains a challenging task, due to the need to derive functional information of ventilation from anatomical observations.\nPURPOSE: We introduce the hybrid estimation of computed tomography obtained respiratory function (HECTOR) method that consists of two components: a volume- and a density-based ventilation estimate. For the first component, a deformable image registration (DIR)-based solution for accurate volumetric CTVI generation is proposed, integrating the physical characteristics of the lung deformations in its design. For the second component, an already established air-tissue density model is used. Furthermore, a novel method is developed for combining the two components.\nMETHODS: The proposed method consists of four principal steps: (1) Application of a specially tailored DIR algorithm to estimate respiratory motion between inhale and exhale phases. (2) Conversion of the motion information to volumetric change maps using a variation of the Jacobian determinant method. (3) Computation of a HU-based method that estimates the local product of air-tissue densities. (4) Combination of the metrics estimated in steps 2 and 3 by means of a smooth minimum function. The proposed approach is validated using the publicly available VAMPIRE dataset consisting of two subgroups: 25 subjects scanned with Galligas 4DPET/CT and 21 subjects scanned with DTPA-SPECT. Another dataset of 18 patients available at The Cancer Imaging Archive (TCIA) was used for further validation. All datasets contain inhale/exhale CT scans paired with ground-truth ventilation images (RefVIs). The CTVIs generated by the proposed HECTOR method were tested against the RefVIs using the Spearman correlation coefficient and Dice overlap of low- and high-function lung (DSC-low and DSC-high, respectively).\nRESULTS: The proposed method achieved mean Spearman, DSC-high and DSC-low coefficients of 0.62, 0.55, and 0.59 on the Galligas PET subgroup and 0.49,0,48, and 0.50 on the DTPA-SPECT subgroup of the VAMPIRE dataset. This performance was better than the highest performing method reported in the original challenge. The same metrics for the TCIA dataset were 0.66, 0.60, and 0.60. The proposed hybrid ventilation method achieved higher Spearman correlation scores than the individual volume- and density-based components in all datasets. Additionally, the use of the specially tailored DIR algorithm was found to achieve higher scores than previously reported volume-based methods.\nCONCLUSIONS: Our work provides a novel processing workflow for CT ventilation imaging that can consistently generate ventilation maps with high fidelity compared to reference approaches. This study also provides further insights into the benefits of combining different types of information to model the complex dynamics of respiratory function. Such information can be useful for potential applications in radiation therapy treatment planning and thoracic dose-response assessment.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17787",
    "link": "https://doi.org/10.1002/mp.17787"
  },
  {
    "title": "3D lymphoma segmentation on PET/CT images via multi-scale information fusion with cross-attention.",
    "authors": [
      "Huan Huang",
      "Liheng Qiu",
      "Shenmiao Yang",
      "Longxi Li",
      "Jiaofen Nan",
      "Yanting Li",
      "Chuang Han",
      "Fubao Zhu",
      "Chen Zhao",
      "Weihua Zhou"
    ],
    "abstract": "BACKGROUND: Accurate segmentation of diffuse large B-cell lymphoma (DLBCL) lesions is challenging due to their complex patterns in medical imaging. Traditional methods often struggle to delineate these lesions accurately.\nOBJECTIVE: This study aims to develop a precise segmentation method for DLBCL using 18F-fluorodeoxyglucose (18F-FDG) positron emission tomography (PET) and computed tomography (CT) images.\nMETHODS: We propose a 3D segmentation method based on an encoder-decoder architecture. The encoder incorporates a dual-branch design based on the shifted window transformer to extract features from both PET and CT modalities. To enhance feature integration, we introduce a multi-scale information fusion (MSIF) module that performs multi-scale feature fusion using cross-attention mechanisms with a shifted window framework. A gated neural network within the MSIF module dynamically adjusts feature weights to balance the contributions from each modality. The model is optimized using the dice similarity coefficient (DSC) loss function, minimizing discrepancies between the model prediction and ground truth. Additionally, we computed the total metabolic tumor volume (TMTV) and performed statistical analyses on the results.\nRESULTS: The model was trained and validated on a private dataset of 165 DLBCL patients and a publicly available dataset (autoPET) containing 145 PET/CT scans of lymphoma patients. Both datasets were analyzed using five-fold cross-validation. On the private dataset, our model achieved a DSC of 0.7512, sensitivity of 0.7548, precision of 0.7611, an average surface distance (ASD) of 3.61 mm, and a Hausdorff distance at the 95th percentile (HD95) of 15.25 mm. On the autoPET dataset, the model achieved a DSC of 0.7441, sensitivity of 0.7573, precision of 0.7427, ASD of 5.83 mm, and HD95 of 21.27 mm, outperforming state-of-the-art methods (p < 0.05, t-test). For TMTV quantification, Pearson correlation coefficients of 0.91 (private dataset) and 0.86 (autoPET) were observed, with R2 values of 0.89 and 0.75, respectively. Extensive ablation studies demonstrated the MSIF module's contribution to enhanced segmentation accuracy.\nCONCLUSION: This study presents an effective automatic segmentation method for DLBCL that leverages the complementary strengths of PET and CT imaging. The method demonstrates robust performance on both private and publicly available datasets, ensuring its reliability and generalizability. Our method provides clinicians with more precise tumor delineation, which can improve the accuracy of diagnostic interpretations and assist in treatment planning for DLBCL patients. The code for the proposed method is available at https://github.com/chenzhao2023/lymphoma_seg.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17763",
    "link": "https://doi.org/10.1002/mp.17763"
  },
  {
    "title": "Multimodal feature-guided diffusion model for low-count PET image denoising.",
    "authors": [
      "Gengjia Lin",
      "Yuxi Jin",
      "Zhenxing Huang",
      "Zixiang Chen",
      "Haizhou Liu",
      "Chao Zhou",
      "Xu Zhang",
      "Wei Fan",
      "Na Zhang",
      "Dong Liang",
      "Peng Cao",
      "Zhanli Hu"
    ],
    "abstract": "BACKGROUND: To minimize radiation exposure while obtaining high-quality Positron Emission Tomography (PET) images, various methods have been developed to derive standard-count PET (SPET) images from low-count PET (LPET) images. Although deep learning methods have enhanced LPET images, they rarely utilize the rich complementary information from MR images. Even when MR images are used, these methods typically employ early, intermediate, or late fusion strategies to merge features from different CNN streams, failing to fully exploit the complementary properties of multimodal fusion.\nPURPOSE: In this study, we introduce a novel multimodal feature-guided diffusion model, termed MFG-Diff, designed for the denoising of LPET images with the full utilization of MRI.\nMETHODS: MFG-Diff replaces random Gaussian noise with LPET images and introduces a novel degradation operator to simulate the physical degradation processes of PET imaging. Besides, it uses a novel cross-modal guided restoration network to fully exploit the modality-specific features provided by the LPET and MR images and utilizes a multimodal feature fusion module employing cross-attention mechanisms and positional encoding at multiple feature levels for better feature fusion.\nRESULTS: Under four counts (2.5%, 5.0%, 10%,  and 25%), the images generated by our proposed network showed superior performance compared to those produced by other networks in both qualitative and quantitative evaluations, as well as in statistical analysis. In particular, the peak-signal-to-noise ratio of the generated PET images improved by more than 20% under a 2.5% count, the structural similarity index improved by more than 16%, and the root mean square error reduced by nearly 50%. On the other hand, our generated PET images had significant correlation (Pearson correlation coefficient, 0.9924), consistency, and excellent quantitative evaluation results with the SPET images.\nCONCLUSIONS: The proposed method outperformed existing state-of-the-art LPET denoising models and can be used to generate highly correlated and consistent SPET images obtained from LPET images.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17764",
    "link": "https://doi.org/10.1002/mp.17764"
  },
  {
    "title": "Flexible and modular PET: Evaluating the potential of TOF-DOI panel detectors.",
    "authors": [
      "Gašper Razdevšek",
      "Georges El Fakhri",
      "Thibault Marin",
      "Rok Dolenec",
      "Matic Orehar",
      "Yanis Chemli",
      "Alberto Giacomo Gola",
      "David Gascon",
      "Stan Majewski",
      "Rok Pestotnik"
    ],
    "abstract": "BACKGROUND: Panel detectors have the potential to provide a flexible, modular approach to Positron Emission Tomography (PET), enabling customization to meet patient-specific needs and scan objectives. The panel design allows detectors to be positioned close to the patient, aiming to enhance sensitivity and spatial resolution through improved geometric coverage and reduced noncollinearity blurring. Parallax error can be mitigated using depth of interaction (DOI) information.\nPURPOSE: One of the key questions the article addresses is: Do panel detectors offer viable clinical imaging capabilities, or does limited angular sampling restrict their utility by causing image distortions and artifacts? Additionally, this article explores the scalability of panel detectors for constructing scanners with a long axial field of view (LAFOV).\nMETHODS: Monte Carlo simulations using GATE software were used to assess the performance of panel detectors with various DOI resolutions and Time-of-Flight (TOF) resolutions as fine as 70 ps. The 30 × $\\times$  30 cm panels comprised pixelated 3 × $\\times$  3 × $\\times$  20 mm LSO crystals. Simulations were run on large high-performance computing clusters (122,000 CPU cores). Open-source CASToR software was used for (TOF MLEM) image reconstruction. The image quality of the scanners was assessed using a range of phantoms (NEMA, Derenzo, XCAT, and a high-resolution brain phantom). The Siemens Biograph Vision PET/CT scanner served as the reference model. The performance of larger 120 × $\\times$  60 cm panels was also evaluated.\nRESULTS: Sensitivity increases over threefold when panel-panel distance is reduced from 80 to 40 cm. The noise equivalent count rate, unmodified by TOF gain, of the panel detectors matches that of the reference clinical scanner at a distance of approximately 50 cm between the panels. Spatial resolution perpendicular to the panels improves from 8.7 to 1.6 mm when the panel-panel distance is reduced, and 70 ps + DOI detectors are used instead of 200 ps, no-DOI detectors. With enhanced TOF and DOI capabilities, panel detectors achieve image quality that matches or surpasses the reference scanner while using about four times less detector material. These detectors can be extended for LAFOV imaging without distortions or artifacts. Additionally, improving TOF and DOI performance enhances contrast-to-noise ratios, thereby improving lesion detection.\nCONCLUSIONS: A compact 2-panel PET scanner can match the performance of conventional scanners, producing high-quality, distortion-free images. Its mobility and flexibility enable novel applications, including bedside imaging and intensive care unitdiagnostics, as well as imaging in positions such as sitting or standing. Furthermore, the modularity of panel detectors offers the potential to construct cost-effective, high-performance total-body imaging systems.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17741",
    "link": "https://doi.org/10.1002/mp.17741"
  },
  {
    "title": "A comparative analysis of GEANT4, MCNP6 and FLUKA on proton-induced gamma-ray simulation.",
    "authors": [
      "Hugo Freitas",
      "Esmaeil Nobakht",
      "Florian Grüner",
      "Joao Seco"
    ],
    "abstract": "BACKGROUND: Precise range verification is essential in proton therapy to minimize treatment margins due to the steep dose fall-off of proton beams. The emission of secondary radiation from nuclear reactions between incident particles and tissues stands out as a promising method for range verification. Two prominent techniques are PET and Prompt Gamma-Ray Spectroscopy (PGS). PGS holds significant promise due to its real-time capability for range monitoring. This method allows for prompt detection and quantification of any disparities between planned and actual dose delivery, facilitating adaptive treatment strategies. Given the key role of Monte Carlo (MC) codes in understanding the PGS mechanisms during proton therapy, it is essential to address the current lack of validated codes covering the full energy spectrum of emitted gamma-rays.\nPURPOSE: Addressing the need for precise range monitoring in proton therapy, our study aims to develop and validate MC codes for PGS. We focus on analyse MCNP6, GEANT4, and FLUKA codes, conducting rigorous validation process by comparing our simulation results with experimental data. Additionally, we propose optimal models and parameters to refine the accuracy of simulations for prompt gamma-ray (PG) spectra.\nMETHODS: Various proton data libraries, models and cross-sections values were used in this study to simulate proton-induced gamma-rays in MCNP6, GEANT4 and FLUKA. To validate these simulations, PGS spectra of  15.0  cm 3  $15.0 \\,{\\rm cm}^{3}$  PMMA block irradiation were obtained with  CeBr 3 ${\\rm CeBr}_3$  inorganic scintillator detector for different proton energies, raging from approximately  90 $\\hskip.001pt 90$  to  130  MeV $130 \\,{\\rm MeV}$  .\nRESULTS: GEANT4 was the only MC code capable of successfully reproducing    10 B $^{10}{\\rm B}$  PG lines, while the FLUKA aligned better with experimental data for mid-range energies. At higher energies, FLUKA overestimated the    12 C $^{12}{\\rm C}$  PG line (   2 + → 0 +  $2^{+} \\rightarrow 0^{+}$  ) at  4.44  MeV $4.44 \\,{\\rm MeV}$  , whereas GEANT4 underestimated it; MCNP6 provided the closest match. Additionally, GEANT4, FLUKA, and MCNP6 failed to accurately reproduce the    16 O $^{16}{\\rm O}$  PG line (   3 - → 0 +  $3^{-} \\rightarrow 0^{+}$  ) at  6.13  MeV $6.13 \\,{\\rm MeV}$  , consistent with previous findings. To address this limitation, a new model based on experimental and theoretical data from literature was developed.\nCONCLUSIONS: This study emphasizes the need for updates to the data tables in MC simulations and underscores the importance of further theoretical and experimental research on PG de-excitation lines relevant to proton therapy. The newly developed model, designed to address discrepancies in the simulation of    12 C $^{12}{\\rm C}$  and    16 O $^{16}{\\rm O}$  de-excitation lines across different toolkits, successfully improved the accuracy of the oxygen de-excitation line, which was previously not well-reproduced.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17754",
    "link": "https://doi.org/10.1002/mp.17754"
  },
  {
    "title": "Knowledge relay: Synergetic generation and transfer learning for pancreatic tumor segmentation on multimodal images.",
    "authors": [
      "Shuiping Gou",
      "Ningtao Liu",
      "Wenbo Liu",
      "Yao Yao"
    ],
    "abstract": "BACKGROUND: Pancreatic cancer is among the most lethal malignancies, with the lowest survival rates. The use of image-guided radiotherapy has shown significant potential in enhancing surgical outcomes for pancreatic cancer. However, accurate segmentation of pancreatic tumors prior to radiotherapy remains a challenge due to the small size, irregular shape, and indistinct boundaries of the pancreas and tumor in monomodal imaging. Furthermore, the availability of multimodal images that meet the requirements for precise pancreatic segmentation is highly limited, leading to the datasets that fail to provide comprehensive knowledge for effective image representation in pancreatic tumor segmentation.\nPURPOSE: This study aims to develop a method for accurately segmenting pancreatic tumors under very harsh data conditions, in which the currently available datasets are fragmented with the issues, such as limited sample sizes, inconsistent lesion matching, and incomplete modalities.\nMETHODS: We propose a knowledge relay framework that leverages synergistic generation and transfer learning strategies. The relay comprises three batons: pancreatic PET image generation, coarse detection, and fine segmentation. Multimodal images, including CT, MR, and PET from three separate datasets, are integrated within this framework. The knowledge contained in each dataset is sequentially transferred and aggregated through the batons by the strategies of transfer learning and fine-tuning. Additionally, we introduce a mask-constrained CycleGAN and an inter-attention UNet within this framework to enhance the extraction and utilization of knowledge for accurate pancreatic tumor segmentation.\nRESULTS: The proposed knowledge relay framework achieves the state-of-the-art performance in pancreatic tumor segmentation on PET/MR images. On the images collected from 19 subjects, our method attained a DSC $\\text{DSC}$  of 80.06%, SEN $\\text{SEN}$  of 83.39%, SPE $\\text{SPE}$  of 99.81%, ASD $\\text{ASD}$  of 4.87 mm $\\text{mm}$  , and  95 HD $95 \\text{HD}$  of 12.69 mm $\\text{mm}$  .\nCONCLUSIONS: The results of comparison and ablation experiments validate the effectiveness of the proposed knowledge relay framework in extracting and integrating knowledge from fragmented datasets under constrained conditions. The comprehensive and enriched knowledge significantly enhances the accuracy of pancreatic tumor segmentation.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17713",
    "link": "https://doi.org/10.1002/mp.17713"
  },
  {
    "title": "Characterization of artificial intelligence performance for lesion detection using synthetic lesions in PET imaging.",
    "authors": [
      "Quinn de Bourbon",
      "Shadab Ahamed",
      "Paul Blanc-Durand",
      "Arman Rahmim",
      "Ran Klein"
    ],
    "abstract": "BACKGROUND: The use of artificial intelligence (AI) for lesion detection has witnessed increased interest and efforts in recent years. Meanwhile, task-specific characterization and comparison of AI performance is lacking as supportive evidence prior to its implementation in the clinical setting.\nPURPOSE: To evaluate the use of synthetic lesions in positron emission tomography (PET) and computed tomography (CT) to characterize the performance of lesion detection AI in terms of their limits of detection.\nMETHODS: An image library was constructed containing 565 well-characterized synthetic lesions in 114 reconstructed studies from 56 real, disease-free PET/CT patient data. Using the Lesion Synthesis Toolbox (LST), lesions were manually defined in terms of location, size and intensity. These lesions were then synthesized, forward projected, and added to the raw patient PET data before reconstruction using the same methods used clinically. Lesions were also appended to the reconstructed CT images. This library was sent to two external research teams developing AI for lesion detection in fluorodeoxyglucose (18F-FDG) PET. AI reported lesions were compared to ground truth data and labelled as hit, miss, or false positive. Psychophysical response models were fitted to each AI's responses to characterize their performance.\nRESULTS: Both AI methods confirmed higher lesion detection rates with increased lesion size and contrast. One AI consistently outperformed the other in terms of number of reported lesions, sensitivity, and precision. The fitted psychophysical response model demonstrated both graphically and parametrically an ability of this model to detect smaller lesions for a given degree of reliability. For example, 10 mm diameter lesions could be detected with 90% sensitivity at 8:1 versus 16:1 lesion to background ratio for the two algorithms. Likewise, 3:1 contrast lesions could be detected with 90% sensitivity when lesion diameters were approximately 16 and 31 mm for each algorithm respectively. Compared to defined lesions parameters, the corresponding AI segmented lesions had lower contrast, consistent with partial volume effects in PET imaging, and also smaller size.\nCONCLUSION: Synthetic lesions are a useful tool to characterize the performance of lesion detection by an observer. Visual and psychometric response models of lesion detection performance with respect to lesion characteristics are effective to objectively compare AI performance on the merit of limits of detection. These methods can be applied to objectively compare lesion detection performance with any alternative decision support tool including human and machine observers, display technologies, and image generation systems.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17694",
    "link": "https://doi.org/10.1002/mp.17694"
  },
  {
    "title": "Results of a Geant4 benchmarking study for bio-medical applications, performed with the G4-Med system.",
    "authors": [
      "Pedro Arce",
      "Jay W Archer",
      "Lorenzo Arsini",
      "Alexander Bagulya",
      "David Bolst",
      "Jeremy M C Brown",
      "Barbara Caccia",
      "Andrew Chacon",
      "Giuseppe Antonio Pablo Cirrone",
      "Miguel Antonio Cortés-Giraldo",
      "Dean Cutajar",
      "Giacomo Cuttone",
      "Paolo Dondero",
      "Andrea Dotti",
      "Bruce Faddegon",
      "Serena Fattori",
      "Christian Fedon",
      "Susanna Guatelli",
      "Akihiro Haga",
      "Sebastien Incerti",
      "Vladimir Ivanchenko",
      "Dmitri Konstantinov",
      "Ioanna Kyriakou",
      "Albert Le",
      "Zhuxin Li",
      "Michel Maire",
      "Alessandra Malaroda",
      "Carlo Mancini-Terracciano",
      "Alfonso Mantero",
      "Claire Michelet",
      "Giuliana Milluzzo",
      "Francesca Nicolanti",
      "Mihaly Novak",
      "Chihiro Omachi",
      "Luciano Pandola",
      "Jake Harold Pensavalle",
      "Álvaro Perales",
      "Yann Perrot",
      "Giada Petringa",
      "Silvia Pozzi",
      "José Manuel Quesada",
      "José Ramos-Méndez",
      "Francesco Romano",
      "Anatoly B Rosenfeld",
      "Mitra Safavi-Naeini",
      "Dousatsu Sakata",
      "Luis G Sarmiento",
      "Takashi Sasaki",
      "Yoshihide Sato",
      "Alberto Sciuto",
      "Ioannis Sechopoulos",
      "Edward C Simpson",
      "Ronny Stanzani",
      "Alessandra Tomal",
      "Toshiyuki Toshito",
      "Hoang Ngoc Tran",
      "Christopher White",
      "Dennis H Wright"
    ],
    "abstract": "BACKGROUND: Geant4, a Monte Carlo Simulation Toolkit extensively used in bio-medical physics, is in continuous evolution to include newest research findings to improve its accuracy and to respond to the evolving needs of a very diverse user community. In 2014, the G4-Med benchmarking system was born from the effort of the Geant4 Medical Simulation Benchmarking Group, to benchmark and monitor the evolution of Geant4 for medical physics applications. The G4-Med system was first described in our Medical Physics Special Report published in 2021. Results of the tests were reported for Geant4 10.5.\nPURPOSE: In this work, we describe the evolution of the G4-Med benchmarking system.\nMETHODS: The G4-Med benchmarking suite currently includes 23 tests, which benchmark Geant4 from the calculation of basic physical quantities to the simulation of more clinically relevant set-ups. New tests concern the benchmarking of Geant4-DNA physics and chemistry components for regression testing purposes, dosimetry for brachytherapy with a    125 I $^{125}I$  source, dosimetry for external x-ray and electron FLASH radiotherapy, experimental microdosimetry for proton therapy, and in vivo PET for carbon and oxygen beams. Regression testing has been performed between Geant4 10.5 and 11.1. Finally, a simple Geant4 simulation has been developed and used to compare Geant4 EM physics constructors and physics lists in terms of execution times.\nRESULTS: In summary, our EM tests show that the parameters of the multiple scattering in the Geant4 EM constructor G4EmStandardPhysics_option3 in Geant4 11.1, while improving the modeling of the electron backscattering in high atomic number targets, are not adequate for dosimetry for clinical x-ray and electron beams. Therefore, these parameters have been reverted back to those of Geant4 10.5 in Geant4 11.2.1. The x-ray radiotherapy test shows significant differences in the modeling of the bremsstrahlung process, especially between G4EmPenelopePhysics and the other constructors under study (G4EmLivermorePhysics, G4EmStandardPhysics_option3, and G4EmStandardPhysics_option4). These differences will be studied in an in-depth investigation within our Group. Improvement in Geant4 11.1 has been observed for the modeling of the proton and carbon ion Bragg peak with energies of clinical interest, thanks to the adoption of ICRU90 to calculate the low energy proton stopping powers in water and of the Linhard-Sorensen ion model, available in Geant4 since version 11.0. Nuclear fragmentation tests of interest for carbon ion therapy show differences between Geant4 10.5 and 11.1 in terms of fragment yields. In particular, a higher production of boron fragments is observed with Geant4 11.1, leading to a better agreement with reference data for this fragment.\nCONCLUSIONS: Based on the overall results of our tests, we recommend to use G4EmStandardPhysics_option4 as EM constructor and QGSP_BIC_HP with G4EmStandardPhysics_option4, for hadrontherapy applications. The Geant4-DNA physics lists report differences in modeling electron interactions in water, however, the tests have a pure regression testing purpose so no recommendation can be formulated.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17678",
    "link": "https://doi.org/10.1002/mp.17678"
  },
  {
    "title": "A magnetic field compatible readout circuit for enhanced coincidence time resolution in BGO Cherenkov radiation-based TOF-PET detectors.",
    "authors": [
      "Shirin Pourashraf",
      "Joshua W Cates",
      "Craig S Levin"
    ],
    "abstract": "BACKGROUND: Developing time-of-flight positron emission tomography/magnetic resonance imaging (TOF-PET/MRI) detectors that exploit prompt Cherenkov photons from bismuth germanate (BGO) crystals for estimating 511 keV photon arrival time.\nPURPOSE: To present a low-noise, high-speed electronic readout circuit design for BGO-based TOF-PET detectors that achieves enhanced coincidence time resolution (CTR) in presence of a strong magnetic field.\nMETHODS: The CTR of a BGO-based TOF-PET test detector employing a high-speed, low-noise electronic readout chain was evaluated in a strong magnetic field produced by a permanent magnet placed directly on top of the circuit. For these experiments, which exploit Cherenkov radiation for precise measurement of annihilation photon time arrival time difference, a point source of 22Na was positioned between a pair of 3 × 3 × 15 mm3 polished BGO crystals wrapped in Teflon tape and optically coupled to 3 × 3 mm2 ultra-violet (UV)-sensitive silicon photomultipliers (SiPMs).\nRESULTS: By incorporating both Cherenkov (prompt) and standard (slow) luminescence components, 283 ± 8 ps and 275 ± 10 ps full-width-half-maximum (FWHM) CTR were achieved without and with the permanent magnet present, respectfully. These values improved to 236 ± 4 ps and 216 ± 17 ps FWHM when only the Cherenkov components of the timing signal (events with the fastest rise time) were considered.\nCONCLUSIONS: Results indicate we have designed a high-performance readout circuit that achieves significantly the same CTR in BGO with or without a strong magnetic field present. This further demonstrates that UV SiPMs can effectively operate in a strong magnetic field while remaining highly advantageous for detecting Cherenkov radiation, thus highlighting their potential to be used in BGO-based TOF-PET/MRI scanners.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17643",
    "link": "https://doi.org/10.1002/mp.17643"
  },
  {
    "title": "Realistic total-body J-PET geometry optimization: Monte Carlo study.",
    "authors": [
      "Jakub Baran",
      "Wojciech Krzemien",
      "Szymon Parzych",
      "Lech Raczyński",
      "Mateusz Bała",
      "Aurélien Coussat",
      "Neha Chug",
      "Eryk Czerwiński",
      "Catalina Oana Curceanu",
      "Meysam Dadgar",
      "Kamil Dulski",
      "Kavya Eliyan",
      "Jan Gajewski",
      "Aleksander Gajos",
      "Beatrix C Hiesmayr",
      "Krzysztof Kacprzak",
      "Łukasz Kapłon",
      "Konrad Klimaszewski",
      "Grzegorz Korcyl",
      "Tomasz Kozik",
      "Deepak Kumar",
      "Szymon Niedźwiecki",
      "Dominik Panek",
      "Elena Perez Del Rio",
      "Antoni Ruciński",
      "Sushil Sharma",
      "Shivani",
      "Roman Y Shopa",
      "Magdalena Skurzok",
      "Ewa Stępień",
      "Faranak Tayefiardebili",
      "Keyvan Tayefiardebili",
      "Wojciech Wiślicki",
      "Paweł Moskal"
    ],
    "abstract": "BACKGROUND: Total-body (TB) Positron Emission Tomography (PET) is one of the most promising medical diagnostics modalities, opening new perspectives for personalized medicine, low-dose imaging, multi-organ dynamic imaging or kinetic modeling. The high sensitivity provided by total-body technology can be advantageous for novel tomography methods like positronium imaging, demanding the registration of triple coincidences. Currently, state-of-the-art PET scanners use inorganic scintillators. However, the high acquisition cost reduces the accessibility of TB PET technology. Several efforts are ongoing to mitigate this problem. Among the alternatives, the Jagiellonian PET (J-PET) technology, based on axially arranged plastic scintillator strips, offers a low-cost alternative solution for TB PET.\nPURPOSE: The work aimed to compare five total-body J-PET geometries with plastic scintillators suitable for multi-organ and positronium tomography as a possible next-generation J-PET scanner design.\nMETHODS: We present comparative studies of performance characteristics of the cost-effective total-body PET scanners using J-PET technology. We investigated in silico five TB scanner geometries, varying the number of rings, scanner radii, and other parameters. Monte Carlo simulations of the anthropomorphic XCAT phantom, the extended 2-m sensitivity line source and positronium sensitivity phantoms were used to assess the performance of the geometries. Two hot spheres were placed in the lungs and in the liver of the XCAT phantom to mimic the pathological changes. We compared the sensitivity profiles and performed quantitative analysis of the reconstructed images by using quality metrics such as contrast recovery coefficient, background variability and root mean squared error. The studies are complemented by the determination of sensitivity for the positronium lifetime tomography and the relative cost analysis of the studied setups.\nRESULTS: The analysis of the reconstructed XCAT images reveals the superiority of the seven-ring scanners over the three-ring setups. However, the three-ring scanners would be approximately 2-3 times cheaper. The peak sensitivity values for two-gamma vary from 20 to 34 cps/kBq and are dominated by the differences in geometrical acceptance of the scanners. The sensitivity curves for the positronium tomography have a similar shape to the two-gamma sensitivity profiles. The peak values are lower compared to the two-gamma cases, from about 20-28 times, with a maximum value of 1.66 cps/kBq. This can be contrasted with the 50-cm one-layer J-PET modular scanner used to perform the first in-vivo positronium imaging with a sensitivity of 0.06 cps/kBq.\nCONCLUSIONS: The results show the feasibility of multi-organ imaging of all the systems to be considered for the next generation of TB J-PET designs. Among the scanner parameters, the most important ones are related to the axial field-of-view coverage. The two-gamma sensitivity and XCAT image reconstruction analyzes show the advantage of seven-ring scanners. However, the cost of the scintillator materials and SiPMs is more than two times higher for the longer modalities compared to the three-ring solutions. Nevertheless, the relative cost for all the scanners is about 10-4 times lower compared to the cost of the uExplorer. These properties coupled together with J-PET cost-effectiveness and triggerless acquisition mode enabling three-gamma positronium imaging, make the J-PET technology an attractive solution for broad application in clinics.",
    "abstract_zh": "",
    "summary_zh": "",
    "journal": "Medical physics",
    "pubdate": "",
    "doi": "10.1002/mp.17627",
    "link": "https://doi.org/10.1002/mp.17627"
  }
]